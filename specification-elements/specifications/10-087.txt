
Copyright © 2010 Open Geospatial Consortium, Inc.   
 

 

Open Geospatial Consortium, Inc. 

Date: 2010-08-18 

Reference number of this document: 10-087 

Category: OGC Public Engineering Report 

Editors: Wenli Yang, Liping Di 

OWS-7 Motion Imagery Discovery and Retrieval  

Engineering Report 

 

 

Copyright © 2010 Open Geospatial Consortium, Inc.  

To obtain additional rights of use, visit http://www.opengeospatial.org/legal/. 

 

Warning 

This document is not an OGC Standard. This document is an OGC Public 

Engineering Report created as a deliverable in an OGC Interoperability Initiative 

and is not an official position of the OGC membership. It is distributed for review 

and comment. It is subject to change without notice and may not be referred to as 

an OGC Standard. Further, any OGC Engineering Report should not be referenced 

as required or mandatory technology in procurements. 

 

Document type:  OpenGIS
® 

Engineering Report 

Document subtype: NA 

Document stage:  Approved 

Document language:  English 

http://www.opengeospatial.org/legal/


OGC 10-087 

ii Copyright © 2010 Open Geospatial Consortium, Inc. 
 

 

Preface 

This document presents the metadata requirements for motion imagery discovery and 

retrieval, with a focus on geometrical metadata required for motion imagery change 

detection, of the OWS 7 Sensor Fusion Enablement (SFE) Thread.  The SFE thread 

builds on the OGC Sensor Web Enablement framework that has achieved a degree of 

maturity through previous OWS interoperability initiatives and deployments worldwide. 

OWS-7 will focus on integrating the SWE interfaces and encodings with workflow and 

web processing services to achieve sensor fusion.  OWS 7 SFE will continue the 

development of Secure SWE architecture and continue the interoperability of SWE and 

CCSI. Emphasis for OWS 7 SFE is on the following: 1) Motion Video Fusion – 

geolocating of motion video for display and processing, and change detection of motion 

video using Web Processing Service with rules; 2) Dynamic Sensor Tracking and 

Notification -- tracking sensors and notify users based on a geographic Area of Interest; 

and 3) CCSI-SWE Best Practice -- building on OWS-6 and developing an ER to be 

considered by the OGC Technical Committee as a Best Practice.  ThisTemplate for OGC 

IP Engineering ReportMotion Imagery Discovery and Retrieval Engineering Report (ER) 

documents the metadata used to tag geolocation of Motion Imagery for discovery, 

retrieval and linkage with other data sources over the same location.  This ER should be 

coordinated with Feature/Decision Fusion Authoritative Data Source Directory ER, and 

with Aviation Architecture ER, in terms of cross-thread catalogs & registries issues, 

content, and usage. 

IPR and Patent Statement 

Attention is drawn to the possibility that some of the elements of this document may be 

the subject of patent rights. The Open Geospatial Consortium Inc. shall not be held 

responsible for identifying any or all such patent rights. 

Recipients of this document are requested to submit, with their comments, notification of 

any relevant patent claims or other intellectual property rights of which they may be 

aware that might be infringed by any implementation of the standard set forth in this 

document, and to provide supporting documentation. 

 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

Contents Page 

1 Introduction ..............................................................................................................5 

1.1 Scope ...................................................................................................................5 

1.2 Document contributor contact points ..................................................................5 

1.3 Revision history ...................................................................................................5 

1.4 Future work .........................................................................................................5 

2 References ................................................................................................................6 

3 Terms and definitions ..............................................................................................6 

4 Conventions .............................................................................................................6 

5 Topic overview ........................................................................................................6 

6 Motion Imagery Metadata ........................................................................................6 

6.1 Introduction .........................................................................................................6 

6.2 Geometrical metadata for physical sensor model ................................................7 

6.2.1 Introduction .....................................................................................................7 

6.2.2 Platform metadata ...........................................................................................7 

6.2.3 Sensor operation and mounting metadata .......................................................9 

6.3 Fitting function metadata ...................................................................................10 

6.3.1 Introduction ...................................................................................................10 

6.3.2 Polynomial metadata .....................................................................................10 

6.4 Control point metadata ......................................................................................11 

6.4.1 Introduction ...................................................................................................11 

6.4.2 Control point metadata ..................................................................................11 

6.5 Radiometric metadata ........................................................................................12 

6.5.1 Introduction ...................................................................................................12 

6.5.2 Radiometric metadata items ..........................................................................12 

6.6 Environmental metadata ....................................................................................13 

6.6.1 Introduction ...................................................................................................13 

6.6.2 Environmental metadata ...............................................................................13 

6.7 Discovery and retrieval metadata ......................................................................14 

6.7.1 Introduction ...................................................................................................14 

6.7.2 Discovery and retrieval metadata..................................................................15 

7 UML Diagrams for Motion Imagery Metadata .....................................................16 

7.1 Introduction .......................................................................................................16 

7.2 Platform metadata UML diagrams ....................................................................16 

7.3 Sensor metadata UML diagrams .......................................................................18 

7.4 Functional fitting and control point UML diagrams .........................................19 

7.5 Environmental metadata UML diagram ............................................................20 

7.6 Motion discovery and retrieval metadata UML diagram ..................................20 

8 Motion Imagery encoding XML scheme ...............................................................21 

9 Summary and discussion........................................................................................26 



OGC 10-087 

iv Copyright © 2010 Open Geospatial Consortium, Inc. 
 

Annex A Metadata Tables .................................................................................................27 

Bibliography ......................................................................................................................42 

 

Figures Page 

Figure 1: The Dynamics class diagram ..................................................................................... 16 

Figure 2: The Attitude class diagram ........................................................................................ 17 

Figure 3: The platform information class diagram .................................................................. 17 

Figure 4: The position, orientation, and mounting class diagram .......................................... 18 

Figure 5: The sensor parameters class diagram ....................................................................... 19 

Figure 6: The control point class diagram ................................................................................ 19 

Figure 7: The fitting function class diagram ............................................................................. 20 

Figure 8: The environmental metadata class diagram ............................................................. 20 

Figure 9: The motion imagery metadata UML class diagram ................................................ 21 

  

Tables Page 

Table 1  Platform Metadata Table ............................................................................................. 27 

Table 2  Sensor Metadata Table ................................................................................................. 30 

Table 3  Fitting Metadata Table ................................................................................................. 35 

Table 4  Control Point Metadata Table ..................................................................................... 37 

Table 5  Radiometric and Environmental Metadata ............................................................... 38 

Table 6  Discovery and retrieval metadata ............................................................................... 40 



OWS 7 Motion Imagery Discovery and Retrieval Engineering Report OGC 10-087 

 

Copyright © 2010 Open Geospatial Consortium, Inc. 5 
 

Motion Imagery Discovery and Retrieval Engineering Report 

1 Introduction 

1.1 Scope 

This Motion Imagery Discovery and Retrieval Engineering Report (ER) documents 

the metadata used to tag geolocation of Motion Imagery (MI) for discovery, retrieval and 

linkage with other data sources over the same location, especially the metadata 

information required to geometrically co-register multiple motion images at pixel level so 

that data recorded at different times (e.g., different days) and/or by different providers for 

common or overlapped FOVs can be compared and pixel level changes among the 

different images can be accurately detected and delineated.  This ER reflects one of the 

achievements during the OWS 7 Sensor Fusion Enablement (SFE) thread, which builds 

on the OGC Sensor Web Enablement framework that has achieved a degree of maturity 

through previous OWS interoperability initiatives and deployments worldwide.  

1.2 Document contributor contact points 

All questions regarding this document should be directed to the editor or the contributors: 

Name Organization 

Wenli Yang George Mason University 

Liping Di George Mason University 

TBA  

 

1.3 Revision history 

Date Release Editor Primary 
clauses 

modified 

Description 

2010-03-26 0.0.0 W.Yang & L.Di Initial 
Draft 

Initial Draft 

2010-07-05 1.0.0 W. Yang & L. Di Various Texts, tables, figues, XML 
scheme 

     

1.4 Future work 

Future work may include but is not limited to: 

- Harmonization with other SWE reports 

- Refinement of the UML models 



OGC 10-087 

6 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

- XML scheme for metadata data encoding  

2 References 

3 Terms and definitions 

4 Conventions 

5 Topic overview 

This document reports the activity of the OWS 7 Sensor Fusion Enablement (SFE) 

thread, which focuses motion video fusion, dynamic sensor tracking and notification, and 

CCSI-SWE Best Practice.  This ER documents the metadata required to geolocate 

Motion Imagery (MI) for discovery, retrieval and linkage with other data sources over the 

same location.  Specifically, this ER specifies the metadata information a MI data 

provider shall supply in order for the user to be able to discover, retrieval, and especially 

determine the earth location of the data so that a MI data set can be linked with other data 

sources, including other MI data, recorded both during the same time period and at 

different times to enable video fusion, change detection, and dynamic sensor tracking and 

notification.  This ER should be coordinated with Feature/Decision Fusion Authoritative 

Data Source Directory ER, and with Aviation Architecture ER, in terms of cross-thread 

catalogs & registries issues, content, and usage. 

6 Motion Imagery Metadata 

6.1 Introduction 

Motion Imagery is defined by [DoD, 2009] as ―imagery (a likeness or representation 

of any natural or man-made feature or related object or activity) utilizing sequential or 

continuous streams of images that enable observation of the dynamic, (temporal), 

behavior of objects within the scene‖.  The most unique distinction between motion 

imagery and other types of imagery, such as still digital imagery and earth resources 

satellite imagery is that motion imagery is recorded in high temporal rate, e.g., more than 

a dozen frames per second, for a field of view (FOV) or largely overlapped FOVs so that 

the temporal dynamics of the subjects, such as a moving person or vehicle, in the FOV or 

FOVs can be captured. Motion imagery can be classified into different types based on 

different criteria, such as the wavelength, spatial resolution, bit-depth, data processing 

level, and use-scenario. Different metadata models can be used to describe the details of 

different categories of motion imagery. This ER focuses on motion imagery’s discovery 

and retrieval metadata information needed for sensor fusion enablement, especially 

information required to geometrically co-register multiple motion images so that data 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

recorded at different times (e.g., different days) and/or by different providers for common 

or overlapped FOVs can be compared at individual pixel level and changes among the 

different images can be accurately detected and delineated.  

6.2 Geometrical metadata for physical sensor model 

6.2.1 Introduction 

Geometrical coregistration of multiple motion imageries can be performed using 

different methods.  The first, and usually the most accurate, method involves vigorous 

construction of physical sensor model. In this method, the spatial positions of each pixel 

in multiple motion imageries having the overlapped FOVs, in reference to a 3-

dimensional (3D) Earth Coordinate Reference System (CRS), can be determined using 

the video camera’s interior and exterior parameters and the multiple imageries can thus 

be accurately co-registered at pixel level.  The second method using functional fitting to 

computing pixel’s location in a 3D Earth CRS from pixel’s position in an image CRS. It 

is also possible, although not common, that function fitting is conducted among image 

CRSes of multiple motion imageries without having Earth CRS involved and the co-

registered imageries can be used to detection changes.  Further geopostioning will be 

needed in order to relate the imageries and/or the detected change information to other 

geospatial information. The third method involves using control points to develop 

relationships between pixel’s Earth CRS position and image CRS position.  Similar to the 

second method, it is also possible the functional relationships of pixel locations are 

developed among different MI images without involving an Earth CRS.   

This clause discusses metadata items needed for construction of physical sensor 

model.  The metadata requirements for the other two methods are discussed in clauses 6.3 

and 6.4, respectively. 

6.2.2 Platform metadata 

All platform geometrical metadata are conditional.  They are required if none of the 

following three conditions are met: 1) the video camera’s position and attitude are 

recorded directly in reference to an Earth fixed coordinate reference system CRS at all 

times; 2) the motion imagery can be geopositioned using the function fitting method, in 

which case the fitting function parameters shall be provided (see clause 6.3); and 3) the 

motion imagery can be geopositioned using control points, in which case the metadata 

about control points shall be provided (see clause 6.4).  This clause lists the platform 

geometrical metadata needed for geopositioning motion imagery using the rigorous 

sensor modeling method: 

1. Platform position (conditional) 

This metadata item provides the direct position of the platform onto which a video 

camera is mount, in an Earth Coordinate Reference System (CRS) such as 

EPSG:4326 (CRS code 4326 defined by the European Petroleum Survey Group). This 



OGC 10-087 

8 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

metadata is not required when video camera’s position is not provided in relation to a 

platform position. Depending on the nature of a platform, this metadata item may 

either be time-variant or time-invariant.   When platform is a moving object, the 

position shall be provided for each frame of a MI or be provided, together with 

platform’s velocity and acceleration, for all frames or for a subset of enough frames 

to allow computation of positions for other frames.  When platform is earth fixed, 

only one position value is necessary for all frames of a MI dataset.  In most cases, if a 

platform is stationary, for instance, a building or an observation tower, video 

camera’s position is usually directly determined in an Earth CRS and thus platform 

position information is not necessary.  

2. Platform velocity (conditional)  

When a platform is a moving object such as a moving land vehicle, this metadata item 

provides velocity vectors of the platform along with the three axes of a reference 

Earth CRS.  The metadata, together with platform acceleration and time information, 

is used to compute platform position for the time when a MI is recorded. The 

metadata is not required when video camera’s position is not provided in relation to 

platform position or when platform position is known for all frames (including the 

stationary platform case). When required, this metadata shall be provided for each 

frame or a subset of enough frames, with platform acceleration included, to allow 

computation of platform positions for frames with which position data are not directly 

provided. 

3. Platform acceleration (conditional) 

When a platform is a moving object such as a moving land vehicle, this metadata item 

provides acceleration vectors of the platform along with the three axes of the selected 

CRS. The metadata, together with platform velocity, is used to compute platform 

position. This metadata is not required when video camera’s position is not provided 

in relation to platform position or when platform position is known for all frames 

(including the stationary platform case). When required, this metadata shall be 

provided for each frame or a subset of enough frames, with platform velocity 

included, to allow computation of platform positions for frames with which position 

data are not directly provided. 

4. Platform attitude (conditional) 

This metadata item provides the attitude of a platform, either in the form of a 3x3 

matrix showing the attitude angles along with a reference Earth CRS axes or a 

sequence of rotation angles, along with the order of rotation, in reference to the 

platform’s nominal attitude at rest.  Depending on the nature of a platform, this 

metadata item may either be time-variant or time-invariant.   When platform is a 

moving object, the attitude shall be provided for each frame of a MI or a subset of 

frames of a MI.  When platform is earth fixed, only one set of attitude values is 

needed for all frames of a MI.  In most cases, if a platform is stationary, e.g., a 

building or an observation tower, video camera’s attitude is usually directly 

determined in an Earth CRS and thus platform attitude information is not necessary.  



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

6.2.3 Sensor operation and mounting metadata 

The sensor, i.e., video camera, operation and mounting metadata are used together 

with the platform geometrical data to determine the light of sight (LOS) of a sensor.  The 

metadata are time-variant and their values shall be provided for each frame of motion 

imagery or for a subset of enough frames to allow interpolation, unless a video camera is 

fixed on a stationary platform, in which case one set of time-invariant values are 

necessary.      

1. Sensor position (required) 

This metadata item provides the direct position of a video camera, either in relation to 

the platform position or direct Earth measured location.  When this position is a 

relative to the position of a platform or to a gimbal which itself is mounted onto a 

platform or possibly another gimbal, the position shall be provided as the offset 

vectors to the platform position or the position of the first gimbal onto which the 

camera is mounted. 

2. Sensor attitude (required) 

This metadata item provides the attitude of video camera, either in the form of a 3x3 

matrix showing the attitude angles along with the CRS axes or a sequence of rotation 

angles along with the order of rotation.  This set of parameters shall be provided 

either in relation to a local CRS, which can be associated to platform CRS or a gimbal 

CRS, or directly in relation to an Earth CRS.   

3. Gimbal postion and attitude (conditional) 

This metadata item provides the position and attitude of gimbal to which a video 

camera is mounted.  When a video camera is mounted on a gimbal, which, in turn, is 

mounted on a platform, the position and attitude of the gimbal may or may not be 

required, depending on whether the camera’s position and attitude is provided in 

relation to gimbal.  When the position and attitude of a video camera are provided in 

reference to its mounting gimbal (i.e., not provided directly in reference to platform 

or the Earth), the position and attitude of gimbal, which is mounted on platform, in 

reference to the platform shall be provided. 

It should be noted that theoretically multiple gimbals can be used in mounting a 

sensor to a platform.  That is, a sensor is mounted on a gimbal, which itself is 

mounted on another gimbal.  The second gimbal may also be mounted on to another 

gimbal and so on so forth. When multiple gimbals are used, the successive mounting 

relationship (i.e., attitudes of each gimbal in relation to a previous gimbal) must be 

provided until reach the platform).  In OWS-7, it is assumed that at most one gimbal 

is used.  

4. Calibrated or effective focal length (optional) 

This metadata item provides a video camera’s actual effective focal length when a 

motion imagery is recorded.  If a video camera’s lens is fixed (i.e., non-zooming 

lens), this parameter is the camera’s calibrated focal length.  If a video camera uses a 

zoom lens but the lens’ zooming is fixed during recording, the actually fixed effective 



OGC 10-087 

10 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

local length shall be provided. In all other cases, the time-variant effective focal 

length for each video frame is necessary.  It is expected that all the motion imagery 

used in this initiative shall be recorded using a single fixed focal length.  

5. Recording spatial resolution: (required)  

This metadata item provides a video camera’s effective spatial resolution, in terms of 

number of rows and column in a scene. The metadata may also be provided using a 

more formal sensor detector layout parameter set, in which case the set of parameters 

shall include the dimensions of detector plane, number of detectors along each 

dimension, distance between adjacent detectors, detector size, and detector shape.  In 

the current initiative, it is expected that the spatial resolution expressed in numbers of 

rows and columns shall be enough. Some video cameras allow variable spatial 

resolutions to be used for different recording purposes.  It is expected that all motion 

imagery used in this initiative shall be provided with the same spatial resolution.  

Thus, only one row number and one column number shall be used. 

6. Viewing angle across the row direction (required) 

This metadata item provides the viewing angle across the row direction of a frame, 

i.e., the FOV along the center row or along the line between two center rows. 

7. Vertical viewing angle across the column direction (required) 

This metadata item provides the viewing angle across the column direction of a 

frame, i.e., the FOV along the center column or along the line between two center 

columns. 

8. Focal point distance or slant range (optional) 

This metadata item provides the distance between the video camera’s position and the 

scene. The distance can be approximate if it is difficult to obtain an accurate value. 

 

6.3 Fitting function metadata 

6.3.1 Introduction 

Functional fitting is also frequently used to relate the pixel coordinate values in a 

motion imagery to those in an Earth CRS or in another motion imagery so that pixel 

locations expressed in one CRS can be transformed to those in another CRS. A fitting 

function is expressed in a set of polynomials or rational polynomials.  Fitting functions 

are time-variant except when video camera is fixed in an Earth CRS or when the relative 

positions of the multiple video cameras used in recording are kept unchanged.  This 

clause defines metadata items required to provide unambiguous fitting function 

information.  

6.3.2 Polynomial metadata 

1. Dimension names for independent and dependent variables (required) 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

Dimension names identify the CRS coordinate axis names, either of an Earth CRS 

(e.g., y, x, or latitude, longitude) or a reference image’s CRS (e.g., row, column, or 

line, sample), as dependent variables and the CRS coordinate axis names in the of the 

CRS (e.g., row, column, or line, sample) of the image to be geolocated or registered, 

as independent variable. 

2. Power of polynomial (required) 

This metadata item provides an integer value representing the power of polynomial. 

3. Coefficients of polynomial (required) 

This metadata item provides a record of floating point values as coefficients for each 

item in a polynomial function. 

4. Scale factor (optional) 

This metadata item provides an optional scale factor for transforming the normalized 

variable to its true value. 

5. Translation value for polynomial coefficients (optional) 

This metadata item provides an optional offset for translating the normalized variable 

to its true value. 

6. Rational polynomial numerator and denominator identification (optional)  

This metadata item provides information to identify whether a polynomial is a 

numerator polynomial or a denominator polynomial when the fitting function is a 

rational polynomial. 

 

6.4 Control point metadata 

6.4.1 Introduction 

The geometrical relationship between pixel locations in a motion image CRS and 

locations in either an Earth CRS or in another reference motion imagery CRS can be 

provided through a set of control points.  The control points are usually referred to as 

ground control points (GCP), although they may locate in above ground objects such as 

buildings. For change motion imagery change detection, all pixels of MI frames may not 

necessarily be associated to an Earth CRS (although general geopositioning of a frame in 

an Earth location is always needed) and only frame-to-frame registrations are required to 

allow detection of changes between images.  This clause defines the metadata required to 

provide information for such control points. 

6.4.2 Control point metadata 

1. Target coordinate reference system (required) 



OGC 10-087 

12 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

This metadata item provides identification information for the CRS associated with 

control point position values.  The CRS is either an Earth CRS or the CRS of a 

reference motion imagery on to which another motion imagery is to be geometrically 

registered. 

2. Number of control points (required) 

This metadata item identifies the number of control points for a motion imagery 

frame. Although the minimum requirement on the number of control points is three, a 

much larger number is usually needed. 

3. Position of control points in target CRS (required) 

This metadata item provides control point position values in the identified Earth CRS 

or the reference image CRS to which the motion imagery is to be registered. 

4. Control point locations in source imagery (required) 

This metadata item provides position coordinate values of control points, expressed in 

row and column or line and sample, in the source image to geolocated or registered. 

5. Quality of GCP (optional) 

This metadata item provides control point accuracy information through a covariance 

matrix. 

 

6.5 Radiometric metadata 

6.5.1 Introduction 

Radiometric metadata are necessary to determine the reflectance of the scene in a MI 

frame.  In some cases, changes in MI are not caused by the relocation/moving of an 

geometry (e.g., the appearance of an new object) but by the change in color/brightness of 

the same geometry (e.g., ground digging/refilling).    Radiometric metadata are needed in 

order to determine whether changes in a scene’s color/brightness are caused disturbance 

in the scene or by other factors such as changes in illumination.  Radiometric metadata 

include those from video camera setting/operation and those from environment. 

6.5.2 Radiometric metadata items 

1. Video camera aperture (required)  

This metadata item provides lens aperture value of a video camera during recording.  

The value of this metadata is time-variant but may be set to a fixed value for a 

specific series of motion imagery. 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

2. Video camera shutter speed (required)  

This metadata item provides shutter speed value of a video camera during recording.  

The value of this metadata is time-variant but may be set to a fixed value for a 

specific series of motion imagery. 

3. Calibration coefficients (optional) 

The calibration coefficients are used to convert digital numbers recorded in the MI 

frames to radiance values reflected from the scene.  These coefficients are typically 

provided as scale and offset in linear conversion equations.  The reflected radiance 

together with the illumination (see the next metadata item) can be used to determine 

the reflectance of each pixel in the MI scene. 

4. Ambient illumination (optional), 

The ambient illumination, either a passive (e.g., solar radiation) or an active source 

(e.g., artificial lights), together with the aperture and shutter speed, can be used to 

derive the radiance recorded by an image. 

5. Cloud percent (optional) 

Percent cloud coverage provides an estimation of the ambient illumination when 

accurate measurement of illumination is not available.  

6. Atmospheric visibility (optional)  

This metadata item provides the greatest horizontal distance at which selected objects 

can be seen, identified, and/or measured with instrumentation.  

6.6 Environmental metadata 

6.6.1 Introduction 

Environmental metadata of a MI are those related to the environment of around the 

scene recorded in the MI.  Information on the environments of a MI is in some cases 

important to MI discovery and retrieval and particularly to MI change detection.  For 

instance, a scene may appear to have changed due to wind effect and shadows caused by 

the terrain slope/aspect and ground objects (e.g., trees) may cause pseudo change effects.  

Some radiometric metadata items, such as illumination and atmospheric visibility, are 

also about the scene environment.  This clause describes environmental metadata not 

included in the previous clauses. 

6.6.2 Environmental metadata 

1. Digital terrain model (optional)  

Digital elevation model (DEM) covering both the location of the target (field of view) 

and the location of sensor, as well as the space between the target and the sensor 

location, are used to determine the intersection of the light of sight (LOS) from the 

sensor to the target scene.  In most cases, it is assumed that there is nothing blocking 

the view from the video sensor to the main target. It is possible that the scene may be 

partially blocked by objects, including terrain, between the sensor and the scene.  

High resolution DEM data, such as the heights of buildings and trees, are extremely 



OGC 10-087 

14 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

useful in determine the intersection of LOS at the scene. The metadata item refers to 

the digital terrain model of the area, covering both the location of the target (field of 

view) and the location of sensor, and the space in-between the two.  

2. Wind speed (optional)  

Wind speed provides additional information on scene variation.  Two images of the 

same unchanged scene may appear different when one is recorded in calm condition 

while another is recorded in windy condition (assuming changes to be detected does 

not include scene wind-induced variations). 

3. Humidity (optional)  

Different humidity conditions may cause variations in color and brightness in motion 

imageries.  Humidity information can be used as a criterion in selecting motion 

imagery pairs for change detection. 

4. Temperature (optional)  

Similar to the humidity, different temperature conditions may cause variations in 

color and brightness in motion imageries. 

5. Soil moisture (optional)  

Soil moisture affects the color and brightness of a scene.  This metadata helps 

radiometric calibration/registration of two scenes.  A disturbed location in a scene in 

the field, e.g., a newly buried improvised explosive device, may appear to have 

similar tone with that of a scene recorded after a precipitation event. 

6. Land cover/use type and scheme (optional)  

Land use/cover type presented in the scene helps change detection algorithm in 

depicting variations in a scene and interpretation of variations.  Different land 

use/cover types require different criteria in defining change versus no change. Land 

use/cover metadata should be associated with certain land use/cover classification 

scheme.  Different land use/cover schemes provide different levels and/or purpose of 

classification.  In most motion imagery change detection use cases, high level and 

detailed land use/cover classification scheme, such as the Anderson Level III and 

Level IV (Anderson et al, 1976), is needed. 

 

6.7 Discovery and retrieval metadata 

6.7.1 Introduction 

Most critical information needed for discovery and retrieval of MI data includes the 

spatial and temporal locations of the imagery.  Additional metadata information, such as 

the spatial position of the video camera used in recording, the description of the target 

being recorded in the MI and of the camera, and viewing geometry, also provides 

important discovery and retrieval information.  Many environmental metadata can be 

used as discovery and retrieval criteria.  Thus, most of discovery and retrieval metadata 

items are already included in the previous clauses, especially those related to the 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

geometrical and dynamical configurations of the sensor and its mounting platform from 

which accurate geopositioning of MI can be derived.  In this clause, additional metadata 

items related to the discovery and retrieval are listed so that they may be used 

independent of geometrical correction.  All metadata items listed in this clause are 

optional except for the image identification and the spatial and temporal metadata, 

although in many cases additional metadata are used together with spatio-temporal 

information for more specific discovery and accurate retrieval of a particular MI or 

frames with a MI.  

6.7.2 Discovery and retrieval metadata 

1. Image identifier (required)  

The metadata item provides the unique identification of a motion imagery. 

2. Observation date and time (required)  

The observation date/time information is one of the most important and frequently 

used discovery and retrieval metadata.  This information is included in the dynamics 

parameters of the sensor and/or platform.  The date/time stamp should either be 

directly recorded together with each MI frame or be interpolated, when frame rate is 

high (e.g., 24 frames per second), from closest frames.  In either case, the MI provider 

should make this information available for each individual MI frame so that it is 

searchable by date/time. 

3. Geographic bounding rectangle of the scene (required) 

This metadata item provides the spatial bounding of the scene recorded in the motion 

imagery.  The bounding rectangle may be expressed either in a two-dimensional 

horizontal Earth CRS or a three-dimensional Earth CRS. This metadata does not tell 

earth locations of individual pixels, unless the motion imagery is georectified to an 

Earth CRS.  It instead provides overall spatial extent information of a motion imagery 

so that the imagery can be searched according to geographic location.  

4. Mission description (optional): 

This metadata item provides a description of the purpose of the motion imagery 

recording mission.  

5. Sensor identification (optional):  

This metadata item provides sensor identification information that may be used for 

discovery and retrieval of motion imagery recorded by a particular sensor.  

6. Sensor type (optional) 



OGC 10-087 

16 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

This metadata item tells the type of the sensor used in taking the motion imagery. 

7. Sensor description (optional) 

This metadata item provides any other additional description information of the 

sensor. 

8. Sensor geometry (optional) 

This metadata item provides information on sensor looking geometry.  This is a 

general description of viewing geometry in addition the accurate sensor geometrical 

information needed in physical sensor model.  

7 UML Diagrams for Motion Imagery Metadata 

7.1 Introduction  

This clause describes the modular/hierarchical relationships among different 

metadata components and the data types of metadata items, using UML class diagrams.   

The geometrical metadata class diagrams are mainly derived from the ISO 19130.  It 

should be noted that the diagrams, including the data types defined in the diagrams, are 

informative.  Significant efforts are required to harmonize the structure with other SFE 

and OWS documents in order to make the UML diagrams as OGC standard. 

7.2 Platform metadata UML diagrams 

The platform’s velocity, acceleration, and attitude metadata item together provide 

platform dynamics information. Figure 1 shows the UML class diagram for platform 

dynamics.   

 

 

 

 

Figure 1: The Dynamics class diagram 

 

The UML class diagram for attitude is shown in Figure 2. This class is a data type 

class.  The attitude can be applied for any objects, including a sensor (i.e., a video 

camera), a platform, or a gimbal.  Thus, in (rare) cases when a video camera’s attitude 

information is directly provided without referencing to a mounting platform, this UML 

class can be used to provide metadata of the camera’s attitude. 

 

 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 2: The Attitude class diagram 

 

 

 

 

 

 

The dynamics information and the position information combined provide a complete 

set of platform geometrical information.  Additional non-geometrical metadata 

information shall further be provided to describe a platform, such as citation and platform 

identifier defined in ISO 19115-2 [ISO, 2008], for discovery and retrieval purpose.  

Figure 3 shows the UML class diagram of platform complete geometrical information 

and additional non-geometrical metadata for discovery and retrieval.  The later will be 

further discussed in clause 6.7. 

 

 

 

 

 

 

 

 

 

 

 

Figure 3: The platform information class diagram 



OGC 10-087 

18 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

7.3 Sensor metadata UML diagrams 

The sensor attitude is described in the same to that of the platform, i.e., Figure 2, the 

UML diagram for attitude.  The sensor’s position, orientation, and mounting relationship 

are shown in UML class diagram Figure 4. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 4: The position, orientation, and mounting class diagram 

 

 

A more complete sensor metadata UML class diagram is shown in Figure 5, which 

includes some more metadata items related to the sensor operation and radiometric 

calibration. 

 

 

 

 

 

 

 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

 

 

 

 

 

 

 

 

 

 

Figure 5: The sensor parameters class diagram 

 

7.4 Functional fitting and control point UML diagrams 

The UML diagrams for geometrical rectification/registration using the control point 

method  and the polynomial fitting function are shown in Figures 6 and 7, respectively. 

 

 

Figure 6: The control point class diagram 

 

 



OGC 10-087 

20 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

 

 

Figure 7: The fitting function class diagram 

 

7.5 Environmental metadata UML diagram 

The UML diagram class for environmental metadata is shown in Figure 8. 

 

 
 

Figure 8: The environmental metadata class diagram 

 

7.6 Motion discovery and retrieval metadata UML diagram 

The complete UML class diagram for motion imagery retrieval and discovery 

metadata, with an emphasis on geometrical rectification and/or registration of multiple 

imageries for change detection, is shown is figure 9. 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

 

Figure 9: The motion imagery metadata UML class diagram 

 

8 Motion Imagery encoding XML scheme 

The XML encoding scheme for motion imagery discovery and retrieval as shown in 

Figure 9 is as the following: 

 

<?xml version="1.0" encoding="ISO-8859-1"?> 
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"> 
 <xs:element name="MIER_MatrixAttitude" type="MIER_MatrixAttitude"/> 
 <xs:complexType name="MIER_MatrixAttitude"> 
  <xs:complexContent> 
   <xs:extension base="MIER_Attitude"> 
    <xs:sequence> 
     <xs:element name="attitudeMatrix" type="xs:string" minOccurs="1" maxOccurs="1"/> 
    </xs:sequence> 
   </xs:extension> 
  </xs:complexContent> 
 </xs:complexType> 
 <xs:element name="MIER_Matrix" type="MIER_Matrix"/> 
 <xs:complexType name="MIER_Matrix"> 
  <xs:sequence> 
   <xs:element name="matrixElements" type="xs:string" minOccurs="9" maxOccurs="9"/> 
  </xs:sequence> 



OGC 10-087 

22 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

 </xs:complexType> 
 <xs:element name="MIER_SensorFrameGeometry" type="MIER_SensorFrameGeometry"/> 
 <xs:complexType name="MIER_SensorFrameGeometry"> 
  <xs:sequence> 
   <xs:element name="columnDirectionViewAngle" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="numberOfColumns" type="xs:int" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="numberOfRows" type="xs:int" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="rowDirectionViewAngle" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="MIER_SensorParameters" type="MIER_SensorParameters" minOccurs="1" 
maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Imagery" type="MIER_Imagery"/> 
 <xs:complexType name="MIER_Imagery"> 
  <xs:sequence> 
   <xs:element name="beginTime" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="boundedBy" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="endTime" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="missionDescription" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensoeGeometry" type="MIER_Attitude" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensorDescription" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensorType" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="Class1" type="Class1"/> 
 <xs:complexType name="Class1"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_Imagery" type="MIER_Imagery"/> 
 <xs:complexType name="MIER_Imagery"> 
  <xs:sequence> 
   <xs:element name="beginTime" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="boundedBy" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="endTime" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="identifier" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="missionDescription" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensoeGeometry" type="MIER_Attitude" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensorDescription" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensorType" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="MIER_SensorPlatForm" type="MIER_SensorPlatForm" minOccurs="1" 
maxOccurs="1"/> 
   <xs:element name="controlPoint" type="MIER_ControlPoint" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="fittingFunction" type="MIER_FittingFunction" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="environmentInfo" type="MIER_Environment" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Extent" type="MIER_Extent"/> 
 <xs:complexType name="MIER_Extent"> 
  <xs:sequence> 
   <xs:element name="crsIdentifier" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="maxX" type="xs:float" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="maxY" type="xs:float" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="maxZ" type="xs:float" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="minX" type="xs:float" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="minY" type="xs:float" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="minZ" type="xs:float" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="Class3" type="Class3"/> 
 <xs:complexType name="Class3"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="Class4" type="Class4"/> 
 <xs:complexType name="Class4"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_PositionAndOrientation" type="MIER_PositionAndOrientation"/> 
 <xs:complexType name="MIER_PositionAndOrientation"> 
  <xs:sequence> 
   <xs:element name="CRS" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="dynamics" type="MIER_Dynamics" minOccurs="1" maxOccurs="1"/> 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

   <xs:element name="offsetVector" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="position" type="MIER_Position" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="mountingObject" type="MIER_PositionAndOrientation" minOccurs="0" 
maxOccurs="1"/> 
   <xs:element name="platform" type="MIER_PlatformParameters" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_SensorParameters" type="MIER_SensorParameters"/> 
 <xs:complexType name="MIER_SensorParameters"> 
  <xs:sequence> 
   <xs:element name="calibrationInfo" type="MIER_Calibration" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="description" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="identifier" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="name" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="operationalWavelength" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Calibration" type="MIER_Calibration"/> 
 <xs:complexType name="MIER_Calibration"> 
  <xs:sequence> 
   <xs:element name="calibrationAgency" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="calibrationDate" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_SensorOperation" type="MIER_SensorOperation"/> 
 <xs:complexType name="MIER_SensorOperation"> 
  <xs:sequence> 
   <xs:element name="aperture" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="focalLength" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="positionAndOrientation" type="MIER_PositionAndOrientation" minOccurs="1" 
maxOccurs="unbounded"/> 
   <xs:element name="recordingTime" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="shutterSpeed" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="MIER_SensorParameters" type="MIER_SensorParameters" minOccurs="1" 
maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="Class5" type="Class5"/> 
 <xs:complexType name="Class5"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_ControlPoint" type="MIER_ControlPoint"/> 
 <xs:complexType name="MIER_ControlPoint"> 
  <xs:sequence> 
   <xs:element name="numberControlPoints" type="xs:int" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="positionImage" type="xs:string" minOccurs="1" maxOccurs="unbounded"/> 
   <xs:element name="positionTargetCRS" type="xs:string" minOccurs="1" maxOccurs="unbounded"/> 
   <xs:element name="qualityControlPoint" type="MIER_Matrix" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="targetCRS" type="xs:string" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Environment" type="MIER_Environment"/> 
 <xs:complexType name="MIER_Environment"> 
  <xs:sequence> 
   <xs:element name="ambientIllumination" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="atmVisibility" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="cloudPercent" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="humidity" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="landCoverType" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sceneDEM" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="soilMoisture" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="temperature" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="windSpeed" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="Class8" type="Class8"/> 
 <xs:complexType name="Class8"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_FittingFunction" type="MIER_FittingFunction"/> 
 <xs:complexType name="MIER_FittingFunction"> 
  <xs:sequence/> 
 </xs:complexType> 



OGC 10-087 

24 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

 <xs:element name="MIER_Position" type="MIER_Position"/> 
 <xs:complexType name="MIER_Position"> 
  <xs:sequence> 
   <xs:element name="position" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="positionAccuracy" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="timeOfMeasurement" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Attitude" type="MIER_Attitude"/> 
 <xs:complexType name="MIER_Attitude"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_AngleAttitude" type="MIER_AngleAttitude"/> 
 <xs:complexType name="MIER_AngleAttitude"> 
  <xs:complexContent> 
   <xs:extension base="MIER_Attitude"> 
    <xs:sequence> 
     <xs:element name="rotatedAxes" type="xs:boolean" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="rotationAngleX" type="xs:string" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="rotationAngleY" type="xs:string" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="rotationAngleZ" type="xs:string" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="rotationSequence" type="xs:string" minOccurs="1" maxOccurs="1"/> 
    </xs:sequence> 
   </xs:extension> 
  </xs:complexContent> 
 </xs:complexType> 
 <xs:element name="MIER_RotationSequence" type="MIER_RotationSequence"/> 
 <xs:complexType name="MIER_RotationSequence"> 
  <xs:sequence> 
   <xs:element name="XYZ" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="XZY" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="YXZ" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="YZX" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="ZXY" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="ZYX" type="xs:string" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_PlatformParameters" type="MIER_PlatformParameters"/> 
 <xs:complexType name="MIER_PlatformParameters"> 
  <xs:sequence> 
   <xs:element name="citation" type="xs:string" minOccurs="0" maxOccurs="unbounded"/> 
   <xs:element name="description" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="dynamics" type="MIER_Dynamics" minOccurs="0" maxOccurs="unbounded"/> 
   <xs:element name="identifier" type="xs:string" minOccurs="1" maxOccurs="unbounded"/> 
   <xs:element name="name" type="xs:string" minOccurs="1" maxOccurs="unbounded"/> 
   <xs:element name="position" type="MIER_Position" minOccurs="0" maxOccurs="unbounded"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="SFEER_Polynomial" type="SFEER_Polynomial"/> 
 <xs:complexType name="SFEER_Polynomial"> 
  <xs:sequence> 
   <xs:element name="resultDimension" type="xs:string" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="SFEER_RationalPolynomial" type="SFEER_RationalPolynomial"/> 
 <xs:complexType name="SFEER_RationalPolynomial"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="SFEER_PolynomialCoefficient" type="SFEER_PolynomialCoefficient"/> 
 <xs:complexType name="SFEER_PolynomialCoefficient"> 
  <xs:sequence> 
   <xs:element name="value" type="xs:string" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Dynamics" type="MIER_Dynamics"/> 
 <xs:complexType name="MIER_Dynamics"> 
  <xs:sequence> 
   <xs:element name="acceleration" type="xs:string" minOccurs="0" maxOccurs="unbounded"/> 
   <xs:element name="attitude" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="timeOfMeasurement" type="xs:dateTime" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="trueHeading" type="xs:string" minOccurs="0" maxOccurs="1"/> 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

   <xs:element name="velocity" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="SFEER_Variable" type="SFEER_Variable"/> 
 <xs:complexType name="SFEER_Variable"> 
  <xs:sequence> 
   <xs:element name="dimension" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="power" type="xs:integer" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="scaleFactor" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="translationValue" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Polynomial" type="MIER_Polynomial"/> 
 <xs:complexType name="MIER_Polynomial"> 
  <xs:complexContent> 
   <xs:extension base="MIER_FittingFunction"> 
    <xs:sequence> 
     <xs:element name="targetDimension" type="xs:string" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="coefficient" type="MIER_PolynomialCoefficient" minOccurs="1" 
maxOccurs="unbounded"/> 
    </xs:sequence> 
   </xs:extension> 
  </xs:complexContent> 
 </xs:complexType> 
 <xs:element name="MIER_FittingFunction" type="MIER_FittingFunction"/> 
 <xs:complexType name="MIER_FittingFunction"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_RationalPolynomial" type="MIER_RationalPolynomial"/> 
 <xs:complexType name="MIER_RationalPolynomial"> 
  <xs:complexContent> 
   <xs:extension base="MIER_FittingFunction"> 
    <xs:sequence> 
     <xs:element name="numerator" type="MIER_Polynomial" minOccurs="1" maxOccurs="1"/> 
     <xs:element name="denominator" type="MIER_Polynomial" minOccurs="1" maxOccurs="1"/> 
    </xs:sequence> 
   </xs:extension> 
  </xs:complexContent> 
 </xs:complexType> 
 <xs:element name="MIER_PolynomialCoefficient" type="MIER_PolynomialCoefficient"/> 
 <xs:complexType name="MIER_PolynomialCoefficient"> 
  <xs:sequence> 
   <xs:element name="value" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="variable" type="MIER_Variables" minOccurs="0" maxOccurs="unbounded"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Variables" type="MIER_Variables"/> 
 <xs:complexType name="MIER_Variables"> 
  <xs:sequence> 
   <xs:element name="dimensionName" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="power" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="scaleFactor" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="translationValue" type="xs:string" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_Radiometric" type="MIER_Radiometric"/> 
 <xs:complexType name="MIER_Radiometric"> 
  <xs:sequence/> 
 </xs:complexType> 
 <xs:element name="MIER_Radiometric" type="MIER_Radiometric"/> 
 <xs:complexType name="MIER_Radiometric"> 
  <xs:sequence> 
   <xs:element name="ambientIllumination" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="aperture" type="xs:string" minOccurs="1" maxOccurs="1"/> 
   <xs:element name="atmVisibility" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="calibrationCoeff" type="xs:string" minOccurs="0" maxOccurs="unbounded"/> 
   <xs:element name="cloudPercent" type="xs:string" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="shutterSpeed" type="xs:string" minOccurs="1" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
 <xs:element name="MIER_SensorPlatForm" type="MIER_SensorPlatForm"/> 
 <xs:complexType name="MIER_SensorPlatForm"> 
  <xs:sequence> 



OGC 10-087 

26 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

   <xs:element name="platformInfo" type="MIER_PlatformParameters" minOccurs="0" maxOccurs="1"/> 
   <xs:element name="sensorInfo" type="MIER_SensorParameters" minOccurs="0" maxOccurs="1"/> 
  </xs:sequence> 
 </xs:complexType> 
</xs:schema> 

 

 

9 Summary and discussion 

This engineering report documents the metadata requirement needed to discover and 

retrieve motion imageries to perform accurate pixel level change detection.  The focus of 

the document is on the geometrical metadata needed for geopositioning of a motion 

imagery to an Earth coordinate system and for geometrical coregistration of multiple 

motion imageries.  Other metadata information that impacts change detection, such as 

radiometric parameters during sensor operation and environmental illumination, is also 

included.  The geometrical metadata and the related UML class diagrams are drawn 

mainly from the ISO 19130, image sensor models for geopositioning. While the metadata 

information described in this report represents an ideal case on requiring the motion 

imagery providers/consumers to supply/use metadata to achieve accurate data fusion and 

change detection result, it should be noted that in real world cases it is unlikely for 

providers to collect and provide and for consumers to obtain and process all such 

information.  During the course of the OWS SFE project, a relatively controlled 

experiment environment was set.  The motion imageries were recorded from almost the 

same paths during very similar environmental conditions.  The process of pushing 

original imageries to SOS, searching for and access to the imageries in SOS, the fusion 

and change detection, and the pushing of fusion/detection result back to SOS, was 

simplified to certain degree to avoid vigorous catalogue registration, publishing, updating 

and vigorous searching, scene matching, and geopositioning.  The controlled experiment 

loosened the requirement on metadata information.  More experiments will be needed to 

test use cases with less a prior knowledge on motion imagery collection.  Another topic 

worth of discussion and future work is the encoding scheme of motion imagery metadata.  

The current scheme is created from UML models primarily derived ISO 19130 standard.  

There are several other schemas including GML, SWE, SensorML, and other ISO TC211 

standards.  Creation (or adoption/harmonization) of a consensus scheme needs efforts 

beyond one OWS initiative.  

 

 



OWS 7 Motion Imagery Discovery and Retrieval Engineering Report OGC 10-087 

 

Copyright © 2010 Open Geospatial Consortium, Inc. 27 
 

Annex A Metadata Tables 

 

Table 1  Platform Metadata Table 

 

ID Parameter Definition Units Obligation Description 

1 Platform 
Position, X 

Vector 
Component 

X component of the 
platform position in an 

Earth CRS 

Length 
(meter or 
kilometer) 

Conditional, required if sensor 
position is not directly defined in an 

Earth CRS 

This parameter provides the X 
coordinate value of platform 

position in an Earth XYZ CRS. 

2 Platform 
Position, Y 

Vector 
Component 

Y component of the 
platform position in an 

Earth CRS 

Length 
(meter or 
kilometer) 

Conditional, required if sensor 
position is not directly defined in an 

Earth CRS 

This parameter provides the Y 
coordinate value of platform 

position in an Earth XYZ CRS. 

3 Platform 
Position, Z 

Vector 
Component 

Z component of the 
platform position in an 

Earth CRS 

Length 
(meter or 
kilometer) 

Conditional, required if sensor 
position is not directly defined in an 

Earth CRS 

This parameter provides the 
vertical, Z, coordinate value of 

platform position in an Earth XYZ 
CRS. 

4 Platform Velocity 
Vector’s X 

Component 

X component of the 
platform velocity in an 

Earth CRS 

Velocity 
(m/s) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

not given.  

This parameter provides platform 
velocity vector’s X component in 

an Earth XYZ CRS. 

5 Platform Velocity 
Vector’s Y 

Component 

Y component of the 
platform velocity in an 

Earth CRS 

Velocity 
(m/s) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

This parameter provides platform 
velocity vector’s Y component in 

an Earth XYZ CRS. 



OGC 10-087 

28 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

not given. 

6 Platform Velocity 
Vector’s Z 

Component 

Z component of the 
platform velocity in an 

Earth CRS 

Velocity 
(m/s) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

not given. 

This parameter provides platform 
velocity vector’s Z component in 

an Earth XYZ CRS. 

7 Platform 
Acceleration 
Vector’s X 

Component 

X component of the 
platform velocity in an 

Earth CRS. 

Acceleration 
(m/s

2
) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

not given. 

This parameter provides platform 
acceleration vector’s X 

component in an Earth XYZ CRS. 

8 Platform 
Acceleration 
Vector’s Y 

Component 

Y component of the 
platform velocity in an 

Earth CRS 

Acceleration 
(m/s

2
) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

not given. 

This parameter provides platform 
acceleration vector’s Y 

component in an Earth XYZ CRS. 

9 Platform 
Acceleration 
Vector’s Z 

Component 

Z component of the 
platform velocity in an 

Earth CRS. 

Acceleration 
(m/s

2
) 

Conditional, required if sensor 
position is not directly defined in an 
Earth CRS and platform position is 

not given. 

This parameter provides platform 
acceleration vector’s Z 

component in an Earth XYZ CRS. 

10 Platform Attitude 
Roll Angle 

The roll angle of the 
platform.   

Angle 
(radian) 

Conditional, required if sensor 
attitude is provided in reference to 
the platform’s coordinate reference 
system. Roll, pitch, and yaw angles 
may also be replaced with a matrix 
of nine angles between the three 
platform CRS axes and the three 

axes of an Earth CRS, as defined in 
item 14. 

This parameter provides the 
platform’s roll angle, which is the 
angle the platform rotates along 

its X axis, positive clockwise 
when looking at the positive 

direction of the X axis. See the 
obligation column for more 

information on this parameter. 

11 Platform Attitude 
Pitch Angle 

The pitch angle of the 
platform 

Angle 
(radian) 

Conditional, required if sensor 
attitude is provided in reference to 
the platform’s coordinate reference 
system. Roll, pitch, and yaw angles 

This parameter provides the 
platform’s pitch angle, which is 
the angle the platform rotates 

along its Y axis, positive 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

may also be replaced with a matrix 
of nine angles between the three 
platform CRS axes and the three 

axes of an Earth CRS, as defined in 
item 14. 

clockwise when looking at the 
positive direction of the Y axis. 
See the obligation column for 

more information on this 
parameter. 

12 Platform Attitude 
Yaw Angle 

The yaw angle of the 
platform 

Angle 
(radian) 

Conditional, required if sensor 
attitude is provided in reference to 
the platform’s coordinate reference 
system. Roll, pitch, and yaw angles 
may also be replaced with a matrix 
of nine angles between the three 
platform CRS axes and the three 

axes of an Earth CRS, as defined in 
item 14. 

This parameter provides the 
platform’s yaw angle, which is the 
angle the platform rotates along 

its Z axis, positive clockwise when 
looking at the positive direction of 

the Z axis. See the obligation 
column for more information on 

this parameter. 

13 Platform True 
Heading 

The platform’s true 
heading angle in 

reference to the North 
platform 

Angle 
(radian) 

Conditional, required if sensor 
attitude is provided in reference to 
the platform’s coordinate reference 

system and when the platform’s 
heading information is not provided 

by platform attitude angles or 
rotations angles. 

 

14 Platform Attitude 
Angle Matrix 

Platform attitude angle 
matrix.  

Angles 
(radians) 

Conditional, required when sensor 
attitude is defined in platform CRS.  
This parameter matrix may also be 

replaced by the platform’s roll, pitch, 
and yaw angle parameters (items 

10-12).  Either this matrix or the roll, 
pitch, yaw angles are needed if 

platform attitude is required. 

This parameter set provides a 
matrix of nine angles between the 
three platform CRS axes and the 
three axes of an Earth CRS, in 

the form of {{xX,xY,xZ}, 
{yX,yY,yZ}, {zX,zY,zZ}}, where 

(x,y,z) is platform CRS and 
(X,Y,Z) is an Earth CRS  

 



OGC 10-087 

30 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

 

Table 2  Sensor Metadata Table 

 

ID Parameter Definition Units Obligation Description 

1 Sensor Position, 
X Vector 

Component 

X component of the 
sensor position, either in 
an Earth CRS or in the 

CRS of the platform onto 
which the sensor is 

mount. 

Length 
(meter or 
kilometer) 

Required This parameter provides the X 
coordinate value of sensor. 

2 Sensor Position, 
Y Vector 

Component 

Y component of the 
sensor position, either in 
an Earth CRS or in the 

CRS of the platform onto 
which the sensor is 

mount. 

Length 
(meter or 
kilometer) 

Required This parameter provides the Y 
coordinate value of sensor. 

3 Sensor Position, 
Z Vector 

Component 

Z component of the 
sensor position, either in 
an Earth CRS or in the 

CRS of the platform onto 
which the sensor is 

mount. 

Length 
(meter or 
kilometer) 

Required This parameter provides the 
vertical, Z, coordinate value of 

sensor. 

4 Sensor Line of 
Sight 

The line of sight (LOS) of 
a sensor measured in two 

angles: view angle and 
azimuthal angle (v, ϕ). 

 

Angles 
(radian, 
radian) 

Required if sensor attitude is not 
provided in sensor roll, pitch, yaw 
parameters (items 5-7) and not 

provided in a nine-element sensor 
attitude matrix (item 8). 

This set of two parameters 
provides the direction of senos 

LOS.  The view angle is 
measured from the projection of 
LOS in the XY plane of a CRS, 
either platform or Earth, toward 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

the CRS’ Z axis. The azimuthal 
angle is measured in the CRS’ XY 

plane, from X axis clockwise 
when looking toward the positive 

direction of the X axis.   

5 Sensor Attitude 
Roll angle 

Roll angle of sensor in 
reference to either the 
CRS of its mounting 

platform or an Earth CRS. 

Angle 
(radian) 

Required when neither sensor LOS 
(item 4) nor the nine-angle sensor 
attitude matrix (item 8) is provided.  

This parameter provides sensor 
attitude’s roll angle, which is the 

angle the sensor rotates, in 
reference to its nominal position 

(i.e., when sensor’s CRS is 
aligned with its external reference 

CRS, either platform or Earth 
CRS), along its X axis, positive 
clockwise when looking at the 
positive direction of the X axis.  

6 Sensor Attitude 
Pitch angle 

Pitch angle of sensor in 
reference to either the 
CRS of its mounting 

platform or an Earth CRS. 

Angle 
(radian) 

Required when neither sensor LOS 
(item 4) nor the nine-angle sensor 
attitude matrix (item 8) is provided. 

This parameter provides sensor 
attitude’s pitch angle, which is the 

angle the sensor rotates, in 
reference to its nominal position 

(i.e., when sensor’s CRS is 
aligned with its external reference 

CRS, either platform or Earth 
CRS), along its Y axis, positive 
clockwise when looking at the 
positive direction of the Y axis. 

7 Sensor Attitude 
Yaw angle 

Yaw angle of sensor in 
reference to either the 
CRS of its mounting 

platform or an Earth CRS. 

Angle 
(radian) 

Required when neither sensor LOS 
(item 4) nor the nine-angle sensor 
attitude matrix (item 8) is provided. 

This parameter provides sensor 
attitude’s yaw angle, which is the 

angle the sensor rotates, in 
reference to its nominal position 

(i.e., when sensor’s CRS is 
aligned with its external reference 

CRS, either platform or Earth 
CRS), along its Z axis, positive 
clockwise when looking at the 



OGC 10-087 

32 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

positive direction of the Z axis. 

8 Sensor Attitude 
Angle Matrix 

Sensor attitude angle 
matrix.  

Angles 
(radians) 

Conditional, required when neither 
sensor line of sight (item 4) nor 

sensor roll, pitch, yaw parameters 
(items 5-7) are provided. 

This parameter set provides a 
matrix of nine angles between the 
three sensor CRS axes and the 

three axes of the CRS the sensor 
is located (either platform CRS or 
an Earth CRS).  The matrix is in 

the form of {{xX,xY,xZ}, 
{yX,yY,yZ}, {zX,zY,zZ}}, where 

(x,y,z) is sensor CRS and (X,Y,Z) 
is either platform CRS or an Earth 

CRS  

9 Gimbal Attitude 
Roll Angle 

The roll angle of gimbal  Angle 
(radian) 

Conditional, required if gimbal is 
used to mount the sensor and the 

sensor’s attitude is defined in 
relation to the gimbal. Gimal attitude 
may also be provided in the form of 

a nine-element matrix (item 12). 

This parameter provides the roll 
angle of a gimbal on to which a 

sensor is mount. 

10 Gimbal Attitude 
Pitch Angle 

The pitch angle of gimbal. Angle 
(radian) 

Conditional, required if gimbal is 
used to mount the sensor and the 

sensor’s attitude is defined in 
relation to the gimbal. Gimal attitude 
may also be provided in the form of 

a nine-element matrix (item 12). 

This parameter provides the pitch 
angle of a gimbal on to which a 

sensor is mount. 

11 Gimbal Attitude 
Yaw Angle 

The yaw angle of gimbal Angle 
(radian) 

Conditional, required if gimbal is 
used to mount the sensor and the 

sensor’s attitude is defined in 
relation to the gimbal. Gimal attitude 
may also be provided in the form of 

a nine-element matrix (item 12). 

This parameter provides the yaw 
angle of a gimbal on to which a 

sensor is mount. 

12 Gimbal Attitude Gimbal attitude angle Angles Conditional, required if gimbal is 
used to mount the sensor and the 

This parameter set provides a 
matrix of nine angles between the 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

Angle Matrix matrix.  (radians) sensor’s attitude is defined in 
relation to the gimbal. Gimal attitude 

may also be provided by its roll, 
pitch and yaw parameters (items 9-

11). 

three gimbal CRS axes and the 
three axes of the CRS the gimbal 
is located (either platform CRS or 
an Earth CRS).  The matrix is in 

the form of {{xX,xY,xZ}, 
{yX,yY,yZ}, {zX,zY,zZ}}, where 

(x,y,z) is gimbal CRS and (X,Y,Z) 
is either platform CRS or an Earth 

CRS  

13 Calibrated 
Effective Focal 

Length 

The calibrated effective 
focal length  

Length (mm) Required This parameter provides 
information on focal length. For 
fixed lens this is the calibrated 

effective focal length.  For zoom 
length, this is the actual focal 

length used when a video image 
frame is recorded. 

14 Horizontal 
Spatial 

Resolution 

The number of pixel 
elements along the 
sensor’s horizontal 

direction. 

Int (unitless) Required This parameter provides number 
of pixels along the sensor’s 

horizontal direction (when sensor 
is at nominal attitude). 

15 Vertical Spatial 
Resolution 

The number of pixel 
elements along the 

sensor’s vertical direction. 

Int (unitless) Required This parameter provides number 
of pixels along the sensor’s 

vertical direction (when sensor is 
at nominal attitude). 

16 Horizontal Field 
of View 

The field of view, 
measured at an angle, 

across the sensor’s  
horizontal direction. 

Angle 
(radian) 

Required This parameter provides sensor’s 
field of view along its horizontal 

direction (when sensor is at 
nominal attitude). 

17 Vertical Field of 
View 

The field of view, 
measured at an angle, 

across the sensor’s 

Angle 
(radian) 

Required This parameter provides sensor’s 
field of view along its vertical 
direction (when sensor is at 



OGC 10-087 

34 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

vertical direction. nominal attitude). 

 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

 

Table 3  Fitting Metadata Table 

 

ID Parameter Definition Units Obligation Description 

1 Dimension 

Name 

The dimension 

names 

representing 

dependent and 

independent 

variables 

CharacterStr

ing 

(unitless) 

Required This parameter provides the names of dimensions representing 

dependent and independent variables in the fitting function.  The 

dependent variables are usually, i.e., in the forward mapping 

approach, the target CRS axis names (e.g., latitude, longitude) and 

the independent variables the names of the CRS of the imagery to be 

geopositioned or co-registered (e.g., line sample).  

2 Power The power of 

polynomial 

Integer 

(unitless) 

Required This parameter provides the power of the fitting polynomial function. 

3 Coefficients Polynomial 

coefficients 

Real 

(unitless) 
Required This parameter provides the coefficient for each term in the 

polynomial fitting function. 

4 Scale The scale factor 

to an 

independent 

variable. 

Real  

(unitless) 

Optional This parameter provides the scale factor to an independent variable.     

5 Translation The translation 

coefficient. 

Real 

(unitless) 

Optional This parameter provides the translation or offset coefficient to an 

independent variable. 

6 Numerator/den

ominator 

An identifier for 

numerator/deno

Integer 

(unitless) 

Conditional, 

required for 

This parameter identifies, in rational function fitting, a polynomial 

either being numerator or being denominator. 



OGC 10-087 

36 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

identification minator  rational 

function 

fitting 

 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

Table 4  Control Point Metadata Table 

 

ID Parameter Definition Units Obligation Description 

1 Target 

CRS 

The identifier for 

the target CSR. 

URI (unitless) Required This parameter provides the identification of the target 

CRS to which an MI is to be rectified or co-registered. 

2 Number 

of control 

points 

The number of 

control points 

Integer (unitless) Required This parameter provides total number of control points 

available for rectification or registration. 

3 Control 

point 

position in 

target 

CRS 

The position 

coordinate 

values of control 

points in target 

CRS. 

DirectPosition Required This parameter provides an array of direction position 

values of the control points in the target CRS. 

4 Control 

point 

position in 

source 

image 

The position 

coordinate 

values of control 

points in source 

image. 

DirectPosition Required This parameter provides an array of direction position 

values of the control points in the source image, usually 

the row/column (or line/sample) numbers.     

5 Quality The quality of 

control points. 

Real Optional This parameter provides the quality covariance matrix 

of the control points. 

 



OGC 10-087 

38 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

Table 5  Radiometric and Environmental Metadata  

 

ID Parameter Definition Units Obligation Description 

1 Calibration 

scale factor 

The scale factor 

digital number to 

radiance conversion. 

Real  

(Radiance unit,  

e.g., Wsr
-1

m
-2

) 

Optional This parameter provides the scale factor in converting image 

digital number to radiance 

(e.g., Radiance=scale*DN+offset) 

2 Calibration 

offset value 

The offset value in 

digital number to 

radiance conversion. 

Real  

(Radiance unit, 

e.g., Wsr
-1

m
-2

) 

Optional This parameter provides the offset value in converting 

image digital number to radiance. 

(e.g., Radiance=scale*DN+offset) 

3 Ambient 

illumination 

The ambient 

illumination of the 

scene recorded. 

Real  

(Radiance unit) 
Optional This parameter provides illumination on the scene recorded 

by in a motion imagery. 

4 Cloud percent The cloud percentage 

in the sky. 

Real  

(unitless) 
Optinal This parameter provides an estimation of the cloud 

percentage in the sky during the recording period.     

5 DTM The digital terrain 

model of the scene. 

Real 

(length) 
Optional This parameter provides the digital terrain model data, 

usually in gridded format of the scene, in the area being 

imaged.  Ideally the DTM also cover the location of the 

sensor and the space between sensor and the scene. 

6 Wind speed The wind speed 

during recording. 

Real  

(Velocity) 
Optional This parameter provides the wind speed during the time of 

recording, ideally including the direction of the wind. 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

7 Humidity The atmospheric 

humidity.  

Real 

(unitless, i.e., 

percentage, or 

humidity unit) 

Optional This parameter provides the humidity value for the scene 

during the recording time period. 

8 Temperature Surface or air 

temperature. 

Real 

(temperature unit) 
Optional This parameter provides the temperature, either air 

temperature (together with height) or at the ground surface. 

9 Soil moisture The soil moisture 

value. 

Real 

(relative or 

absolute moisture 

unit) 

Optional This parameter provides the estimation or measurement of 

soil moisture, if bare soil is shown in the imagery and is a 

subject of observation.  

1

0 

Land 

use/cover 

type 

The land use and/or 

land cover type. 

CharacterString 
Optional This parameter provides the land use and/or land cover 

(LULC) type of the scene. Ideally the LULC information is 

provided in a gridded format.  If LULC grid is not available, 

a description of the dominant LULC is also helpful. 

 

* Radiometric metadata include sensor operation, such as aperture and shutter speed, are not included in this table.



OGC 10-087 

40 Copyright © 2010 Open Geospatial Consortium, Inc. 
 

Table 6  Discovery and retrieval metadata 

 

ID Parameter Definition Units Obligation Description 

1 Identifier The identifier 

of a motion 

imagery. 

CharacterString Required This parameter provides a unique identifier of a motion imagery. 

2 Image start 

time 

The start time 

of the image 

recording. 

DateTime Required This parameter provides the start time of the image being recorded. 

3 Image end 

time 

The end time 

of the image 

recording. 

DateTime Required This parameter provides the end time of the image being recorded. 

4 Geographic 

extent 

The 

geographic 

coverage of 

the imagery. 

Real 

(length) 

Required This parameter provides the spatial coverage of the imagery. The 

values should be provided together with a 2D or 3D CRS.  At least 

four values are needed (i.e., 2D CRS)     

5 Mission 

description 

A description 

of the imaging 

mission 

CharacterString Optional This parameter provides a description, in free text, of the purpose 

of the motion imagery recording mission.  

6 Sensor 

identification 

Identification 

of the sensor. 

CharacterString Optional This parameter provides the identification information of the 

sensor used in the image recording. 

7 Sensor type The type of CharacterString Optional This parameter tells the type of the sensor used in recording. 



OGC 10-087 

Copyright © 2010 Open Geospatial Consortium, Inc.           41 
 
 

sensor 

8 Sensor 

description 

Description of 

the sensor. 

CharacterString Optional This parameter provides a description of the sensor used in 

recording the imagery. 

9 Sensor 

geomerty 

The 

orientation of 

the sensor. 

CharacterString Optional This parameter provides a description of the general orientation of 

the sensor, such as north, east, and southeast. 

 

 

 

 

 

 

 

 



OWS 7 Motion Imagery Discovery and Retrieval Engineering Report OGC 10-087 

 

Copyright © 2010 Open Geospatial Consortium, Inc. 42 
 

Bibliography 

Anderson, J., Hardy, E., Roach, J., and Witmer, R., 1976, A Land use and land cover 

classification system for use with remote sensor data, Geological Survey Professional 

Paper 964, United States Government Printing Office, Washington DC, 1976, 41pp. 

DoD, 2009, Motion imagery standards profile (MISP) Version 5.4, Online: 

http://www.gwg.nga.mil/misb/docs/MISP54.pdf (accessed on 03/11/2010) 

ISO, 2008, Geographic information — Metadata — Part 2: Extensions for imagery and 

gridded data, ISO 19115-2, 54pp. 

ISO, 2009, Geographic information — Image sensor model for geopositioning, ISO 

19130,  150pp. 

ISO, 2003, , Geographic information — Metadata, ISO 19115, 149pp. 

 

http://www.gwg.nga.mil/misb/docs/MISP54.pdf

	Introduction
	Scope
	Document contributor contact points
	Revision history
	Future work

	References
	Terms and definitions
	Conventions
	Topic overview
	Motion Imagery Metadata
	Introduction
	Geometrical metadata for physical sensor model
	Introduction
	Platform metadata
	Sensor operation and mounting metadata

	Fitting function metadata
	Introduction
	Polynomial metadata

	Control point metadata
	Introduction
	Control point metadata

	Radiometric metadata
	Introduction
	Radiometric metadata items

	Environmental metadata
	Introduction
	Environmental metadata

	Discovery and retrieval metadata
	Introduction
	Discovery and retrieval metadata


	UML Diagrams for Motion Imagery Metadata
	Introduction
	Platform metadata UML diagrams
	Sensor metadata UML diagrams
	Functional fitting and control point UML diagrams
	Environmental metadata UML diagram
	Motion discovery and retrieval metadata UML diagram

	Motion Imagery encoding XML scheme
	Summary and discussion

