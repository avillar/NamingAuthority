
Open GIS Consortium
35 Main Street, Suite 5
Wayland, MA 01778

Telephone: +1-508-655-5858
Facsimile: +1-508-655-2237

Editor:
Telephone: +1-703-830-6516
Facsimile: +1-703-830-7096

ckottman@opengis.org

The OpenGIS™ Abstract Specification
Topic 7: The Earth Imagery Case

Version 4

OpenGIS™ Project Document Number 99-107.doc



The OpenGIS™ Abstract Specification

Copyright © 1999, Open GIS Consortium, Inc.

NOTICE

The information contained in this document is subject to change without notice.

The material in this document details an Open GIS Consortium (OGC) specification in accordance with the license and
notice set forth on this page. This document does not represent a commitment to implement any portion of this
specification in any companies’ products.

While the information in this publication is beleived to be accurate, the Open GIS Consortium makes no warranty of
any kind with regard to this material including but not limited to the implied warranties of merchantability and fitness
for a particular purpose. The Open GIS Consortium shall not be liable for errors contained herein or for incidental or
consequential damages in connection with the furnishing, performance or use of this material. The information
contained in this document is subject to change without notice.

The Open GIS Consortium is and shall at all times be the sole entity that may authorize developers, suppliers and
sellers of computer software to use certification marks, trademarks, or other special designations to indicate compliance
with these materials.

This document contains information which is protected by copyright. All Rights Reserved. Except as otherwise
provided herein, no part of this work may be reproduced or used in any form or by any means (graphic, electronic, or
mechanical including photocopying, recording, taping, or information storage and retrieval systems) without the
permission of the copyright owner. All copies of this document must include the copyright and other information
contained on this page.

The copyright owner grants member companies of the OGC permission to make a limited number of copies of this
document (up to fifty copies) for their internal use as a part of the OGC Technology Development process.



The OpenGIS™ Abstract Specification Page i

Volume 7: The Earth Imagery Case (99-107.doc)

Revision History

Date Description
31 March 1999 Bring forward 98-107r1 as 99-107; update for new document template and 1999 copyrights; move

former section 2.3 to section 1.2; other minor editorial updates (figure and table numbering, etc).



The OpenGIS™ Abstract Specification Page ii

Volume 7: The Earth Imagery Case (99-107.doc)

This page is intentionally left blank.



The OpenGIS™ Abstract Specification Page iii

Volume 7: The Earth Imagery Case (99-107.doc)

Table of Contents

1. Introduction.............................................................................................. 1
1.1. The Abstract Specification ..................................................................................1
1.2. Introduction to The Earth Imagery Case...........................................................1
1.3. References for Section 1.......................................................................................1

2. The Essential Model for The Earth Imagery Case............................... 3
2.1. Project Worlds for Images...................................................................................3
2.2. Coverage Generation Functions for Earth Images ...........................................3

2.2.1. Examples of Image Generation Complexities .......................................................................3
2.2.2. The Central Problem of Images: the Image Generation Function.......................................4

2.3. References for Section 2.......................................................................................4

3. Abstract Model for The Earth Imagery Case ....................................... 5
3.1. References for Section 3.......................................................................................5

4. Future Work............................................................................................. 6

5. Well Known Structures ........................................................................... 7

6. Appendix A. White Paper on Earth Image Geometry Models ........... 8
6.1. Introduction ..........................................................................................................8

6.1.1. Common Properties of Image Geometry Models...................................................................8
6.1.2. Rigorous Image Geometry Models.........................................................................................9
6.1.3. Real-Time Image Geometry Models ....................................................................................10

6.2. Polynomials Image Geometry Models ..............................................................11
6.3. Grid Interpolation Image Geometry Model.....................................................12

6.3.1. Grid Points ............................................................................................................................12
6.3.2. Grid Points Image Support Data..........................................................................................12
6.3.3. Grid Model Accuracy ...........................................................................................................12
6.3.4. Size of Image Support Data .................................................................................................12
6.3.5. Tri-linear Interpolation Mathematics..................................................................................13
6.3.6. Advantages and Disadvantages............................................................................................14

6.4. Ratios of Polynomials .........................................................................................14
6.4.1. Ratios of Polynomials Mathematics.....................................................................................15
6.4.2. Advantages and Disadvantages............................................................................................15

6.5. Universal Real-time Image Geometry Model ..................................................16
6.5.1. Universal Real-time Image Geometry Model Mathematics ................................................16

6.5.1.1. Linear Polynomials .....................................................................................................................19
6.5.1.2. Image Model Section ..................................................................................................................19
6.5.1.3. Normalized Ground Coordinates.................................................................................................20
6.5.1.4. Ratios of Polynomials .................................................................................................................20
6.5.1.5. Un-Normalized Image Coordinates.............................................................................................21
6.5.1.6. Correction Functions ...................................................................................................................21
6.5.1.7. Fitting Errors ...............................................................................................................................21
6.5.1.8. Ground Accuracy Estimates ........................................................................................................22



The OpenGIS™ Abstract Specification Page iv

Volume 7: The Earth Imagery Case (99-107.doc)

6.5.1.9. Image to Ground Computations ..................................................................................................22
6.5.1.10. Ground Viewing Angle Computations ......................................................................................22

6.5.2. Universal Real-time Image Geometry Support Data...........................................................22
6.5.2.1. Common Header Fields...............................................................................................................23
6.5.2.2. Universal Image Geometry Model Header..................................................................................23
6.5.2.3. Polynomial Records ....................................................................................................................24
6.5.2.4. Correction Table Records............................................................................................................25
6.5.2.5. Monoscopic Accuracy Estimates Records...................................................................................25
6.5.2.6. Stereoscopic Accuracy Estimates Records..................................................................................26

6.5.3. Other Image Support Data ...................................................................................................27
6.5.3.1. Image Collection Data Record ....................................................................................................27
6.5.3.2. Ground Point Record...................................................................................................................28
6.5.3.3. File Header Record .....................................................................................................................29

6.6. Future Work .......................................................................................................30
6.7. Appendices ..........................................................................................................30

6.7.1. FPE Generation of Universal Image Geometry Model.......................................................30
6.7.2. NITF Formatting of Image Support Data...........................................................................30

6.7.2.1. Tagged Record Extensions..........................................................................................................30
6.7.2.2. Universal Image Geometry Model Header..................................................................................31
6.7.2.3. Polynomial Records ....................................................................................................................32
6.7.2.4. Correction Table Records............................................................................................................33
6.7.2.5. Monoscopic Accuracy Estimates Records...................................................................................33
6.7.2.6. Stereoscopic Accuracy Estimates Records..................................................................................34
6.7.2.7. Image Collection Data Record ....................................................................................................34
6.7.2.8. Ground Point Record...................................................................................................................36
6.7.2.9. USMSD File Header Record.......................................................................................................37

6.7.3. References for Appendix A...................................................................................................37



The OpenGIS™ Abstract Specification Page 1

Volume 7: The Earth Imagery Case (99-107.doc)

1. Introduction

1.1. The Abstract Specification
The purpose of the Abstract Specification is to create and document a conceptual model sufficient
enough to allow for the creation of Implementation Specifications. The Abstract Specification
consists of two models derived from the Syntropy object analysis and design methodology [1].

The first and simpler model is called the Essential Model and its purpose is to establish the
conceptual linkage of the software or system design to the real world. The Essential Model is a
description of how the world works (or should work).

The second model, the meat of the Abstract Specification, is the Abstract Model that defines the
eventual software system in an implementation neutral manner. The Abstract Model is a description
of how software should work. The Abstract Model represents a compromise between the paradigms
of the intended target implementation environments.

The Abstract Specification is organized into separate topic volumes in order to manage the
complexity of the subject matter and to assist parallel development of work items by different
Working Groups of the OGC Technical Committee. The topics are, in reality, dependent upon one
another each one begging to be written first. Each topic must be read in the context of the entire
Abstract Specification.

The topic volumes are not all written at the same level of detail.  Some are mature, and are the basis
for Requests For Proposal (RFP). Others are immature, and require additional specification before
RFPs can be issued. The level of maturity of a topic reflects the level of understanding and
discussion occurring within the Technical Committee. Refer to the OGC Technical Committee
Policies and Procedures [2] and Technology Development Process [3] documents for more
information on the OGC OpenGIS™ standards development process.

Refer to Topic Volume 0: Abstract Specification Overview [4] for an introduction to all of the topic
volumes comprising the Abstract Specification and for editorial guidance, rules and etiquette for
authors (and readers) of OGC specifications.

1.2. Introduction to The Earth Imagery Case
There are many initiatives addressing portions of the overall scope of this Topic Volume.
Important among them is the ISO TC/211 initiative to add a work item to address raster and image
data types.  OGC and ISO TC/211 intend to work closely to achieve common specifications.

This Topic Volume, Earth Imagery, will provide essential and abstract models for technology that
is already used widely (but not interoperably) across the GIS landscape.  This technology properly
depends on the more general technology that  supports Coverages.

A Request for Proposals for Simple Coverages is expected to be released in early 1998.  Responses
to that request are expected to include significant Earth Image functionality, especially for
orthophotos.  This Topic Volume will be updated upon acceptance of Coverage implementation
specifications to keep it a consistant with Coverage technology.

Further progress toward Earth Imagery specifications will be made when Coverage technology
underpinnings are in place.

Note: The remainder of this document is a White Paper, and not yet a part of the formal Abstract
Specification

Editor’s Note: Version 3 of this topic (Topic 7, Earth Imagery) differed from Version 2 by only
minor editorial changes.

1.3. References for Section 1
[1] Cook, Steve, and John Daniels, Designing Objects Systems: Object-Oriented Modeling with

Syntropy, Prentice Hall, New York, 1994, xx + 389 pp.

[2] Open GIS Consortium, 1997. OGC Technical Committee Policies and Procedures, Wayland,
Massachusetts. Available via the WWW as <http://www.opengis.org/techno/development.htm>.



The OpenGIS™ Abstract Specification Page 2

Volume 7: The Earth Imagery Case (99-107.doc)

[3] Open GIS Consortium, 1997. The OGC Technical Committee Technology Development Process,
Wayland, Massachusetts. Available via the WWW as
<http://www.opengis.org/techno/development.htm>.

[4] Open GIS Consortium, 1999.  Topic 0, Abstract Specification Overview, Wayland, Massachusetts.
Available via the WWW as <http://www.opengis.org/techno/specs.htm>.



The OpenGIS™ Abstract Specification Page 3

Volume 7: The Earth Imagery Case (99-107.doc)

2. The Essential Model for The Earth Imagery Case

2.1. Project Worlds for Images
A commonly encountered Project World is portion of reality within the viewing cone of a camera,
where only the spectral radiance of items in that viewing cone is contemplated.  This is the Project
World in ordinary photography.  Here, we do not see the red wagon; we only see the red.

Notice that in Topic 5, The Open GIS Feature, it was common to “see” a Project World in a cartoon
fashion, so that modeling it with geometry would be straightforward.  This mental model is still
appropriate for many coverage applications.  When using a camera, however, the lens creates the
geometries in the image without effort, so the “cartooning” abstraction is not needed.

For ordinary photography, the coverage generation function, G, is a central projection.  We will
discuss this in more detail in section 3.10.2, below.

Editor’s Note: This is a zombie reference to an unknown section. Not sure what section it should
refer to.

2.2. Coverage Generation Functions for Earth Images
Figure 2-1 contrasts the general setting of a coverage with the particular case of an Earth Image.
Note that the Project World is the Earth as seen through the “eyes” of a remote sensing device.  The
Image Generation function could involve any of the mathematical complexities of the next section.
The Coverage Extent now reveals itself as the image space.  Each point (or each pixel) on the
image maps to a value in a Pixel Range.

r

c

Project 
World

Coverage
Generation
Function

Coverage
Extent

Schema
Mapping Range

value 1
value 2

G
R

Schema

r

c

Earth 
Image
Generation
Function

Image
Grid

Pixel
Mapping Range

value 1
value 2

G
R

Pixel

Figure 2-1. The Earth Image Special Case of a Coverage

The function, R, could be defined at fractional pixels.  Alternatively, it could be defined only at
pixel locations (say, centers).  Both types of R are acceptable.

2.2.1. Examples of Image Generation Complexities
The coverage generation function, G, can be complex, taking into account such factors as

• motion compensation (allowing a moving perspective center with a push-broom sensor)

• terrain relief displacement and camera distortion

• atmospheric and air-water-interface defraction



The OpenGIS™ Abstract Specification Page 4

Volume 7: The Earth Imagery Case (99-107.doc)

• the theory of conformal transformations for cartographic projections

• the theory of phase history processing for synthetic aperture radar

• the composition of several factors, perhaps caused by the iterative use of images and
coverages as the Project World for new images and coverages

• other image formation technologies

For those coverages using the visible earth surface as the Project World, and using photography (or
digital imaging) as the coverage generation process,  the study of G is called photogrammetry (the
study of mapping object space into image space).  In fact, the notion of coverage includes an even
larger part of photogrammetry.  A  photograph (or a digital image) may itself be used as the Project
World, and in this setting, G can map the photograph coordinates into those of an orthophoto.
Another G could model the geometry involved in photomosaicking.

2.2.2. The Central Problem of Images: the Image Generation Function
The remarks above demonstrate that the key challenge in interoperability of images is the
establishment of well known structures for the representation of stored image generation functions.

2.3. References for Section 2
[1] OpenGIS™ Abstract Specification, OpenGIS™ Project Documents 99-100 through 99-116,

available through www as <http://www.opengis.org/techno/specs.htm>.



The OpenGIS™ Abstract Specification Page 5

Volume 7: The Earth Imagery Case (99-107.doc)

3. Abstract Model for The Earth Imagery Case
The Abstract Model for Earth Imagery is TBD.

3.1. References for Section 3
[2] OpenGIS™ Abstract Specification, OpenGIS™ Project Documents 99-100 through 99-116,

available through www as <http://www.opengis.org/techno/specs.htm>.



The OpenGIS™ Abstract Specification Page 6

Volume 7: The Earth Imagery Case (99-107.doc)

4. Future Work
We need WKS for image stored functions, similar to or the same as those in the Section 6 “White
Paper.”



The OpenGIS™ Abstract Specification Page 7

Volume 7: The Earth Imagery Case (99-107.doc)

5. Well Known Structures
WKS for Earth Images are TBD.



The OpenGIS™ Abstract Specification Page 8

Volume 7: The Earth Imagery Case (99-107.doc)

6. Appendix A. White Paper on Earth Image Geometry Models

6.1. Introduction

Note: Each image geometry model presented in this White Paper provides technology for the
representation of Image Generation Functions as stored functions.

This white paper presents four different image geometry models suitable for real-time use, with
emphasis on a “Universal Real-time Image Geometry Model.”  This Universal Real-time Image
Geometry Model is the new NIMA standard real-time image geometry model. This white paper is
largely based on, and supersedes, OpenGIS Project Documents 97-003 and 96-012.

An image geometry model is needed to determine the correct ground position of a point visible in
an image of the earth. An image geometry model relates 3–D ground positions to the corresponding
2–D image positions. Such an image geometry model (partially) defines the coverage generation
function G defined by Cliff Kottman in OpenGIS Project Documents 96-024R2 and 97-002. An
image geometry model defines G for the case where a feature is an image coverage or family of
image coverages.

An image geometry model is alternately called an image sensor model, sensor model, or image
mathematical model. The term “sensor” is often used when the image is digital; the word “camera”
is usually used when the image is hardcopy. The data used by such an image geometry model is
often called image support data.

This paper primarily discusses high accuracy geometry models for general images. Much simpler
geometry models are adequate for images that have been orthorectified, or when low accuracy is
sufficient. Also, much simpler geometry models can provide medium horizontal accuracy for
rectified or nearly-vertical images, when the imaged ground is relatively flat.

Two broad categories of high accuracy image geometry models are used. “Rigorous” image
geometry models are sometimes used. However, rigorous models are complex and usually require
relatively long computation times. For real-time applications, simpler image geometry models are
often used, requiring much shorter computation times. Fast computation permits these models to be
used in real-time, where perhaps 60 new points must be transformed each second. Fast computation
is also useful for other image operations, such as rectification, orthorectification, and perspective
scene generation.

This paper discusses four different image geometry models suitable for real-time use:

• Polynomial model

• Grid interpolation model

• Ratios of polynomials model

• Universal real-time image geometry model
The presented “Universal Real-time Earth Image Geometry Model” is universal in the sense that
we think it can accurately represent the geometry of all known types of images and image sensors.
These image sensor types include frame, panoramic, pushbroom, whiskbroom, and Synthetic
Aperture Radar (SAR) sensors. This model can accurately represent images from these sensor types
for purposes of image exploitation. This universal real-time model is an extension of the ratios of
polynomials model, and employs interpolation of high-order correction functions. The ratios of
polynomials model is an extension of the polynomial model.

The four listed real-time image geometry models are not suitable for direct adjustment by analytical
triangulation or most adjustment methods. They are not directly adjustable because accurate values
of ground position error estimates cannot be easily computed, to be used for the accuracy of ground
points computed using the adjusted image geometry model. The rigorous image geometry models
are suitable for adjustment by analytical triangulation and most other adjustment methods.

6.1.1. Common Properties of Image Geometry Models
Most image geometry models share some similar properties, including those discussed in the
following paragraphs.



The OpenGIS™ Abstract Specification Page 9

Volume 7: The Earth Imagery Case (99-107.doc)

Communication of Parameter Values. All image geometry models require that values for the model
parameters be communicated. Parameter values must be communicated from the system or point
where these values are determined, to the (often multiple) systems where the associated image is
exploited. In most cases, these parameter values are communicated with the digital image data, in
the same file or in an associated file.

Error Estimates. Many image geometry models include estimates of the errors in the ground
positions (or image positions) that can be computed using that model. These error estimates may be
direct model parameters, or model parameters can be used to compute different error estimates for
different ground and image positions.

Image Support Data. The data that includes the values of these image geometry model parameters
is often called image support data. This image support data often includes values for other
parameters, not needed or used for defining the ground-image geometry. Some of this other support
data is needed or useful for image interpretation, such as the sun direction. Image geometry support
data is one of several categories of image metadata, that may also include:

1. Data format specification metadata, for image data and all metadata

2. Image radiance, enhancement, and classification metadata, including radiance processing history

3. Data source and availability metadata

4. Other metadata

Fractional Pixel Positions. When image positions are computed, the results are usually pixel
position indices: row number and column number in the 2-D array of digital image pixels. Pixel
position indices are usually calculated in floating point, giving row and column positions in both
integer and fractional pixel spacings. Fractional pixel position indices are rounded or truncated to
the nearest integer when needed. Rounding is appropriate if integer pixel indices are assumed to
refer to the center of the pixel area. Truncation is appropriate if integer pixel indices are assumed to
refer to the corner of the pixel area (half way between the centers of adjacent pixels).

Note: This proposal uses the terms of “row” and “column” for digital image pixel position indices.
Alternatively, the terms “line” and “sample” could be used, with the same meanings. We think the

Computation Directions. Image exploitation often uses computation in two directions: from image
coordinates to ground coordinates and/or from ground coordinates to image coordinates. For
example, computation from image coordinates to ground coordinates can be used to determine the
ground coordinates of a feature point, from its position measured in a monoscopic image.
Computation from ground coordinates to image coordinates is more frequently used in our
experience, for operations including:

1. Elevation and feature extraction from stereoscopic images

2. Image rectification, orthorectification, and perspective scene generation

3. Generation of graphics overlays on images

Many image geometry models directly model the transformation in only one direction between
ground coordinates and image coordinates. That is, some directly model the transformation from 3–
D ground coordinates to 2–D image coordinates. Other image geometry models define the
transformation from 2–D image coordinates to 3–D ground coordinates. In this case, the ground
elevation is usually a software input, in addition to the two image coordinates. Alternatively, two or
more stereoscopic images can be used, and the software inputs are the image coordinates of the
same ground point in multiple images.

A few image geometry models directly model the transformations in both directions. When an
image geometry model directly models the transformation in only one direction, the associated
software usually also supports computations in the reverse direction. Computation in the reverse
direction is often implemented by iteratively executing the forward direct model.

6.1.2. Rigorous Image Geometry Models
The traditional approach to image geometry mathematical models is to separately model most of
the physical elements of the image sensor and its environment. Such an image geometry model is



The OpenGIS™ Abstract Specification Page 10

Volume 7: The Earth Imagery Case (99-107.doc)

often called a “rigorous” model. A rigorous image geometry model can be nearly-optimally
adjusted, by analytical triangulation and other adjustment methods. Furthermore, accurate estimates
can be computed of the accuracy of ground positions computed using such an image geometry
model. Most rigorous image geometry models also have the advantage of high modeling accuracy,
often a fraction of one pixel spacing.

Optimized adjustment of a rigorous image geometry model is possible because most parameter
value errors are statistically uncorrelated or are simply correlated, since each parameter has
physical significance. Some parameter values can be determined once during camera calibration,
such as the camera principal distance (or focal length) and lens distortion corrections. Other
parameter values differ for each image, and thus must be (approximately) measured at the time of
image collection and/or (usually) subsequently adjusted or computed. Such image specific
parameters often include the 3-D sensor position coordinates and 3-D sensor attitude angles at the
time of image collection. Still other parameters are often used to model atmospheric refraction,
earth curvature, film distortion, and other factors affecting the image geometry.

However, a rigorous image geometry model usually has the disadvantages:

1. Model is mathematically complex, requiring complex software with long execution times.
Furthermore, development of such software requires considerable knowledge of both mathematics
and image sensor physics.

2. Model uses values of many different parameters, which must be correctly communicated from
their source to all points of use.

3. Software must be changed for each different image sensor, since the model includes effects
peculiar to a small range of sensors, and excludes effects not applicable to those few sensors.

4. Largely separate software is used for each image geometry model that is handled by an image
exploitation system or software package, and selection of the proper software can be difficult or
erroneous.

5. Software must be developed and changed in the many different systems and software packages
that exploit images, to accommodate a new or modified image sensor. If uniform results are desired
from exploitation of the same image at different locations, configuration management of the image
geometry models is required.

6.1.3. Real-Time Image Geometry Models
When an image geometry model is needed in a real-time image exploitation environment, a simpler
real-time image geometry model is often used to avoid long software execution times. Several
alternative real-time image geometry models are presented in this white paper.

Each system or software using a real-time image geometry model often computes its own model
parameter values, by using the appropriate rigorous image geometry model. That is, a rigorous
image geometry model is used to compute corresponding image and ground positions at a grid of
many points. In many cases, this grid is a 3–D grid in ground coordinates. The polynomial and/or
other functions for such a real-time model are then fit to the points in this grid. Estimates of the
additional errors introduced by the real-time image geometry model are often computed. However,
estimates of the total errors in the real-time image geometry model are rarely computed, combining
the additional errors with the errors in the rigorous model used.

Performing these point computations (and perhaps fitting polynomial functions) requires
computation time before real-time operation can start. These preliminary computations also require
software in addition to the rigorous image geometry model software, and that software retains all
the disadvantages discussed above for rigorous geometry models.

When each image exploitation system does its own fitting, each system is free to define any real-
time image geometry model that meets that system’s execution time and accuracy requirements.
However, each system will then produce data with slightly different errors (and different error
estimates). These error differences make overall enterprise error analysis and diagnosis more
difficult.

Alternatively, one system could compute one real-time image geometry model to be used by
several other systems. Such single computation has rarely been done, except for the ratios-of-
polynomials model discussed below.



The OpenGIS™ Abstract Specification Page 11

Volume 7: The Earth Imagery Case (99-107.doc)

6.2. Polynomials Image Geometry Models
A frequent approach to real-time image geometry models is to use polynomial functions (instead of
rigorous models). That is, two polynomial functions are used to compute the image row and
column position corresponding to a ground position. Both of these polynomial functions are of
three ground coordinates, such as latitude, longitude and height or elevation. For example, the
polynomial functions can have the form:

r = a ijk xn
i

k =0

m3

∑
j=0

m2

∑
i=0

m1

∑ yn jznk

c = b ijk xn
i

k =0

n3

∑
j =0

n2

∑
i=0

n1

∑ yn jznk

Where:

r = Row index of pixel in image

c = Column index of pixel in image

x = East-West position of point on ground

y = North-South position of point on ground

z = Height or elevation of point on ground

aijk, bijk = Polynomial coefficients
The maximum powers of each ground coordinate (m1, m2, m3, n1, n2, and n3) are often limited.
For example, each maximum power may be 2 or 3. Furthermore, some products of powers may not
be allowed. For example, the polynomial coefficients may be assumed to be zero whenever i + j + k
> 2.

Since polynomial models sacrifice accuracy, multiple polynomials are often used, using each
polynomial in a different section of the image or ground space. Such sectioning of the image
geometry has been done in a wide variety of ways.

The advantages of a Polynomials Image Geometry Model are simplicity and computation speed.
However, use of low order polynomials usually produces low fitting accuracy, such as errors of
many pixel spacings. Using low order polynomials is thus often derisively called “rubber sheeting.”
The errors are often many pixel spacings when polynomials are fit to a fairly small number of
points with questionable accuracy.

However, use of low order polynomials is quite accurate when modeling a digitally orthorectified
image. In that case, this model can have zero modeling error:

r = ao + ax * x + ay * y

c = bo + bx * x + by * y
Where:

r = Row index of pixel in image

c = Column index of pixel in image

x = East-West position of point on ground

y = North-South position of point on ground



The OpenGIS™ Abstract Specification Page 12

Volume 7: The Earth Imagery Case (99-107.doc)

ao, ax, ay, bo, bx, by = Polynomial coefficients

6.3. Grid Interpolation Image Geometry Model
Another approach to real-time image geometry models is to use interpolation between a number of
stored point solutions. The point positions are often arranged in a 3-D (or 2-D) grid in ground
coordinates. The image coordinates (row and column indices) for each grid point are computed
using some rigorous image geometry model and are stored as image support data.

To find the image coordinates corresponding to specified ground coordinates, the surrounding eight
grid points are found. Tri-linear interpolation is then used between these eight points.  Alternately,
higher order interpolation could be used between more surrounding points. For example, cubic
interpolation could be used between the 64 surrounding grid points. Another variation is to use a
grid (partially) in image coordinates.

The Grid Interpolation Image Geometry Model approach using a 3-D grid in ground coordinates
was proposed by Cliff Kottman in OpenGIS Project Document 96-012, and the following
discussion is adapted from that document.

6.3.1. Grid Points
A regular grid in ground coordinates is chosen to enclose the object space imaged (or the portion of

the Earth imaged). The grid points are thus located at (xi, yj, zk), where:
1  ≤  i  ≤  M, 1  ≤  j  ≤  N, 1  ≤  k ≤  P

There are thus M*N*P points in this regular grid.  A grid cell has eight of these points as corners,

and has points of the form (xi, yj, zk) and (x(i+1), y(j+1), z(k+1)) as the endpoints of a grid
cell diagonal.

6.3.2. Grid Points Image Support Data
An available rigorous image geometry model is used to compute the image coordinates
corresponding to each grid point. These image coordinate row and column values are recorded as
image support data, together with parameters that define the grid point locations in ground
coordinates. This computation for an image can be done at a central facility. This computation
could be done once, after all adjustments of the rigorous model are completed. Alternately, this
computation could be repeated after each of several adjustments of the rigorous image geometry
model.

The grid point ground locations could be recorded in image support data in several alternative
ways. For example, the ground coordinates could be directly recorded, recording one 5-tuple (xi, yj,
zk, r, c) for each ijk point. Alternately, parameters defining the grid point ground coordinates could
be recorded. Such parameters for each axis might include the offset to the first point, the spacing
between points, and the number of points.

6.3.3. Grid Model Accuracy
The accuracy of the grid interpolation image geometry is increased by using a smaller grid point
spacing in object space. The rule is simple: Given a maximum error budget,  choose the grid
spacing so that the maximum error introduced by tri-linear interpolation is less than the error
budget. Figure 6-1 is an illustration of the situation.

6.3.4. Size of Image Support Data
If the rigorous image geometry model has only low order components, only a modest number of
grid points may be needed. Because optical projection can be accurately represented by ratios of
first order polynomials, they have slowly changing (first order) partial derivatives. Radar image
projections are also nearly linear. Furthermore, second order polynomials can accurately
approximate many of the corrections used in rigorous models, such as for earth curvature,
atmospheric refraction,  and lens distortion. These correction functions thus have slowly changing
partial derivatives. When this is true, a grid that is small enough to be easily handled can also be
fine enough to support a small error budget.



The OpenGIS™ Abstract Specification Page 13

Volume 7: The Earth Imagery Case (99-107.doc)

(x1,y1,z1)

r
c

x

y

z

T is linear within each cube of object space.
The cubes are made small enough until the linear 
interpolation is sufficiently accurate.

Figure 6-1. A region of local linearity.

However, some image geometry models have high order model components. For example, camera
vibration during the sweep of a panoramic camera can have tens of vibration cycles during the
exposure of one image. If the peak-to-peak magnitude of the vibration or another high order effect
is significantly larger than the desired maximum fitting error, then hundreds of grid points can be
required in each of the three ground coordinates.

Since the (xi, yj, zk) grid points are equally spaced, the set of ground coordinates can be
represented as a very small set of data. For example, each image point position might be
represented by two short unsigned integers, with the row and column each having a range from 0 or
1 to the number of rows or columns in the image. Also, each ground point position might be
represented by three short unsigned integers, by using an origin and point spacing for each
coordinate.

6.3.5. Tri-linear Interpolation Mathematics
Tri-linear interpolation is relatively easy to compute. Assume that we are interpolating the function
T within the grid cell with corners numbered from 1 to 8 as shown in Figure 6-2. Assume that
T(xi,yi,zi) = (ri,ci) for i = 1, 2, …, 8, and the eight points (xi,yi,zi) are the corners of the grid cell in
object space. Further assume that (x0,y0,z0) is a point within the polyhedron defined by the eight
corners.  The goal is to compute T(x0,y0,z0).  We first compute the parameters α, β, and γ using the
equations:

α  =  (x0-x1)/(x2-x1)

β =  (y0-y1)/(y3-y1)

γ  =  (z0-z1)/(z5-z1)



The OpenGIS™ Abstract Specification Page 14

Volume 7: The Earth Imagery Case (99-107.doc)

1 2

3
4

5
6

7 8

(x8,y8,z8)

α

β

γ

(x0,y0,z0)

x

z

y

Figure 6-2. The tri-linearity details.

We then compute T at (x0,y0,z0) by:

T(x0,y0,z0) = (1-γ){(1-β)[(1-α)(r1,c1) + α(r2,c2)] + β[(1- α)(r3,c3) + α(r4,c4)]} + γ {(1- β)[(1-
 α)(r5,c5) + α(r6,c6)] + β[(1- α)(r7,c7) + α(r8,c8)]}

Using this formulation,  the interpolation of T at an arbitrary point, takes 23 adds, 3 divides, and 20
multiplies, and can be further accelerated by careful implementation.

6.3.6. Advantages and Disadvantages
The primary disadvantage of a Grid Interpolation Image Geometry Model is that the image support
data will be very large when a large number of grid points are required. This situation normally
occurs for certain image sensors having high order geometric effects, such as significant vibration
during image collection and electronic array non-linearities. The advantages of a Grid Interpolation
Image Geometry Model include:

1. One grid model can be used for all types of images.

2. An exploitation system or software using the grid model can be completely ignorant of the
rigorous image geometry model used to create it. The rigorous image geometry model is thus easier
to update as sensors evolve, since changes to it do not cascade into the exploitation software.
Configuration management of rigorous image geometry models is easier.

3. The same grid model can be used by all exploitation software, producing the same errors and
error estimates in each. This commonality will make enterprise wide error analysis easier.

4. Transfer of image support data for this grid model can be robust, if the ground coordinates of
each grid point are separately recorded. The loss of a few points in the set of 5-tuples is easy to
detect by the obvious loss of symmetry, and is easy to patch (with some loss of accuracy) by
interpolating or extrapolating from surviving points.

6.4. Ratios of Polynomials
In the last few years, one real-time image geometry model has come into widespread use within the
U. S. intelligence community. This model is often called the Rational Functions  model, and the
polynomial coefficients are often called Rapid Positioning Capability (RPC) data. The image
distribution agency computes the RPC data for each image, and distributes this data with the



The OpenGIS™ Abstract Specification Page 15

Volume 7: The Earth Imagery Case (99-107.doc)

images. Some of these images are distributed in NITF 2.0 format, with the RPC image support data
included in the same NITF file.

6.4.1. Ratios of Polynomials Mathematics
This image geometry model uses a ratio of two polynomial functions to compute image row, and a
similar ratio to compute image column. All four polynomials are functions of three ground
coordinates, namely latitude, longitude, and height (or elevation). A separate image geometry
model is computed for each previously defined segment of a large image. Each polynomial has 20
terms, although the coefficients of some polynomial terms are often zero. In the polynomial
functions, the three ground coordinates and two image coordinates are each offset and scaled to
have a range from -1.0 to +1.0 over an image segment.

For each image or previously defined image segment, the defined ratios of polynomials have the
form:

rn =
p1(xn , yn, zn )

q1(xn , yn, zn )

cn =
p2(xn , yn, zn )

q 2( xn, yn, zn )
Where:

rn = Normalized row index of pixel in image

cn = Normalized column index of pixel in image

xn, yn, zn = Normalized ground coordinate values

The polynomials p and q have the form:

p = a ijk xn
i

k =0

m3

∑
j=0

m 2

∑
i=0

m1

∑ yn jzn k

q = b ijk xn
i

k =0

n 3

∑
j=0

n 2

∑
i=0

n1

∑ yn jzn k

Where:

aijk, bijk  = Polynomial coefficients
The maximum powers of each ground coordinate (m1, m2, m3, n1, n2, and n3) are limited to 3.
Furthermore, the total power of all three ground coordinates is limited to 3. That is, the polynomial
coefficients are defined to be zero whenever i + j + k > 3. The normalization of the ground and
image coordinates is the same as discussed below for the Universal Real-time Image Geometry
Model, see Sections 6.5.1.3 and 6.5.1.5.

6.4.2. Advantages and Disadvantages
The Grid Interpolation Image Geometry Model has many of the advantages discussed above for the
grid interpolation model, including:

One ratio of polynomials model can be used for all types of images.

An exploitation system or software using the ratio model can be completely ignorant of the
rigorous image geometry model used to create it. The rigorous image geometry model is thus easier
to update as sensors evolve, since changes to it do not cascade into the exploitation software.
Configuration management of rigorous image geometry models is easier.



The OpenGIS™ Abstract Specification Page 16

Volume 7: The Earth Imagery Case (99-107.doc)

The same ratio model can be used by all exploitation software, producing the same errors and error
estimates in each. This commonality will make enterprise wide error analysis easier.

However, this ratios-of-polynomials image geometry model has several limitations:

1. Limited accuracy in fitting to the associated rigorous image geometry model

2. Usually fit to a rigorous image geometry model with limited accuracy (not triangulated with
several overlapping images)

3. Complex fitting process, to avoid a denominator polynomial function going to zero within the
image segment extent (producing excessive errors)

4. Not provided with all images distributed by the distributing agency

6.5. Universal Real-time Image Geometry Model
This “Universal Real-time Image Geometry Model” is universal in the sense that we think it can
accurately represent the geometry of all known types of images and image sensors. These image
sensor types include frame, panoramic, pushbroom, whiskbroom, and Synthetic Aperture Radar
(SAR) sensors. This model can accurately represent images from all these sensor types for purposes
of image exploitation, but not for image geometry model adjustment, by triangulation and most
other adjustment methods.

This Universal Real-time Image Geometry Model is the new NIMA standard real-time geometry
model for images of the earth. This Universal Model was developed and first implemented by GDE
Systems, Inc. under Defense Mapping Agency (now the National Imagery and Mapping Agency,
NIMA) contract 800-95-C-8029. This contract is for the Front-end Processing Environment (FPE)
supporting NIMA’s Alternate Source Exploitation (ASE) initiative. The objectives of this Universal
Real-time Image Geometry Model included:

1. Support exploitation of images collected by all current and future imaging sensors, include
frame, panoramic, pushbroom, whiskbroom, and SAR sensors, from both government and
commercial image sources

2. Provide very high fitting accuracy, relative to rigorous sensor models

3. Allow implementation in any image exploitation system

(This contract has also developed five “generic sensor models,” for frame, panoramic, pushbroom,
whiskbroom, and SAR sensors. These generic sensor models are rigorous in the sense that they are
intended for image geometry model adjustment, by analytical triangulation and most other
adjustment methods. Each of these generic sensor models is generic in the sense that we think it can
accurately represent the geometry of most images and image sensors of that general type. These
five generic sensor models share many parts of their mathematics and image support data.)

The Universal Real-time Image Geometry model  is an extension of the ratios of polynomials
model, and employs interpolation of high-order correction functions. Although the Universal
Model is more complex, we think it offers the advantages of:

1. Higher storage efficiency (or more data compression) for image support data, by not requiring a
very large number of polynomials or points to accurately fit the rigorous sensor models of complex
sensors having high order geometric effects (such as sensor vibration effects)

2. Extensive future use within the National Imagery and Mapping Agency (NIMA)

Support data for this Universal Real-Time Image Geometry Model is produced by fitting this model
to any more rigorous sensor model, following completion of analytical triangulation or other
adjustment. An image exploitation system can use this universal image geometry model directly as
its real-time image geometry model.

6.5.1. Universal Real-time Image Geometry Model Mathematics
This universal real-time image geometry model uses one ratio of two polynomial functions to
compute the row image coordinate, and uses a similar ratio of two different polynomials to
compute the column image coordinate. (Such ratios of polynomials are often called Rational
Functions , and the coefficients are often called Rapid Positioning Coefficients (RPC).) All four



The OpenGIS™ Abstract Specification Page 17

Volume 7: The Earth Imagery Case (99-107.doc)

polynomials are functions of three ground coordinates: two horizontal coordinates and one vertical
coordinate. In the polynomial functions, the three ground coordinates and two image coordinates
are each offset and scaled to have a range from -1.0 to +1.0 over an image or image section.

This universal real-time image geometry model extends the current Rational Functions  model in
five respects:

1. One image geometry model can be split into multiple subdivisions or sections, when needed to
obtain the desired accuracy. Each image axis can be divided into an integer number of equal parts,
up to 8 parts in each image coordinate. The image coordinates divided are computed using two
linear polynomials of the three ground coordinates, with each of these polynomials containing four
terms. Ratios of different polynomials are then used for each image section.

2. The modified polynomials are variable order, up to the fifth power of the two horizontal
coordinates, and up to third power of height or elevation. Higher powers are used when needed to
obtain the desired accuracy. All combinations of all powers of the three ground coordinates are
allowed, producing a maximum number of terms in each polynomial of:

(1 + 5) * (1 + 5) * (1 + 3) = 144

3. The denominator polynomials can be omitted, and usually are omitted. When a denominator
polynomial is not supplied, the denominator is taken to be unity (1.0).

4. In addition to the ratios of polynomials, optional image position correction tables are allowed.
Each table is a function of one image coordinate, computed by a ratio of polynomials, either image
row or column. Each table contains corrections to both row and column. Linear interpolation of the
corrections is used for image positions between the tabulated correction values. These correction
tables are included when needed to achieve the desired accuracy.

5. The three ground coordinates can be in any defined ground coordinate system. (In Rational
Functions , the three ground coordinates are usually latitude, longitude, and height in the WGS-84
coordinate system. Height is referenced to the ellipsoid, not to the geoid or mean sea level.)

When a user needs a different ground coordinate system than is used by the available image
geometry model, we assume the user will also use ground coordinate transformation software that
performs the needed coordinate conversions.

When the image geometry model is divided into sections, all sections are fit to the (un-divided)
rigorous geometry model so that there is only a negligible difference between adjacent sections.
That is, there is only a fraction of a pixel difference between the image positions computed by
adjacent image sections at the same ground position. This negligible difference holds at all the
ground positions along the boundaries between adjacent sensor model sections.



The OpenGIS™ Abstract Specification Page 18

Volume 7: The Earth Imagery Case (99-107.doc)

Normalize 
Ground 

Coordinates

Un-normalize 
Image 

Coordinates

Compute 
Ratios of 

Polynomials

Interpolate 
Correction 

Tables

Ground Coordinates:  
x, y, z

Normalized Ground  
Coordinates: x, y, z

Normalized Image  
Coordinates: r, c

Un-normalized Image  
Coordinates: r, c

Ground 
Coordinates 
Offsets and 

Scales

Polynomial 
Coefficients

Image 
Coordinates 
Offsets and 

Scales

Correction 
Tables

Add

Corrected Image  
Coordinates: r, c

Image Coordinates 
Corrections: r, c

Compute 
Linear 

Polynomials

Determine 
Image Model 

Section

Approximate Image  
Coordinates: r, c

Image Model 
Section Numbers

Linear 
Polynomial 

Coefficients

Numbers of 
Sections, 

Image 
Dimensions

Support Data For 
Universal 
Real-Time Image 
Geometry Model

Select Image 
Model Section 
Support Data

Figure 6-3. Universal Real-Time Image Geometry Model computations.



The OpenGIS™ Abstract Specification Page 19

Volume 7: The Earth Imagery Case (99-107.doc)

Figure 6-3 summarizes the computations required to use the universal real-time image geometry
model to compute the image coordinates corresponding to the ground coordinates of a point. The
following subsections provide more details of the universal model.

6.5.1.1. Linear Polynomials

Linear polynomials are provided for computing the approximate position in an image for any
ground point. These approximate polynomials are required only if the image geometry model is
divided into multiple subdivisions or sections, to obtain the desired accuracy. The approximate
image position can be computed for an arbitrary ground point using the linear polynomials. This
approximate image position is then used to determine the appropriate image geometry model
section.

The defined linear polynomials have the form:

r = a * x + b * y + c * z + d
c = e * x + f * y + g * z + h

Where:

r = Approximate row index of pixel in image

c = Approximate column index of pixel in image

x = East-West position of point on ground

y = North-South position of point on ground

z = Height or elevation of point on ground

a, b, c, d, e, f, g, h = Linear polynomial coefficients
6.5.1.2. Image Model Section

The computed approximate position in an image is used to determine in which image geometry
model section a point falls. As needed for accuracy, an image is divided into up to 8 equal sections
in the row direction, and up to 8 equal sections in the column direction. The number of sections
used in each direction are recorded as integers. These integers are used, with the image size in each
direction, to determine which section an approximate image position falls within.

The image segment in each direction is computed:

nsr = integer
r * N sr

N ir

 
 
 

 
 
 

nsc = integer
c * N sc

N ic

 
  

 
  

Where:

nsr = Image section in row direction

nsc = Image section in column direction

r = Approximate row index of pixel in image

c = Approximate column index of pixel in image

Nsr = Number of image model sections in row direction



The OpenGIS™ Abstract Specification Page 20

Volume 7: The Earth Imagery Case (99-107.doc)

Nsc = Number of image model sections in column direction

Nir= Number of image rows

Nic = Number of image columns
integer ( ) = The integer part of the value in the parenthesis

6.5.1.3. Normalized Ground Coordinates

For each image model section, the x, y, and z ground coordinates (often latitude, longitude, and
height) are offset and scaled to fit the range from -1.0 to +1.0. The normalized ground coordinates
are computed from the un-normalized coordinates using the equations:

xn =
xu − xo

xs

yn =
yu − yo

ys

zn =
zu − zo

zs
Where:

xn, yn, zn = Normalized ground coordinate values
xu, yu, zu = Un-normalized ground coordinate values, such as longitude, latitude, and

height

xo, yo, zo = Offset values for three ground coordinates
xs, ys, zs = Scale values for three ground coordinates
The quantities zu, zo, and zs are all in the same units, normally meters. Similarly, the quantities
xu, yu, xo, yo, xs, and ys are all in the same units, perhaps degrees of latitude and longitude.

6.5.1.4. Ratios of Polynomials

For each image model section, the defined ratios of polynomials have the form:

rn =
p1(xn , yn, zn )

q1(xn , yn, zn )

cn =
p2(xn , yn, zn )

q 2( xn, yn, zn )
Where:

rn = Normalized row index of pixel in image

cn = Normalized column index of pixel in image

xn, yn, zn = Normalized ground coordinate values



The OpenGIS™ Abstract Specification Page 21

Volume 7: The Earth Imagery Case (99-107.doc)

The polynomials p and q have the form:

p = a ijk xn
i

k =0

m3

∑
j=0

m 2

∑
i=0

m1

∑ yn jzn k

q = b ijk xn
i

k =0

n 3

∑
j=0

n 2

∑
i=0

n1

∑ yn jzn k

Where:

aijk, bijk = Polynomial coefficients
m1 � 5, m2 � 5, m3 � 3

n1 � 5, n2 � 5, n3 � 3

Note that the currently available Rational Functions  (e.g., RPC) can be represented, if m1, m2, m3,
n1, n2, and n3 are all set to 3 and polynomial coefficients are set to 0 when
i + j + k > 3.

6.5.1.5. Un-Normalized Image Coordinates

The row and column image coordinates (r and c) computed by the ratios of polynomials are offset
and scaled to fit the range from -1.0 to + 1.0. The un-normalized image coordinates are computed
from the normalized coordinates using the equations:

ru = rn * rs + ro
cu = cn * cs + co

Where:

ru, cu = Un-normalized image coordinate values

rn, cn = Normalized image coordinate values

ro, co = Offset values for two image coordinates

rs, cs = Scale values for two image coordinates

The quantities ru, cu, ro, co, rs, and cs are all in the same units, namely pixel spacings.
6.5.1.6. Correction Functions

The universal real-time image geometry model includes image position correction tables when
needed to achieve the desired accuracy. One or more tables can be used, with each correction table
defining corrections to both row and column image positions. When more than one table is used,
the corrections defined by all applicable tables are added. Each table is a function of one image
coordinate, either image row or column. A correction table can apply to the entire image or only to
one section of the image geometry model.

The row and column positions computed by the ratio of polynomials are corrected after they are un-
normalized. Each correction table is indexed by either the row or column un-normalized image
position. The number of entries in each table is variable, with a variable spacing between table
entries and a variable (row or column) position of the first table entry. The correction to apply at a
point falling between two table values is computed by linear interpolation between the two
surrounding table values.

6.5.1.7. Fitting Errors

To indicate the universal model fitting errors, fitting error estimates are provided. Separate row and
column fitting errors are recorded, specifying the estimated errors committed in fitting the universal
real-time image geometry model to the rigorous sensor model. These errors are given with and
without use of all the provided correction tables (if any are provided), to indicate the additional



The OpenGIS™ Abstract Specification Page 22

Volume 7: The Earth Imagery Case (99-107.doc)

errors if the correction tables are not used. All these fitting errors are specified as Linear Errors
(LEs) with 0.9 probability. That is, the magnitude of the actual image row or column error has a 0.9
probability of being less than the specified LE value.

6.5.1.8. Ground Accuracy Estimates

We propose including monoscopic accuracy estimates in the image support data for each universal
real-time image geometry model. In addition, we propose including stereoscopic accuracy
estimates when images are expected to be exploited stereoscopically. These accuracies are the
estimated errors in ground positions of points computed from image position measurements using
the associated image support data. These accuracies reflect the estimated errors in the image
support data, but not the accuracies of measuring points in the images. For universal model support
data, these accuracies reflect the use of all included correction tables, if any.

We propose that each accuracy record include both absolute and relative accuracies, allowing
relative accuracies to be specified for multiple distance bins. Absolute accuracy is of a single
ground point, relative to ground truth. Relative accuracy is between two ground points, the
accuracy of one point with respect to the other point. Each distance bin specifies the minimum and
maximum vector distances between two points, for which the stated relative accuracy applies.

Separate accuracy data is included for:

1. A summary of the accuracies over a group of overlapping images (e.g., the group of images
triangulated together). In this case, the relative accuracies are between any two points measured in
any of these images or stereomodels.

2. The individual accuracies of one image or one stereomodel. In this case, the relative accuracies
are between two points where at least one of these points is measured in this image or stereomodel.

6.5.1.9. Image to Ground Computations

The ground position corresponding to an image position can be computed using the universal real-
time image geometry model, by computing the iterative inverse of the ground to image
transformation. The inputs are the row and column image positions, plus the ground height or
equivalent.

6.5.1.10. Ground Viewing Angle Computations

The ground viewing angle in 3-D space to a ground point from an image can be computed using the
universal real-time image geometry model. The viewing angle can be determined by first
performing the image to ground computation for the same image position and two somewhat
different elevations or heights. The viewing direction is given by the 3-D vector connecting these
two ground positions.

The convergence angle for a stereoscopic pair of images can be computed from the two ground
viewing angles. The ground viewing vectors in 3-D space from two images to the same ground
point are first computed. The convergence angle is the angle between these two vectors in 3-D
space.

The epipolar direction in horizontal ground coordinates for two overlapping images can also be
computed at any ground point using the universal model. The two image positions corresponding to
one ground point are first computed. The ground positions at a somewhat different elevation
corresponding to those two image positions are then computed. The direction from one of these
ground positions to the other is the epipolar direction.

6.5.2. Universal Real-time Image Geometry Support Data
As specified above, the universal real-time image geometry model includes polynomial functions,
plus optional correction tables. Multiple polynomial transformations can be provided for one
image, with each transformation to be used within a specified section of a larger image. Image
support data, or image geometry metadata, must provide values for all the quantities used in this
real-time model

The image support data required by this universal real-time image geometry model has been
organized into eleven types of data records:

1. Universal Image Geometry Model Header

2. Four separate polynomial function records:



The OpenGIS™ Abstract Specification Page 23

Volume 7: The Earth Imagery Case (99-107.doc)

2.1. Row Numerator Polynomial (numerator for computing image row)

2.2. Row Denominator Polynomial (denominator for computing image row)

2.3. Column Numerator Polynomial (numerator for computing column)

2.4. Column Denominator Polynomial (denominator for computing column)

3. Two types of image correction table records, as functions of:

3.1. Row Function Correction (function of image row)

3.2. Column Function Correction (function of image column)

4. Four types of accuracy estimate records:

4.1. Summary Monoscopic Accuracy Estimates

4.2. Individual Monoscopic Accuracy Estimates

4.3. Summary Stereoscopic Accuracy Estimates

4.4. Individual Model Stereoscopic Accuracy Estimates

The records for polynomials are repeated for each image section. The records for correction tables
can apply to an entire image or can be repeated for each image section. (Note: This section uses the
term “record” for each group of image support data. Some other term may be preferred in the
OpenGIS Abstract Specification, such as object or data object.)

The following subsections specify the required contents of these eleven types of image support data
records. These record types include options to handle a range of uses.

6.5.2.1. Common Header Fields

These image support data records all begin with the fields:

1. Record Type, alphanumeric text identifying this type of record

2. Length of Data, integer number of the bytes following this field. (Note that each record has more
bytes than specified in this field.)

3. Image ID, alphanumeric text

4. Image Support Data Version, one integer from 0 to 9

Increasing numbers in the Image Support Data Version field are intended to be used when
applicable to indicate increasing quality of the data in that type of record. Different version
numbers should be allowed in the different records for one image. (For the FPE, this Image Support
Data Version field will initially be “1” when the image support data was adjusted by the FPE or “0”
when the image support data was not adjusted.)

6.5.2.2. Universal Image Geometry Model Header

One record type is used for Universal Image Geometry Model Header, with image support data
including one such record for each image. This Universal Image Geometry Model Header provides
overall information for an entire image, and contains the fields:

1. Record Type, alphanumeric text identifying this type of record

2. Length of Data, integer number of the bytes following this field

3. Image ID, alphanumeric text

4. Image Support Data Version, one integer

5. Triangulation ID, alphanumeric text, of the last triangulation that adjusted the support data for
this image, when this information is available

6. Geographic Coordinate System, of the un-normalized horizontal ground coordinates used in the
universal real-time image geometry model for this image, alphanumeric text containing code or



The OpenGIS™ Abstract Specification Page 24

Volume 7: The Earth Imagery Case (99-107.doc)

name. This geographic coordinate system is assumed to imply or include the correct datum,
ellipsoid, and prime meridian.

7. Horizontal Units, of the un-normalized horizontal ground coordinates used in the universal real-
time image geometry model, alphanumeric text containing name of units (e.g., degrees, radians,
meters)

8. Vertical Coordinate System, of the un-normalized vertical ground coordinates used in the
universal real-time image geometry model for this image, alphanumeric text containing name or
code. This system will specify whether heights (or elevations) are relative to the ellipsoid or the
geoid (mean sea level).

9. Vertical Units, of the un-normalized height or elevation used in the universal real-time image
geometry model, alphanumeric text containing name of units (e.g., meters, feet)

10. Row and Column Image Size, two integers in pixels

11. Row and Column Numbers of Sections, two integers

12. The following field is repeated for the eight terms of the approximate linear sensor model:

12.1. Polynomial Coefficient, one number

13. The following fields are repeated for each sensor model section:

13.1. Row and Column Section Numbers, two integers

13.2. Row and Column Fitting Error LE (0.9P) With Correction Tables, two numbers

13.3. Row and Column Fitting Error LE (0.9P) Without Correction Tables, two numbers

13.4. Repeated for each of two image and three ground coordinates:

13.4.1. Position Offset, one number, in same units as this coordinate

13.4.2. Position Scale Factor, one number, in same units as this coordinate

6.5.2.3. Polynomial Records

Four record types are used for universal real-time image geometry model polynomials. Each record
contains the coefficients for one polynomial function. Four different record types are used to
distinguish among the four polynomial uses. Image support data includes one record for each
polynomial used in each image geometry model section of each image.

The same polynomial record format is used for all universal model polynomials. Each polynomial
record contains the fields:

1. Record Type, alphanumeric text identifying this type of record

2. Length of Data, integer number of the bytes following this field

3. Image ID, alphanumeric text

4. Image Support Data Version, integer from 0 to 9

5. Row and Column Section Numbers, two integers

6. Maximum Powers of Latitude, Longitude, and Elevation, three integers

7. The following field is repeated for each polynomial term:

7.1. Polynomial Coefficient, number

The number of polynomial terms is the product of three integers, each integer being one plus the
corresponding Maximum Power integer. The polynomial coefficients are ordered by the numerical

value of the subscript of aijk or bijk, as defined in Section 6.5.1.4.



The OpenGIS™ Abstract Specification Page 25

Volume 7: The Earth Imagery Case (99-107.doc)

Two to four polynomial records are included for each section of an image, when this real-time
image geometry model divides an image. The denominator polynomials are omitted when not
needed (i.e., when the denominator polynomial is 1.0). When the sensor model is not divided, the
included polynomial records are for the entire image, and the Row and Column Section Number
fields contain 00.

6.5.2.4. Correction Table Records

Two record types are used for universal real-time image geometry model correction tables. Each
correction table record contains the data for one correction table. Two different record types are
used to distinguish between tables that are functions of image row and of image column. These
correction tables are intended for high order corrections, for effects such as sensor vibration and
electronic array non-linearities.

Image support data optionally includes multiple correction tables for each image. Correction table
records are omitted when not needed. More than one table of each type are allowed. When more
than one table is included, the image corrections from all tables are added to the uncorrected image
row and column numbers.

Each correction table record contains data for a regularly spaced set of points, and contains the
image row and column corrections to be applied at each table point. The set of points are defined in
un-normalized and uncorrected image row or column coordinates. The correction to be applied
between these table points is computed by linear interpolation between the two surrounding points.

Each correction table record contains the fields:

1. Record Type, alphanumeric text identifying this type of record

2. Length of Data, integer number of the bytes following this field

3. Image ID, alphanumeric text

4. Image Support Data Version, one integer

5. Row and Column Section Numbers, two integers

6. Table Spacing and Offset, two numbers in pixel units

7. Number of Table Entries, one integer

8. The following fields are repeated for each table entry:

8.1. Image Row Correction, one number in pixel units

8.2. Image Column Correction, one number in pixel units

These correction table records can be used for each section of an image, when this real-time
geometry model divides an image. When the sensor model is not divided or the correction table
data is not divided, these records are for the entire image, and the Row and Column Section
Number fields contain 00.

6.5.2.5. Monoscopic Accuracy Estimates Records

We propose using two different record types for monoscopic ground accuracy estimates, using the
same record contents except for the record type. Monoscopic accuracy estimates records should be
included for both stereoscopic and monoscopic images.

One record type contains summary monoscopic accuracy estimates for a group of images, with a
support data file optionally including one such record. This record reflects the entire group of
adjusted images included in that support data file. In this summary record, the relative accuracies
are between any two points measured in any of these images (including two points measured in the
same image). The horizontal shear is the typical vector distance between the horizontal positions of
the same ground point measured in overlapping images.

The second record type contains monoscopic accuracy estimates for a single primary image, with
an image support data file containing one or more such records for each adjusted image included in
that file. In these specific image records:



The OpenGIS™ Abstract Specification Page 26

Volume 7: The Earth Imagery Case (99-107.doc)

1. The relative accuracies are between one point measured in the primary image and any point
measured in any other listed image.

2. The absolute accuracies are for points measured in the primary image.

3. The horizontal shear is the typical vector distance between the horizontal positions of the same
ground point measured in the primary image and in all the other listed images overlapping it.

Each monoscopic accuracy estimates record contains the fields:

1. Record Type, alphanumeric text identifying this record type

2. Length of Data, integer number of the bytes following this field

3. Reference Height, one number. This height is the one used to estimate the horizontal accuracies.

4. Absolute Accuracy Horizontal CE (90%), one number, in meter units

5. Horizontal Shear, between overlapping images, one number, in meter units

6. Number of Images, one integer

7. Repeated for each image in group:

7.1. Image ID, alphanumeric text

7.2. Image Support Data Version, one integer

8. Number of Relative Accuracy Distance Bins, one integer

9. Repeated for each relative accuracy distance bin:

9.1. Bin Minimum Distance, one number, in meter units

9.2. Bin Maximum Distance, one number, in meter units

9.3. Relative Accuracy Horizontal CE (90%), one number, in meter units

In a single primary image record, the first listed image is the primary image. The same image can
also be listed a second time, to cover relative accuracies between two points both measured in that
primary image.

6.5.2.6. Stereoscopic Accuracy Estimates Records

We propose using two different record types for stereoscopic ground accuracy estimates, using the
same record contents except for the record type. Stereoscopic accuracy records are included in an
image support data file only for image pairs that are expected to be exploited stereoscopically.

One record type contains summary stereoscopic accuracy estimates for a group of images, with an
image support data file optionally including one such record covering all the adjusted stereoscopic
images included in that file. In this summary record:

1. The relative accuracies are between any two points measured in these stereomodels (including
two points measured in the same stereomodel).

2. The Y parallax is the typical absolute value between all stereoscopic pairs of images.

3. The horizontal shear is the typical vector distance between the horizontal positions of the same
ground point measured in overlapping stereomodels.

4. The vertical shear is the typical absolute difference between the heights of the same ground point
measured in overlapping stereomodels.

The second record type contains stereoscopic accuracy estimates for a single primary stereoscopic
pair of images, with an image support data file containing one or more such records for each
adjusted stereomodel included in that file. In these records:

1. The relative accuracies are between one point measured in the primary stereomodel and any
point measured in any other listed stereomodel.



The OpenGIS™ Abstract Specification Page 27

Volume 7: The Earth Imagery Case (99-107.doc)

2. The absolute accuracies are for points measured in the primary stereomodel.

3. The Y parallax is the typical absolute value between the two images of the primary stereomodel.

4. The horizontal shear is the typical vector distance between the horizontal positions of the same
ground point measured in the primary stereomodel and in all listed overlapping stereomodels.

5. The vertical shear is the typical absolute difference between the heights of the same ground point
measured in the primary stereomodel and in all listed overlapping stereomodels.

Each stereoscopic accuracy estimates record contains the fields:

1. Record Type, alphanumeric text identifying this record type

2. Length of Data, integer number of the bytes following this field

3. Absolute Accuracy Horizontal CE (90%), one number, in meter units

4. Absolute Accuracy Vertical LE (90%), one number, in meter units

5. Y Parallax, one number, in pixel units

6. Horizontal Shear, between overlapping stereomodels, one number, in meter units

7. Vertical Shear, between overlapping stereomodels, one number, in meter units

8. Number of Images, one even integer

9. Repeated for left and right images of all stereopairs:

9.1. Image ID, alphanumeric text

9.2. Image Support Data Version, one integer

10. Number of Relative Accuracy Distance Bins, one integer

11. Repeated for each relative accuracy distance bin:

11.1. Bin Minimum Distance, one number, in meter units

11.2. Bin Maximum Distance, one number, in meter units

11.3. Relative Accuracy Horizontal CE (90%), one number, in meter units

11.4. Relative Accuracy Vertical LE (90%), one number, in meter units

In a single primary stereomodel record, the first two listed images are the primary stereomodel. The
same stereomodel can also be listed a second time, to cover relative accuracies between two points
both measured in that primary stereomodel.

6.5.3. Other Image Support Data
We propose that additional data be included in the image support data which contains parameter
values for the universal real-time earth image geometry model. This additional image support data
is additional image metadata that provides values of parameters not needed or used for defining the
ground-image geometry.

6.5.3.1. Image Collection Data Record

We propose that this additional image support data include information needed or useful for image
interpretation, here called image collection data. This Image Collection Data record contains data
useful for exploitation, but independent of the image geometry model. One record type is used for
the Image Collection Data, with image support data including one such record for each image. The
same Image Collection Data record format is used for all types of images.

Each Image Collection Data record contains the fields:

1. Record Type, alphanumeric text identifying this type of record

2. Length of Data, integer number of the bytes following this field



The OpenGIS™ Abstract Specification Page 28

Volume 7: The Earth Imagery Case (99-107.doc)

3. Image ID, alphanumeric text

4. Image Support Data Version, one integer

5. Image Title, optional text

6. Sun Azimuth and Elevation Angles, two numbers, in degrees

7. Imaging Date, three numbers, for year, month, and day

8. Imaging Time, three numbers, for hour, minute and second

9. Sensor Identification, alphanumeric text

10. Geometric Mean Ground Sample Distance (GSD), one number, in meter units

11. Image Interpretability Rating System, optional alphanumeric code

12. Image Interpretability Value, optional number, in the specified Image Interpretability Rating
System

13. Aggregation mode, one integer

14. Country, alphanumeric text containing name or code

15. Number of Bands, one integer

16. The following fields are repeated for each band:

16.1. Minimum and Maximum Electromagnetic Wavelengths, two numbers

16.2. Pixel Spread Function Percentages, 5 optional numbers

16.3. Row Pixel Spread Function, 5 optional numbers

16.4. Column Pixel Spread Function, 5 optional numbers

The data specified above for sensor bands is expected to be sometimes useful in selecting good
image enhancements, such as a Modulation Transfer Function Correction (MTFC). This data is also
expected to be sometimes useful for manual and automated image interpretation. The Pixel Spread
Function fields specify the pixel amplitude response to electromagnetic radiation (e.g., light within
the sensor response band) received at various distances from the effective center of the pixel.

6.5.3.2. Ground Point Record

We propose allowing the additional image support data to include information for selected ground
points, sometimes used as diagnostic points. This ground point data includes corresponding ground
and image positions, that could be used for manual and/or automatic checking of the image
geometry model and its support data.

We propose using one record type for Ground Points, with an image support data file including one
such record for each ground point that can be used as a diagnostic point for any included image.
This record contains information for each image in which the position of that ground point was
determined. (For the FPE, the ground points recorded in a file include all points used in
triangulation, including all tie points and control points.)

Each Ground Point record contains the fields:

1. Record Type, alphanumeric text identifying this record type

2. Length of Data, integer number of the bytes following this field

3. Triangulation ID, when this control point or tie point was used or produced from a known
specific triangulation. (This Triangulation ID could identify other triangulation results, such as
covariance matrices or other points used by the same triangulation.)

4. Ground Point ID, alphanumeric text identifying this point within this file

5. Ground Point Name, alphanumeric character string suitable for display



The OpenGIS™ Abstract Specification Page 29

Volume 7: The Earth Imagery Case (99-107.doc)

6. Use of Point, either: diagnostic point, tie point, XYZ control point, XY control point, Z control
point, triangulation-result point, or other ground point

7. Ground Position Status, either: undetermined, input, computed, or other

8. Geographic Coordinate System, of the horizontal ground coordinates of this point, alphanumeric
text containing code or name. This geographic coordinate system is assumed to imply or include
the correct datum, ellipsoid, and prime meridian.

9. Horizontal Units, of the horizontal ground coordinate of this point, alphanumeric text containing
name of units (e.g., degrees, radians, meters)

10. Vertical Coordinate System, of the vertical ground coordinate of this point, alphanumeric text
containing name or code. This system will specify whether heights are relative to the ellipsoid or
geoid.

11. Vertical Units, of the height or elevation of this point, alphanumeric text containing name of
units (e.g., meters, feet)

12. North-South Ground Position of Point, one number

13. East-West Ground Position of Point, one number

14. Height of Point, above the ellipsoid surface, one number

15. Geoid Separation Distance, above the ellipsoid surface, one number, in vertical units. This
distance is optional, but should be included when the Vertical Coordinate System is the geoid.

16. Absolute Accuracy Horizontal CE (90%), one number, in meter units

17. Absolute Accuracy Vertical LE (90%), one number, in meter units

18. Ground Position Covariances, 3 by 3 matrix of numbers (nine numbers) , in meter units

19. Number of images, in which point position was determined

20. Repeated for each counted image:

20.1. Image ID, alphanumeric text

20.2. Image Support Data Version, one integer

20.3. Image Position Status: undetermined, measured, computed, or other

20.4. Image Position Row, one number, in pixel units

20.5. Image Position Column, one number, in pixel units

20.6. Image Position Row Accuracy, standard deviations, one number, in pixel units

20.7. Image Position Column Accuracy, standard deviations, one number, in pixel units

6.5.3.3. File Header Record

When support data for multiple images is included in one data file, one record type shall be used
for the file header, with each file beginning with one such record. This record contains file
identification information plus a list of all the images whose support data is included in this file.
(This image list is redundant information, but is included to provide easy access to a list of all the
images included in this file.) Each File Header record shall contain the fields:

1. Record Type, alphanumeric text identifying this record type

2. Length of Data, integer number of the bytes following this field

3. Triangulation ID, alphanumeric text

4. Triangulation Description, alphanumeric text

5. Number of Images, one integer



The OpenGIS™ Abstract Specification Page 30

Volume 7: The Earth Imagery Case (99-107.doc)

6. Repeated for each image:

6.1. Image ID, alphanumeric text

6.2. Image Support Data Version, one integer

6.6. Future Work
Desirable future work related to these real-time image geometry models includes:

1. The image support data structures discussed above and below should to be further refined. For
example, it may be appropriate to include additional image collection data (or metadata).

2. Open standard Application Programming Interfaces (APIs) should be defined for image
geometry models in general, including real-time image geometry models such as discussed here.
GDE Systems has just started work to define such an open standard API, under the FPE contract.

3. Methods for adjustment of the image support data of real-time image geometry models should be
developed, if practical, for use when additional control data becomes available. Even limited
adjustments would be useful, such as adjustment of the overall ground position, scale, and rotation.
However, determination of good ground accuracy data for the adjusted sensor model support data is
needed.

6.7. Appendices

6.7.1. FPE Generation of Universal Image Geometry Model
The FPE currently plans to produce universal real-time image geometry model support data with
the denominator polynomials q1 and q2 equal to 1.0 (i.e., n1 = n2 = n3 = 0). The degrees of the
numerator polynomials (i.e., m1, m2, and m3) will be dynamically selected to achieve the desired
accuracy. Typically one pair of ratios of polynomials will be used for an entire image. An image
model will be divided into image model sections when the needed accuracy cannot be achieved
with the maximum polynomial degrees. Correction tables will be included only when required to
achieve the desired accuracy, tentatively only for one type of images.

Support data for this universal real-time image geometry model is usually produced by fitting this
real-time model to one of five generic sensor models, developed by the FPE program. These five
generic sensor models are for frame, panoramic, pushbroom, whiskbroom, and Synthetic Aperture
Radar (SAR) images. The three ground coordinates used are always latitude, longitude, and height
in the WGS-84 coordinate system. Height is referenced to the ellipsoid (not to the geoid or mean
sea level).

The Number of Bands field in the Image Collection Data Record is included for future use, and will
initially contain either 0 or 1 from the FPE. The FPE will send to the DPS only one band of a
multiple-band alternate-source image, but will rarely have access to valid band information. When
provided to the DPS, the band information is for the single image band that is sent.

6.7.2. NITF Formatting of Image Support Data
We have defined how the image support data defined in Sections 6.2 and 6.3 could be formatted
like NITF 2.0 Tagged Record Extensions. The specification of these Tagged Record Extensions is
not yet final, and they have not yet been registered. We include these definitions as supplementary
information. A format like an NITF Tagged Record Extension is used for each image support data
record previously defined, as discussed in the following subsections.

6.7.2.1. Tagged Record Extensions

All records in universal real-time image geometry model support data are formatted like Tagged
Record Extensions in the NITF version 2.0. These new Tagged Record Extensions are intended to
be included in the image subheader portion of an NITF file. Key features of Tagged Record
Extensions include:

1. All data is recorded as ASCII coded characters, using 8 bits (one byte) per character.

2. All fields have a fixed length, an integer number of characters or bytes.

3. The Record Type field is first and contains 6 alphanumeric characters.



The OpenGIS™ Abstract Specification Page 31

Volume 7: The Earth Imagery Case (99-107.doc)

4. The Length of Data field follows the Record Type field, and contains a 5 character decimal
coded integer. The Length of Data field specifies the number of characters in the record after this
field (11 characters less than the entire record length). The maximum size of a record is thus about
100,000 bytes.

5. The contents of alphanumeric fields are left justified and padded to the right boundary with space
characters.

6. The contents of numeric fields are right justified and padded to the left boundary with leading
zero characters.

7. Null or default contents of alphanumeric fields are all space characters.

8. Null or default contents of numeric fields are zero characters.

Many fields are formatted like similar fields in the Support Data Extensions (SDEs) defined for
certain images recorded in NITF. These widely-used standardized formats are used partially to
allow easy reformatting of Rapid Positioning Coefficients (RPC) and other existing image support
data, to or from this real-time image geometry model format. Features of the SDEs used here
include:

1. All record type codes are initially defined to end with the letter “A”, designating the first version
of that record type. If the format of this record type needs to be changed later, the last (non-blank)
character will be changed to “B” and subsequent letters of the alphabet.

2. Image IDs can be recorded with up to 40 alphanumeric characters. This allows recording of a
specified section of a larger image.

3. Scale factors for normalizing row and column image positions are defined in pixels (not inverse
pixels).

4. Scale factors for normalizing latitude and longitude ground coordinated are defined in degrees
(not inverse degrees).

5. Scale factors for normalizing ground height are defined in meters (not inverse meters).

6.7.2.2. Universal Image Geometry Model Header

A Tagged Record Extension for the Universal Image Geometry Model Image Header shall use the
format specified in Table 6-1. One record type shall be used, with image support data including one
such record for each image. The same Universal Image Geometry Image Model Header record
format shall be used for all types of images.

Bytes Data Item Name Format Units Range Comments

6 Record Type A6 – USMIHA Identifies this record type
5 Length of Data I5 Bytes After this field

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9

40 Triangulation ID A40 – Of last triangulation that
adjusted this image

8 Geographic Coordinate
System

A8 – “WGS-84” Of horizontal coordinates

7 Horizontal Units A7 – “Degrees” Of ground coordinates
8 Vertical Coordinate System A8 – “Ellipsoid” Of height or elevation
7 Vertical Units A7 – “Meters” Of ground coordinates
7 Row Image Size I7 Pixels 1 to 9999999
7 Column Image Size I7 Pixels 1 to 9999999
2 Row No. of Sections I2 Sections 01 to 99
2 Column No. Sections I2 Sections 01 to 99

The following one field is repeated for the eight terms of the approximate linear sensor model:
12 Polynomial Coefficient E12.3 Various –

The following sixteen fields are repeated for each image section:
2 Row Section No. I2 Sections 00 to 99 Note 1
2 Column Section No. I2 Sections 00 to 99 Note 1



The OpenGIS™ Abstract Specification Page 32

Volume 7: The Earth Imagery Case (99-107.doc)

5 Row Fitting Error LE With
Correction Tables

F5.2 Meters 0.01 to 99.99 Note 2

5 Column Fitting Error LE
With Correction Tables

F5.2 Meters 0.01 to 99.99 Note 2

5 Row Fitting Error LE
Without Tables

F5.2 Meters 0.01 to 99.99 Note 2

5 Column Fitting Error LE
Without Tables

F5.2 Meters 0.01 to 99.99 Note 2

7 Row Offset I7 Pixels 0 to 9999999
7 Column Offset I7 Pixels 0 to 9999999
8 Latitude Offset F8.4 0.0001 degree ±90.0000
9 Longitude Offset F9.4 0.0001 degree ±180.0000
5 Height Offset I5 Meters ±9999
7 Row Scale Factor I7 Pixels 0 to 9999999
7 Column Scale Factor I7 Pixels 0 to 9999999
8 Latitude Scale Factor F8.4 0.0001 degree ±90.0000
9 Longitude Scale Factor F9.4 0.0001 degree ±180.0000
5 Height Scale Factor I5 Meters ±9999

Notes Description

1. If the image geometry model is not divided, there shall be one section for the whole image. When one record
contains data for the entire image, the Row and Column Section Number fields shall contain 00.

2. The Row and Column Fitting Errors shall indicate the errors in fitting the universal real-time image geometry
model to the rigorous image geometry model. These errors shall be given with and without use of all the
provided correction tables (if any are provided), to indicate the additional errors if the correction tables are
not used. All the fitting error LEs shall be 0.9 probability.

Table 6-1. Universal Image Geometry Model Header record format.

6.7.2.3. Polynomial Records

A Tagged Record Extension for a polynomial record shall use the format specified in Table 6-2.
The same record format shall be used in four different record types, using different record type
values to distinguish among the four polynomial function uses in a universal real-time image
geometry model. Image support data shall include a record for each polynomial used in each sensor
model section of each image. The denominator polynomials shall be omitted when not needed (i.e.,
when the denominator polynomial is 1.0).

No. of
Bytes

Data Item
Description

Format Units Range Comments

6 Record Type A6 – Note 3 Identifies this record type
5 Length of Data I5 Bytes After this field

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9
2 Row Section Number I2 Sections 00 to 08 Note 1
2 Column Section Number I2 Sections 00 to 08 Note 1
1 Maximum Power of Latitude I1 – 0 to 5
1 Maximum Power of Longitude I1 – 0 to 5
1 Maximum Power of Height I1 – 0 to 3

The following field is repeated for each polynomial term: Note 2
22 Polynomial Coefficient E22.15 – –

Notes Description
1. If the sensor model is not divided, there shall be one set of polynomials for the entire image. When one record

contains data for the entire image, the Row and Column Section Number fields shall contain 00.
2. The number of polynomial terms is the product of three integers, each integer being one plus the

corresponding Maximum Power integer. The polynomial coefficients shall be ordered by the numerical value

of the subscript of aijk or bijk, as defined in Section 6.2.
3. The Record Type field contents for the four polynomials shall be:

UMRNPA Row Numerator Polynomial
UMRDPA Row Denominator Polynomial
UMCNPA Column Numerator Polynomial



The OpenGIS™ Abstract Specification Page 33

Volume 7: The Earth Imagery Case (99-107.doc)

UMCDPA Column Denominator Polynomial

Table 6-2. Polynomial record types format.

6.7.2.4. Correction Table Records

A Tagged Record Extension for a correction table shall use the format specified in Table 6-3. The
same record format shall be used in two different record types, using the different type values to
distinguish between tables that are functions of image row and of image column. Image support
data shall optionally include multiple correction tables for each image or each section of an image.
Correction table records shall be omitted when not needed. More than one table of each type shall
be allowed.

No. of
Bytes

Data Item
Description

Format Units Range Comments

6 Record Type A6 – Note 3 Identifies this record type
5 Length of Data I5 Bytes After this field

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9
2 Row Section No. I2 Sections 00 to 08 Note 1
2 Column Section No. I2 Sections 00 to 08 Note 1

22 Table Spacing E22.15 Pixels –
22 Table Offset E22.15 Pixels –

4 Number of Table Entries I3 – 4 to 3025
The following two fields are repeated for each table entry:

5 Image Row Correction F5.1 0.1 pixel ±99.9 Note 2
5 Image Column Correction F5.1 0.1 pixel ±99.9 Note 2

Notes Description

1. When the sensor model is not divided or the correction table data is not divided, these Records shall be for the
entire image. When one record contains data for the entire image, the Row and Column Section Number
fields shall contain 00.

2. These corrections are applied to the image positions computed using the polynomials. When more than one
table is included, the image corrections from all tables shall be added to the uncorrected image row and
column numbers.

3. The Record Type field contents for the two types of correction tables shall be:
UMRCTA Row Correction Table
UMCCTA Column Correction Table

Table 6-3. Correction table record format

6.7.2.5. Monoscopic Accuracy Estimates Records

A Tagged Record Extension for monoscopic accuracy estimates shall use the format specified in
Table 6-4. We propose using one monoscopic accuracy record for each monoscopic image. In
addition, one monoscopic accuracy record could be used for a group of images that have about the
same accuracy, perhaps because they were triangulated together.

Bytes Data Item Name Format Units Range Comments

6 Record Type A6 – Note 2 Identifies this record type
5 Length of Data I5 Bytes After this field
6 Reference Height F6 Meters – Note 1
6 Absolute Accuracy CE F6.2 Meters 0.01 to

999.99
0.9 probability

6 Horizontal Shear F6.2 Meters 0.01 to
999.99

Root mean square of vector
length

5 Number of Images I5 Images 1 to 1000
The following two fields are repeated for each image in group:

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9
1 Number of Relative Accuracy

Distance Bins
I1 Bins 0 to 9



The OpenGIS™ Abstract Specification Page 34

Volume 7: The Earth Imagery Case (99-107.doc)

The following three fields are repeated for each relative accuracy distance bin:
6 Bin Minimum Distance F6 Meters 0 to 999999 Note 2
6 Bin Maximum Distance F6 Meters 0 to 999999
6 Relative Accuracy CE F6.2 Meters 0.01 to

999.99
0.9 probability

Notes Description
1. This height is the one used to estimate the horizontal accuracies.
2. The Record Type field for the two types of monoscopic accuracy records shall contain:

SIMAEA Summary Monoscopic Accuracy Estimates
IIMAEA Individual Monoscopic Accuracy Estimates

Table 6-4. Monoscopic Accuracy Estimates record format

6.7.2.6. Stereoscopic Accuracy Estimates Records

A Tagged Record Extension for stereoscopic accuracy estimates shall use the format specified in
Table 6-5. We propose using one stereoscopic accuracy record for each pair of images that are
expected to be exploited stereoscopically. In addition, one stereoscopic accuracy record could be
used for a group of stereomodels that have about the same accuracy, perhaps because they were
triangulated together.

Bytes Data Item Name Format Units Range Comments

6 Record Type A6 – Note 1 Identifies this record type
5 Length of Data I5 Bytes After this field
6 Absolute Accuracy CE F6.2 Meters 0.01 to

999.99
0.9 probability

6 Absolute Accuracy LE F6.2 Meters 0.01 to
999.99

0.9 probability

6 Y Parallax F6.2 Meters 0.01 to
999.99

Root mean square

6 Horizontal Shear F6.2 Meters 0.01 to
999.99

Root mean square of vector
length

6 Vertical Shear F6.2 Meters 0.01 to
999.99

Root mean square of magnitude

5 Number of Images I5 Images 2 to 1002 Even integers only
The following two fields are repeated for the left and right images of all stereopairs in group:

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9
1 Number of Relative Accuracy

Distance Bins
I1 Bins 0 to 9

The following four fields are repeated for each relative accuracy distance bin:
6 Bin Minimum Distance F6 Meters 0 to 999999 Note 2
6 Bin Maximum Distance F6 Meters 0 to 999999
6 Relative Accuracy CE F6.2 Meters 0.01 to

999.99
0.9 probability

6 Relative Accuracy LE F6.2 Meters 0.01 to
999.99

0.9 probability

Notes Description
1. The Record Type field for the three types of stereoscopic accuracy records shall contain:

SMSAEA Summary Stereoscopic Accuracy Estimates
IMSAEA Individual Model Stereoscopic Accuracy Estimates

Table 6-5. Stereoscopic Accuracy Estimates record format

6.7.2.7. Image Collection Data Record

A Tagged Record Extension for Image Collection Data shall use the format specified in Table 6-6.
One record type shall be used for Image Collection Data, with image support data including one
such record for each image. The codes used for Image Interpretability Rating System, and the
corresponding units and ranges used for Image Interpretability Value, shall be as specified in Table
6-7.



The OpenGIS™ Abstract Specification Page 35

Volume 7: The Earth Imagery Case (99-107.doc)

No. of
Bytes

Data Item
Description

Format Units Range Comments

6 Record Type A6 – USMICA Identifies this record type
5 Length of Data I5 Bytes After this field

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9

80 Image Title A80 – – Optional
6 Sun Azimuth Angle F6.2 Degrees 0.00 to

360.00
Note 1

5 Sun Elevation Angle F5.2 Degrees 0.00 to
90.00

Note 1

4 Imaging Year I4 Years – When known
2 Imaging Month I2 Months 01 to 12 When known
2 Imaging Day I2 Days 01 to 31 When known
2 Imaging Hour I2 Hours 00 to 23 When known
2 Imaging Minute I2 Minutes 00 to 59 When known
2 Imaging Second I2 Seconds 00 to 59 When known

40 Sensor Identification A40 – – Optional
5 Geometric Mean GSD F5.2 Meters 0.01 to

99.99
3 Image Interpretability Rating

System
A3 – – When available

5 Image Interpretability Value F5.2 When defined
2 Aggregation Mode I2 – –

40 Country A40 – – Name or code
3 Number of Bands I3 Bands 0 or 999

The following fields are repeated for each band:
6 Minimum Wavelength I6 Microns Note 2
6 Maximum Wavelength I6 Microns Note 2
10 Pixel Spread Function

Percentages
5 of I2 Percent 00 to 99 Note 3

20 Row Pixel Spread Function 5 of F4.1 Pixel
Spacings

0.0 to 99.9 Note 3

20 Column Pixel Spread Function 5 of F4.1 Pixel
Spacings

0.0 to 99.9 Note 3

Notes Description
1. The Sun Azimuth and Sun Elevation angles shall all be for the ground point at the center of the image, when

these angles vary within the image.
2. Frequency of electromagnetic energy detected in band. Values shall be optional in these fields, with actual

values being included only when available.
3. The Pixel Spread Function fields shall specify the pixel amplitude response to electromagnetic radiation (e.g.,

light within the sensor response band) received at various distances from the effective center of the pixel.
Values shall be optional in these fields, with actual values being included only when available. Five points on
the Pixel Spread Function shall be recorded, with the percent response and pixel position (from the center of
the pixel) being recorded for each point. The percent response values shall be relative to the radiation
response at the center of the pixel. (By definition, the response is 100% at zero distance from the center of the
pixel.) Separate Pixel Spread Function pixel position fields shall be used for the row and column image
directions. The Pixel Spread Function in each axis is assumed to be constant over the image and symmetrical
about the effective center of the pixel.

Table 6-6. Image Collection Data record format. (continued)

 
Image Interpretability Rating System Image Interpretability Value

Code Meaning Units Range

PNI Predicted NIIRS NIIRS 0.00 to 9.90
PRI Predicted NRIS NRIS 0.00 to 9.90

GRD Ground Resolved Distance Meters 0.01 to 99.99
(blank) Interpretability not rated Not applicable Not applicable



The OpenGIS™ Abstract Specification Page 36

Volume 7: The Earth Imagery Case (99-107.doc)

Table 6-7. Image Interpretability Rating System Codes and Values.

6.7.2.8. Ground Point Record

A Tagged Record Extension for a Ground Point shall use the format specified in Table 6-8, with
image support data including one such record for each point. Table 6-9 specifies the coding for the
“Use of Point” field, and Table 6-10 specifies the coding for the “Ground Position Status” field.
Table 6-11 specifies the coding for the “Image Position Status” field.

Bytes Data Item Name Format Units Range Comments

6 Record Type A6 – GRDPTA Identifies this record type
5 Length of Data I5 Bytes After this field

40 Triangulation ID A40 – – If applicable
7 Ground Point ID A7 – –

30 Ground Point Name A30 – –
1 Use of Point I1 – See Table 6-9
1 Ground Position Status I1 – See Table 6-10
8 Geographic Coordinate System A8 – “WGS-84” Note 2
7 Horizontal Units A7 – “Degrees” Of ground coordinates
8 Vertical Coordinate System A8 – “Ellipsoid” Of height or elevation
7 Vertical Units A7 – “Meters” Of ground coordinates

11 Latitude of Point F11.7 Degrees ±90
12 Longitude of Point F12.7 Degrees ±180
8 Height of Point F8.2 Meters ±10000.00
8 Geoid Separation Distance F8.2 Meters ±10000.00 When needed

See Note 1
6 Horizontal Accuracy CE F6.2 Meters 0.00 to 999.99 0.9 probability
6 Vertical Accuracy LE F6.2 Meters 0.00 to 999.99 0.9 probability

108 Ground Position Covariances, 3
by 3 covariance matrix

9 of
F12.4 Meter

2 ±999999.9999

2 Number of Images I2 – 1 to 99
The following seven fields are repeated for each image in which this ground point was measured

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9
1 Image Position Status I1 – See Table 6-11

10 Image Position Row F10.2 Pixels ±999999.99
10 Image Position Column F10.2 Pixels ±999999.99
6 Row Position Accuracy, standard

deviation
F6.2 Pixels 000.00 to

999.99
6 Column Position Accuracy,

standard deviation
F6.2 Pixels 000.00 to

999.99

Notes Description
1. The Geoid Separation Distance is needed only if ground point heights (or elevations) are referenced to the

Geoid or mean sea level, instead of the ellipsoid.
2. Specifies the coordinate system used for the horizontal ground coordinates of this point, including datum,

ellipsoid, and prime meridian.

Table 6-8. Ground Point record format

 
Code Meaning

0 Tie point, to be used or was used in triangulation
1 Z control point, use only height in triangulation
2 XY control point, use only horizontal position in triangulation
3 XYZ control point, use 3-D ground position in triangulation
5 Diagnostic point, or check point, not used in triangulation
6 Triangulation result point, ground 3-D position values computed from image positions by

triangulation
9 Other ground point, undefined use



The OpenGIS™ Abstract Specification Page 37

Volume 7: The Earth Imagery Case (99-107.doc)

Table 6-9. Coding for the “Use of Point” field.

 
Code Meaning

0 Undetermined, ground position values not valid
1 Input, ground position values input from external source
2 Computed, ground position values computed from image positions
9 Other

Table 6-10. Coding for the “Ground Position Status” field

 
Code Meaning

0 Undetermined, image position values are not valid
1 Measured, image position values were measured in this image
2 Computed, image position values were computed from ground position
9 Other

Table 6-11. Coding for the “Image Position Status” field.

6.7.2.9. USMSD File Header Record

One record type shall be used for the USMSD file header, with each USMSD file beginning with
one such record. This record contains file identification information plus a list of all the images
whose support data is included in this file. Each USMSD File Header record shall use the format
specified in Table 6-12.

No. of
Bytes

Data Item
Description

Format Units Range Comments

6 Record Type A6 – USMFHA Identifies this record type
5 Length of Data I5 Bytes After this field

40 Triangulation ID A40 – – If applicable
240 Triangulation Description A240 – – Optional

5 Number of Images I5 Images 1 to 1000
The following two fields are repeated for each counted image

40 Image ID A40 – –
1 Image Support Data Version I1 – 0 to 9

Table 6-12. USMSD File Header record format.

6.7.3. References for Appendix A.

[1] Manual of Photogrammetry, American Society of Photogrammetry, Fourth Edition, 1980

[2] An Essential Specification for Coverages and Images, OpenGIS Project Document 96-024R2, by
Cliff Kottman

[3] An Interface for Earth Image Math Models, OpenGIS Project Document 96-012, by Cliff Kottman

[4] A Universal Image Geometry Model, OpenGIS Project Document 97-003, by Arliss Whiteside


