
 
 
 
 
 

Open Geospatial Consortium 
35 Main Street, Suite 5 
Wayland, MA 01778 

Telephone: +1-508-655-5858 
Facsimile: +1-508-655-2237 

 
Editor:  

percivall@opengeospatial.org 
 

 
 

The OpenGIS® Abstract Specification  
Topic 7: The Earth Imagery Case 

 
Version 5 

 
 
 

 
 
 
 

OpenGIS® Project Document Number 04-107 



   

The OpenGIS® Abstract Specification 

Copyright © 2004, Open Geospatial Consortium, Inc.  

This document does not represent a commitment to implement any portion of this specification in any companys 
products.  
OGCs Legal, IPR and Copyright Statements are found at http://www.opengeospatial.org/about/?page=ipr&view=ipr  
 
NOTICE  
 
Permission to use, copy, and distribute this document in any medium for any purpose and without fee or royalty is 
hereby granted, provided that you include the above list of copyright holders and the entire text of this NOTICE.  
We request that authorship attribution be provided in any software, documents, or other items or products that you 
create pursuant to the implementation of the contents of this document, or any portion thereof.  
No right to create modifications or derivatives of OGC documents is granted pursuant to this license. However, if 
additional requirements (as documented in the Copyright FAQ at 
http://www.opengeospatial.org/about/?page=ipr&view=ipr_faq) are satisfied, the right to create modifications or 
derivatives is sometimes granted by the OGC to individuals complying with those requirements.  
 
THIS DOCUMENT IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR 
WARRANTIES, EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF 
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR TITLE; THAT 
THE CONTENTS OF THE DOCUMENT ARE SUITABLE FOR ANY PURPOSE; NOR THAT THE 
IMPLEMENTATION OF SUCH CONTENTS WILL NOT INFRINGE ANY THIRD PARTY PATENTS, 
COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS.  
 
COPYRIGHT HOLDERS WILL NOT BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL OR 
CONSEQUENTIAL DAMAGES ARISING OUT OF ANY USE OF THE DOCUMENT OR THE PERFORMANCE 
OR IMPLEMENTATION OF THE CONTENTS THEREOF.  
 
The name and trademarks of copyright holders may NOT be used in advertising or publicity pertaining to this 
document or its contents without specific, written prior permission. Title to copyright in this document will at all times 
remain with copyright holders.  
 
RESTRICTED RIGHTS LEGEND. Use, duplication, or disclosure by government is subject to restrictions as set forth 
in subdivision (c)(1)(ii) of the Right in Technical Data and Computer Software Clause at DFARS 252.227.7013  
OpenGIS®, OGC, OpenGeospatial, OpenLS®, Open GIS Consortium, Inc. are trademarks or registered 
trademarks of Open Geospatial Consortium, Inc. in the United States and in other countries.



   

The OpenGIS® Abstract Specification 

Revision History 
 
Date Description 
27 September 
2004 

Replaced previous material in Topic 7 with ISO 19101-2, Reference Model  Geographic 
Information  Imagery.  Version 5 of OGC Topic 7 is identical with ISO 19101-2 Working Draft 
#3.   
 
Topic 7 will be updated jointly with the progress of ISO 19191-2.  
 
Appendix A of Topic 7, version 4 contained a White Paper on Earth Image Geometry Models.  
That white paper is now separate OGC Recommendation document.  

31 March 1999 Bring forward 98-107r1 as 99-107; update for new document template and 1999 copyrights; move 
former section 2.3 to section 1.2; other minor editorial updates (figure and table numbering, etc). 

 



   

The OpenGIS® Abstract Specification 

 

This page is intentionally left blank. 

 



© ISO 2002  All rights reserved 

ii 

 

 

 

ISO TC 211  N  XXX 
Date:   16 August 2004 

ISO 19101-2  Version WD3 

 ISO TS 19101-2 

ISO TC 211/WG 6 

Secretariat:   NSF 

Geographic information  Reference Model  Imagery  
Information géographique Modèle de référence  Imagerie  

Error! AutoText entry not defined. 

 

Document type:   Technical Specification 
Document subtype:    
Document stage:   (30) Commitee 
Document language:   E 
 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved iii

 

Copyright notice 

This ISO document is a working draft or committee draft and is copyright-protected by ISO. While the 
reproduction of working drafts or committee drafts in any form for use by participants in the ISO standards 
development process is permitted without prior permission from ISO, neither this document nor any extract from 
it may be reproduced, stored or transmitted in any form for any other purpose without prior written permission 
from ISO. 

Requests for permission to reproduce this document for the purpose of selling it should be addressed as shown 
below or to ISOs member body in the country of the requester: 

Norwegian Technology Centre 
P.O. Box 7072 Majorstua  
NO-0306  Oslo, Norway 
Tel: + 47 22 59 01 00 
Fax: + 47 22 59 01 29 
e-mail: bjs@nts.no 

Reproduction for sales purposes may be subject to royalty payments or a licensing agreement. 

Violators may be prosecuted. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved iv

 

Contents 

Foreword.................................................................................................................................................................... x 

Introduction............................................................................................................................................................... xi 

1 Scope ................................................................................................................................................................... 1 

2 Conformance ....................................................................................................................................................... 1 

3 Normative references .......................................................................................................................................... 1 

4 Terms and definitions.......................................................................................................................................... 2 

5 Symbols and abbreviated terms ......................................................................................................................... 6 

5.1 Abbreviations .................................................................................................................................................. 6 
5.2 Symbols.......................................................................................................................................................... 6 
5.3 Notation .......................................................................................................................................................... 7 

6 Geographic Imagery Systems............................................................................................................................. 7 

6.1 Geographic imagery as features...................................................................................................................... 7 
6.2 Open distributed processing of geographic imagery......................................................................................... 9 

7 Enterprise viewpoint  community objectives and policies ............................................................................ 10 

7.1 Introduction ................................................................................................................................................... 10 
7.2 Geographic imagery community objective...................................................................................................... 10 
7.3 Geographic imagery scenario........................................................................................................................ 10 
7.4 Geographic imagery policies ......................................................................................................................... 11 

7.4.1 Introduction to policies ............................................................................................................................ 11 
7.4.2 Policy development guidelines ................................................................................................................ 11 
7.4.3 Geographic imagery policies ................................................................................................................... 12 

8 Information viewpoint  knowledge based decisions...................................................................................... 13 

8.1 Introduction to information viewpoint.............................................................................................................. 13 
8.1.1 Creating knowledge from Imagery........................................................................................................... 13 
8.1.2 General feature model ............................................................................................................................ 14 
8.1.3 Topics relevant across data, information, and knowledge ........................................................................ 15 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved v

 

8.2 Geographic imagery data  raw data ............................................................................................................. 17 
8.2.1 Sensors and platforms ............................................................................................................................ 17 
8.2.2 IG_Sensor .............................................................................................................................................. 18 
8.2.3 Passive sensors...................................................................................................................................... 19 
8.2.4 Active sensors ........................................................................................................................................ 22 
8.2.5 Calibration, validation and metrology....................................................................................................... 24 
8.2.6 Position and attitude determination ......................................................................................................... 25 
8.2.7 Image acquisition request ....................................................................................................................... 26 

8.3 Geographic imagery information  processed, located, gridded ..................................................................... 26 
8.3.1 IG_Image................................................................................................................................................ 26 
8.3.2 Derived Imagery ..................................................................................................................................... 31 
8.3.3 Imagery Metadata................................................................................................................................... 34 
8.3.4 IG_Image application specialization ........................................................................................................ 34 
8.3.5 Encoding rules for imagery...................................................................................................................... 34 

8.4 Geographic imagery knowledge  inference and interpretation ...................................................................... 35 
8.4.1 Knowledge from imagery......................................................................................................................... 35 
8.4.2 Image understanding and classification................................................................................................... 35 
8.4.3 IG_KnowledgeBase ................................................................................................................................ 37 

8.5 Geographic imagery for decisions  application context ................................................................................. 39 
8.5.1 Decision Context (IG_Context)................................................................................................................ 39 
8.5.2 Decision fusion ....................................................................................................................................... 41 
8.5.3 Visualization ........................................................................................................................................... 42 

9 Computational viewpoint  services for imagery............................................................................................. 43 

9.1 Task-oriented computation ............................................................................................................................ 43 
9.2 Computational patterns ................................................................................................................................. 44 
9.3 Geographic imagery services ........................................................................................................................ 46 

9.3.1 Geographic imagery human interaction services ..................................................................................... 48 
9.3.2 Geographic imagery model/information management services ................................................................ 48 
9.3.3 Geographic imagery workflow/task management services ....................................................................... 49 
9.3.4 Geographic imagery processing services ................................................................................................ 49 
9.3.5 Geographic communication services ....................................................................................................... 51 

9.4 Service chaining for imagery ......................................................................................................................... 51 
9.5 Service metadata  extensions for imagery ................................................................................................... 52 

10 Engineering viewpoint  deployment approaches......................................................................................... 52 

10.1 Introduction ................................................................................................................................................. 52 
10.2 Distributed system for geographic imagery .................................................................................................. 52 
10.3 Imagery collection node............................................................................................................................... 54 
10.4 Sensor processing node .............................................................................................................................. 55 
10.5 Image archive nodes ................................................................................................................................... 55 
10.6 Value-added processing and exploitation nodes .......................................................................................... 57 
10.7 Decision support nodes ............................................................................................................................... 58 
10.8 Channels: networks and DCPs .................................................................................................................... 58 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved vi

 

10.8.1 Imagery considerations for channels ..................................................................................................... 58 
10.8.2 Space to ground communications.......................................................................................................... 59 
10.8.3 Internet ................................................................................................................................................. 59 

10.9 Persistent implementation ........................................................................................................................... 59 

Annex A  Abstract test suite.................................................................................................................................. 60 

Annex B  ISO Reference model for open distributed processing (RM-ODP) ...................................................... 61 

Annex C  Imagery use cases................................................................................................................................. 62 

C.1 Agricultural irrigation use case ...................................................................................................................... 62 
C.2 Vehicle traffic use case ................................................................................................................................. 62 
C.3 Natural resources use case........................................................................................................................... 63 
C.4 Hurricane evacuation use case ..................................................................................................................... 64 
C.5 Commercial airborne photogrammetry .......................................................................................................... 65 
C.6 Intelligence, surveillance and reconnaissance ............................................................................................... 67 
C.7 Controlling wildfires....................................................................................................................................... 68 
C.8 Digital earth .................................................................................................................................................. 69 
C.9 Earth science vision...................................................................................................................................... 70 

Annex D  Service chaining examples ................................................................................................................... 73 

Annex E  Application area decision tree............................................................................................................... 74 

Annex F  Principles relating to remote sensing of the Earth from space ........................................................... 75 

Bibliography............................................................................................................................................................. 78 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved vii

 

Table of Figures 

Figure 1 - Image state diagram with modifications for geographic imagery ................................................................... 8 

Figure 2  Geographic imaging scenario .................................................................................................................... 11 

Figure 3  - Information viewpoint packages ................................................................................................................ 13 

Figure 4  Semiotic derivation of the information viewpoint......................................................................................... 14 

Figure 5 - Feature modeling extended to imagery....................................................................................................... 15 

Figure 6 - IG_Sensor and associated classes............................................................................................................. 18 

Figure 7 - Electromagnetic spectrum.......................................................................................................................... 19 

Figure 8 - IG_Image................................................................................................................................................... 27 

Figure 9 - IG_ImageValues ........................................................................................................................................ 29 

Figure 10 - IG_DerivedImage..................................................................................................................................... 32 

Figure 11 - Effects of atmospheric scattering.............................................................................................................. 33 

Figure 12  -  Multi-tiered imagery encoding................................................................................................................. 35 

Figure 13  Image knowledge packages .................................................................................................................... 35 

Figure 14  Image classification and understanding class diagram............................................................................. 37 

Figure 15  -  IG_KnowledgeBase ............................................................................................................................... 38 

Figure 16 - Applications based on resolution .............................................................................................................. 40 

Figure 17 - Imagery requirements for selected applications ........................................................................................ 41 

Figure 18  -  Imagery for decision support .................................................................................................................. 44 

Figure 19 - Types of service description..................................................................................................................... 47 

Figure 20 -  Geographic imagery system deployment diagram ................................................................................... 53 

Figure 21  - Imagery collection node deployment diagram.......................................................................................... 54 

Figure 22  -  Sensor processing node deployment diagram ........................................................................................ 55 

Figure 23  -  Imagery archive node deployment diagram ............................................................................................ 56 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved viii

 

Figure 24 -  Image archive node component diagram................................................................................................. 56 

Figure 25  -Value-added processing node deployment diagram ................................................................................. 57 

Figure 26  - Decision support node deployment diagram ............................................................................................ 58 

Figure 27 - NIIA Scope .............................................................................................................................................. 68 

Figure 28 - Geographic imagery processing chain  IEEE/GRSS ............................................................................... 73 

Figure 29 - Geographic imagery processing chain  OGC.......................................................................................... 73 

Figure 30  Application Area Decision Tree................................................................................................................ 74 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved ix

 

Table of Tables 

Table 1   Sources of externally defined UML classes ................................................................................................ 7 

Table 2 - Policy development guidelines .................................................................................................................... 12 

Table 3 - Sources of error in geographic imagery ....................................................................................................... 16 

Table 4  Optical sensing wavelengths ...................................................................................................................... 20 

Table 5  - Optical measurements ............................................................................................................................... 20 

Table 6 - Radar band designations  [IEEE Std 686-1997] ........................................................................................... 22 

Table 7  - Radar measurements................................................................................................................................. 23 

Table 8  -  Positioning systems................................................................................................................................... 26 

Table 9   IG_Image Examples.................................................................................................................................. 28 

Table 10  - IG_Image operations inherited from CV_Coverage................................................................................... 30 

Table 11  -  IG_Image operations............................................................................................................................... 31 

Table 12 - Image classification and understanding classes......................................................................................... 36 

Table 13  Applications and spatial resolution............................................................................................................ 40 

Table 14 - Application area taxonomy ........................................................................................................................ 42 

Table 15  Object factory computational pattern ....................................................................................................... 45 

Table 16  Message-oriented computational pattern................................................................................................. 46 

Table 17   Geographic services taxonomy .............................................................................................................. 48 

Table 18  - Imagery collection node examples............................................................................................................ 55 

Table B-1  Use of RM-ODP viewpoints in this Standard .......................................................................................... 61 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved x

 

Foreword 

ISO (the International Organization for Standardization) is a worldwide federation of national standards bodies (ISO 
member bodies). The work of preparing International Standards is normally carried out through ISO technical 
committees. Each member body interested in a subject for which, a technical committee has been established has the 
right to be represented on that committee. International organizations, governmental and non-governmental, in liaison 
with ISO, also take part in the work. ISO collaborates closely with the International Electrotechnical Commission (IEC) 
on all matters of electrotechnical standardization. 

International Standards are drafted in accordance with the rules given in the ISO/IEC Directives, Part 3. 

Draft International Standards adopted by the technical committees are circulated to the member bodies for voting. 
Publication as an International Standard requires approval by at least 75 % of the member bodies casting a vote. 

Attention is drawn to the possibility that some of the elements of this International Standard may be the subject of 
patent rights. ISO shall not be held responsible for identifying any or all such patent rights. 

International Standard ISO 19129 was prepared by Technical Committee ISO/TC 211, Geographic 
information/Geomatics. 

This international standard contains TBD annexes. Annex TBD is normative; annex TBD is informative. 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2002  All rights reserved xi

 

Introduction 

This Technical Specification provides a reference model for the open distributed processing of geographic imagery.  
The motivating themes addressed in this reference model are: 

• In terms of volume, imagery is the dominant form of geographic information.  
• Stored geographic imagery volume will grow to the order of an exabyte 
• National imagery archives are multiple petabytes in size; ingesting a terabyte per day 
• Individual application data centers are archiving 100s of terabytes of imagery  
• Tens of thousands of datasets have been catalogued but are not yet on-line. 

• Most geographic imagery will never be directly accessed by humans 
• Human attention is the scarce resource, and is insufficient to view petabytes of data. 
• Semantic processing will be required: automatic detection of features; mining based on geographic concepts 

• Information technology allows the creation of geographic information products through processing of geographic 
imagery.  Standards are needed to increase creation of products. 

• A number of existing standards are used for the exchange of geographic imagery.  

• Hurdles to moving imagery online are technical, legal, business 
• Technical issues of accessibility - geocoding, geographic access standards 
• Intellectual property will be stolen. 
• Privacy Impact Assessment 
• Standards are needed 

• Governments have been the predominant suppliers of remote sensed data in the past.  This is changing with the 
commercialization of remote sensed data acquisition.   

• Geographic imagery is a key input to support policy makers in decision support. 

The ultimate challenge is to enable the geographic imagery collected from different sources to become an integrated 
digital representation of the Earth widely accessible for humanities critical decisions. 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 1

 

Geographic information  Reference model  Imagery  

1 Scope 

This Technical Specification defines a reference model for standardization in the field of geographic imagery. This 
reference model identifies the scope of the standardization activity being undertaken and the context in which it takes 
place. The scope will include gridded data with an emphasis on imagery. Although structured in the context of 
information technology and information technology standards, this Technical Specification will be independent of any 
application development method or technology implementation approach..  

2 Conformance 

Any imagery-handling system claiming conformance with the reference model established in this Technical 
Specification shall pass the requirements described in the abstract test suite presented in Annex A.   

3 Normative references 

The following normative documents contain provisions, which through reference in this text constitute provisions of this 
Technical Specification.  At the time of publication, the editions indicated were valid. All standards are subject to 
revision, and parties involved in agreements based on this Technical Specification are encouraged to investigate the 
possibility of applying the most recent editions of the normative documents indicated below. For undated references, 
the latest edition of the normative document referred to applies. Members of IEC and ISO maintain registers of 
currently valid International Standards. 

ISO 31-0:1992, Quantities and units  General principles 

ISO 31-6:1992, Quantities and units - Light and related electromagnetic radiations 

ISO 2382-1:1993, Information technology - Vocabulary - Part 1: Fundamental terms 

ISO 2382-13:1996, Information technology - Vocabulary - Part 13: Computer graphics 

ISO/IEC 10746-1:1998, Information technology  Open Distributed Processing  Reference model: Overview 

ISO/IEC 10746-2:1996, Information technology  Open Distributed Processing  Reference model: Foundations 

ISO/IEC 12087-1:1995, Information technology  Computer graphics and image processing  Image Processing and 
Interchange (IPI) - Functional specification - Part 1: Common architecture for imaging  

ISO 13249-5:2003, Information technology  Database languages  SQL multimedia and application packages  
Part 5: Still image 

ISO/IEC TR 14252:1996, Information technology  Guide to the POSIX Open System Environment (OSE) 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 2

 

ISO 14721:2003, Space data and information transfer systems  Open archival information system  Reference 
model 

ISO 19101:2002 Geographic information  Reference model 

ISO 19107:2003 Geographic information  Spatial schema  

ISO 19108:2002 Geographic information  Temporal schema  

ISO 191091) Geographic information  Rules for application schema  

ISO 191101 Geographic information  Feature cataloguing methodology  

ISO 19111:2003 Geographic information  Spatial referencing by coordinates  

ISO 19115:2003 Geographic information  Metadata  

ISO 19115-21, Geographic information  Metadata  Part 2: Extensions for imagery and gridded data  

ISO 191191, Geographic information  Services  

ISO 191231, Geographic information - Schema for coverage geometry and functions  

ISO 191291, Geographic information - Imagery, gridded and coverage data framework 

ISO 191301, Geographic information - Sensor and data models for imagery and gridded data 

ISO 22028-1:2004, Photography and graphic technology  Extended colour encodings for digital image storage, 
manipulation and interchange  Part 1: Architecture and requirements. 

CIE Publication 17.4, 1987, International Lighting Vocabulary 

OpenGIS Consortium Abstract Specification, Topic Volume 15 - Image Exploitation Services, 2000, OGC document 
00-115.  

4 Terms and definitions 

For the purposes of this Technical Specification, the following terms and definitions apply. 

band  
range of wavelengths of electromagnetic radiation specified to produce a single response to a sensing device. 

computational viewpoint 
viewpoint on an ODP system and its environment that enables distribution through functional decomposition of the 
system into objects which interact at interfaces. [ISO/IEC 10746-2] 

                                                   

1) To be published. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 3

 

coverage 
feature that acts as a function to return values from its range for any direct position within its spatiotemporal domain 
[ISO 19123] 

data  
reinterpretable representation of information in a formalised manner suitable for communication, interpretation, or 
processing [ISO/IEC 2382-1] 

digital number (DN)  
discrete integer value representing a measurement as detected by a sensor 

decision support system 
interactive computer program to aid decision makers in formulating, analyzing, and selecting alternatives 

engineering viewpoint 
viewpoint on an ODP system and its environment that focuses on the mechanisms and functions required to support 
distributed interaction between objects in the system. [ISO/IEC 10746-2] 

enterprise viewpoint 
viewpoint on an ODP system and its environment that focuses on the purpose, scope and policies for that system. 
[ISO/IEC 10746-2] 

feature 
abstraction of real world phenomena [ISO 19101] 

geographic feature 
representation of real world phenomenon associated with a location relative to the Earth [ISO 19125] 

grid 
network composed of two or more sets of curves in which the members of each set intersect the members of the other 
sets in an algorithmic way. [ISO DIS 19123] 

information  
meaning currently assigned to data by means of the conventions applied to these data 

(Editors note: to be consistent with ISO 19118 for information should be used: knowledge concerning objects, such as 
facts, events, things, processes, or ideas, including concepts, that within a certain context has a particular meaning 
[ISO/IEC 2382-1].  This is difficult as the 2382-1 definition says that information is knowledge, whereas this Technical 
Specification defines knowledge as more than information.) 

information viewpoint 
viewpoint on an ODP system and its environment that focuses on the semantics of information and information 
processing. [ISO/IEC 10746-2] 

(geographic) image  
gridded coverage whose range values quantitatively describe physical phenomena. 

NOTE The physical parameters are the result of measurement by a sensor or a prediction from a model. 

imagery  
set of images.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 4

 

interface 
named set of operations that characterize the behaviour of an entity [ISO 19119] 

interoperability 
capability to communicate, execute programs, or transfer data among various functional units in a manner that requires 
the user to have little or no knowledge of the unique characteristics of those units [ISO 2382-1] 

knowledge 
an organized, integrated collection of facts and generalizations. [Need a reference] 

NOTE scientific knowledge - knowledge accumulated by systematic study and organized by general principles; "mathematics is 
the basis for much scientific knowledge" 

knowledge base 
data base of knowledge about a particular subject.  

NOTE: The data base contains facts, inferences, and procedures needed for problem solution. [Webster Computer] 

(measurable) quantity  
attribute of a phenomenon, body or substance that may be distinguished qualitatively and determined quantitatively  
[International Vocabulary of Basic and General Terms in Metrology (VIM)] 

measurement  
set of operations having the object of determining a value of a quantity [International Vocabulary of Basic and General 
Terms in Metrology (VIM)] 

measurand  
particular quantity subject to measurement [International Vocabulary of Basic and General Terms in Metrology (VIM)] 

EXAMPLE    vapour pressure of a given sample of water at 20 °C.  

NOTE The specification of a measurand may require statements about quantities such as time, temperature and pressure. 

(Editors note: this is the definition of measurand in ISO CD 19136: Phenomenon or property that is subject to 
observation.  But VIM is more authoritative than ISO 19136 on this topic.  So, 19136 should adopt VIM definition.) 

observable 
(phenomenon that is derivable from a measurand) 

observable. The fundamental physical quantity or quantities that a sensor can measure, such as temperature which 
through a process of calibration can be related to a Geophysical parameter.   Observables can usually be measured by 
processes traceable to physical standards. (Earth Observing System Calibration Advisory Panel) 

(ISO CD 19136: Observable - Phenomenon or property that is subject to observation.  Observation is not defined in 
19136.  Observation: measurand at a location and time.) 

ontology  
entities and relations for a domain of interest to a community of agents. [derived from IEEE SUO] 

operation 
specification of a transformation or query that an object may be called to execute [ISO 19119] 

NOTE  An operation has a name and a list of parameters. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 5

 

orthoimage 
georectified image in which displacement of objects in the image, due to sensor orientation and terrain relief, have 
been removed. .   

pixel  
picture element 

NOTE It is the smallest unit of display 

remote sensing 
collection and interpretation of information about an object without being in physical contact with the object. 

resolution (of a sensor)  
smallest difference between indications of a sensor that can be meaningfully distinguished  

NOTE For imagery, resolution refers to radiometric, spectral, spatial and temporal resolutions.   

scene 
spectral radiances of a view of the natural world as measured from a specified vantage point in space and at a 
specified time.  [ISO 22028-1] 

NOTE A scene may correspond to an actual view of the natural world or to a computer-generated virtual scene simulating such 
a view. 

semiotics 
systematic investigation of the nature, properties and kinds of signs. 

NOTE semiotics comprises syntactics, semantics and pragmatics (Webster) 

sensor  
element of a measuring instrument or measuring chain that is directly affected by the measurand  [International 
Vocabulary of Basic and General Terms in Metrology (VIM)] 

sensor model 
description of the radiometric and geometric characteristics of a sensor  

(Ed. Note: compare with description of the radiometric and geometric characteristics of the sensor including position 
and orientation of the instrument measuring the data [19130]) 

service 
distinct part of the functionality that is provided by an entity through interfaces [ISO/IEC TR 14252] 

taxonomy 
ontology with constraints for subtyping, covering and partition. [Derived from IEEE SUO] 

NOTE  A taxonomy is a formally defined ontology 

technology viewpoint 
viewpoint on an ODP system and its environment that focuses on the choice of technology in that system. [ISO/IEC 
10746-2] 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 6

 

traceability 
property of the result of a measurement or the value of a standard whereby it can be related to stated references, 
usually national or international standards, through an unbroken chain of comparisons all having stated uncertainties 
[International Vocabulary of Basic and General Terms in Metrology (VIM)] 

uncertainty of measurement 
parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could 
reasonably be attributed to the measurand  

NOTE 1 The parameter may be, for example, a standard deviation (or a given multiple of it), or the half-width of an interval 
having a stated level of confidence.  

NOTE 2 Uncertainty of measurement comprises, in general, many components. Some of these components may be evaluated 
from the statistical distribution of the results of series of measurements and can be characterized by experimental standard 
deviations. The other components, which can also be characterized by standard deviations, are evaluated from assumed probability 
distributions based on experience or other information.  

NOTE 3 It is understood that the result of the measurement is the best estimate of the value of the measurand, and that all 
components of uncertainty, including those arising from systematic effects, such as components associated with corrections and 
reference standards, contribute to the dispersion. 

viewpoint (on a system) 
form of abstraction achieved using a selected set of architectural concepts and structuring rules, in order to focus on 
particular concerns within a system. [ISO/IEC 10746-2] 

5 Symbols and abbreviated terms 

5.1 Abbreviations 

The following abbreviations are used in this Technical Specification. 

DCP Distributed Computing Platform 
IT Information Technology 
ODP Open Distributed Processing (see RM-ODP) 
OGC Open GIS Consortium 
RM-ODP Reference Model of Open Distributed Processing (ISO/IEC 10746) 
TBS To Be Supplied 
UML Unified Modelling Language 
VIM International Vocabulary of Basic and General Terms in Metrology 
XML Extensible Markup Language 
 

5.2 Symbols 

TBS 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 7

 

5.3 Notation 

The conceptual schema specified in this Technical Specification is described using the Unified Modelling Language 
(UML) [3], following the guidance of ISO/TS 19103.  Several model elements used in this schema are defined in other 
ISO standards developed by ISO/TC 211.  Names of UML classes, with the exception of basic data type classes, 
include a two-letter prefix that identifies the standard and the UML package in which the class is defined.  Table 2 lists 
the other standards and packages in which UML classes used in this International Standard have been defined. 

Table 1   Sources of externally defined UML classes 

Prefix Standard Package 

CV ISO 19123 Coverages 

FC ISO 19110 Feature catalgouing 

IG ISO 19101-2 Reference model - Imagery 

MD ISO 19115 Metadata 

PS ISO 19116 Positioning services 

 

6 Geographic Imagery Systems 

6.1 Geographic imagery as features  

In the ISO 19100 series of standards a geographic image is a type of coverage, and a coverage is a type of feature. 

A feature is an abstraction of real world phenomena (See ISO 19101). A geographic feature has implicit or explicit 
reference to a location relative to the Earth.  

A coverage is a feature that acts as a function to return values from its range for any direct position within its 
spatiotemporal domain (See ISO 19123).  Examples of coverages include an image, a polygon overlay, or a digital 
elevation matrix. 

A grid may be used to structure the domain of a coverage.  As defined in ISO 19123, a grid is a network composed of 
two or more sets of curves in which the members of each set intersect the members of the other sets in an algorithmic 
way. 

A geographic image shall be a gridded coverage whose range values quantitatively describe physical phenomena.   

Physical quantities, as defined in IS0 31-0 Quantities and units - Part 0: General principles, shall be used in a 
geographic image for the quantitative description of physical phenomena.  Conventional scales, such as the Beaufort 
scale, Richter scale, colour intensity scales, and land cover classification, shall not be used as range values for a 
geographic image.  Conventional scales may be used in other types of geographic coverages.  The physical quantities 
of a geographic image may be the result of measurement by a sensor or from a prediction by a physical model.  

The definition for geographic image is tightly constrained in this Technical Specification following the semiotic concept 
of icon.  Geographic imagery as iconic signs have a relationship that shall be very precise, such that relationships 
among elements in a geographic image are isomorphic to relationships among elements in the object.  A photograph of 
a geographic scene conforms to this definition. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 8

 

Requiring the data of an image to be organized in a grid reflects that an image is a uniform method for representing the 
physical phenomena.  A random set of point data from a sensor is not an image. 

It is useful to distinguish between image as used in this Technical Specification, and the colloquial use of the term 
image. As used in this Technical Specification, an image is a representation of image data within a computer system.  
To view an image, a presentation process is required.   The definition used in this Technical Specification is consistent 
with image (or digital image) as defined in ISO/IEC 12087-1:  Common architecture for imaging. 

To place geographic imagery in the larger context of digital imagery, various types of image encodings are shown in 
the image state diagram of Figure 1.  Figure 1 is nearly identical to the image state diagram of ISO 22028-1:2004, 
Photography and graphic technology  Extended colour encodings for digital image storage, manipulation and 
interchange  Part 1: Architecture and requirements. ISO 22028-1 categorizes image encodings into scene-referred or 
picture-referred image states.  

 
Figure 1 - Image state diagram with modifications for geographic imagery  

 

Scene-referred encodings are representations of an original scene, where a scene is defined to be the spectral 
radiances of a view of the natural world as measured from a specified vantage point in space and at a specified time. 
Scene-referred image data may correspond to an actual view of the natural world, or to a computer-generated virtual 
scene simulating such a view. To accommodate geographic imagery, this Technical Specification has modified the 
image state diagram of ISO 22028-1 by changing from “Scene-referred coulour encoding” to “Scene-referred image 
encoding.”  Geographic imagery makes use of a much broader spectrum than the colours addressed by ISO 22028-1.  
This Technical Specification applies the approach of feature modeling of the 19100-series of international standards to 
the Scene-referred image encodings. This Technical Specification emphasizes images derived from scene-referred 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 9

 

image encodings, such as derivation of geophysical values based on sensor measurements.  These derived images 
are also considered to be scene-referred image encodings. 

Picture-referred colour encodings are representations of the colour-space coordinates of a hardcopy or softcopy image. 
Picture-referred colour encodings can be further subdivided into original-referred colour encodings and output-referred 
colour encodings.  

Original-referred colour encodings are representative of the colour-space coordinates (or an approximation thereof) of 
a two-dimensional hardcopy or softcopy input image. For geographic information, original-referred colour encodings 
could be obtained from printed maps, printed pictures of a geographic scene, drawings of geographic information, etc.  
Although an original-referred colour encoding may be of a picture of a geographic scene, because the picture was 
previously colour-rendered for printing, it is not a scene-referred image encoding. 

Output-referred colour encodings are representative of the colour-space coordinates of image data that are appropriate 
for a specified real or virtual output device and viewing conditions. Output-referred colour encodings are tightly coupled 
to the characteristics of a particular real or virtual output device and viewing conditions.  Portrayal of geographic 
information is addressed in ISO 19117, Geographic Information – Portrayal. 

Picture-referred colour encodings are colour encodings of any type of geographic information including, but not limited, 
to geographic imagery.  Issues such as false-colour rendering must be addressed to transform the broader spectrum of 
geographic imagery into colour imagery.  Picture-referred colour encodings are addressed in this Technical 
Specification in Clause 8.5.3, Visualization. 

6.2 Open distributed processing of geographic imagery 

The objective of this Technical Specification is the coordinated development of standards that allow the benefits of 
distributed geographic image processing to be realized in an environment of heterogeneous IT resources and multiple 
organizational domains.  An underlying assumption is that uncoordinated standardization made according to no plan, 
cannot be united under a necessary framework.   

This Technical Specification provides a reference model for the open, distributed processing of geographic imagery.  
The basis for defining an information system in this specification is the Reference Model for Open Distributed 
Processing (RM-ODP).  (See Annex B for a brief description of RM-ODP.)  The basis for defining geographic 
information in this specification is the ISO 19100 series of standards. 

The RM-ODP viewpoints are used in the following fashion: 

- Typical actors and their business activities and policies to carry out the activities of  are addressed in the 
Enterprise Viewpoint. 

- Data structures and the progressive addition of value to the resulting products are found in the schemas of the 
Information Viewpoint. 

- Individual processing services and the chaining of services in  are addressed in the Computational Viewpoint 

- Approaches to deploy the components of the Information and Computational viewpoints to distributed physical 
locations are addressed in the Engineering Viewpoint. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 10

 

7 Enterprise viewpoint  community objectives and policies 

7.1 Introduction 

The Enterprise viewpoint on an ODP system and its environment focuses on the purpose, scope and policies for that 
system. [ISO/IEC 10746-2]  The purpose is provided as the objective of the geographic imagery community.  The 
scope is defined through a high-level scenario in this clause and through a of use cases in Annex C.  Policies are 
discussed in this clause through a set of critiera for developing policies for geographic imagery systems as well as 
several example international policies relating to geographic imagery. 

7.2 Geographic imagery community objective 

The central concept of the enterprise viewpoint is how the geographic imagery community interacts to enable imagery 
collected from different sources to become an integrated digital representation of the Earth widely accessible for 
humanities critical decisions.  The enterprise viewpoint provides the traceability between this objective and the system 
design for distributed geographic imagery processing systems.  

The fundamental goal of the Geographic imagery community is to advance and protect interests of humanity by 
development of imaging capabilities, and by sustaining and enhancing the Geographic imagery industry. Doing so will 
also foster economic growth, contribute to environmental stewardship, and enable scientific and technological 
excellence. 

7.3 Geographic imagery scenario 

Figure 3 provides a geographic imagery scenario.  The context is that a customer requests geographic imagery 
information to be used with other information, including other geographic information, in support of a decision. 

The customers request for geographic imagery information is assessed in the planning step.  The customers desired 
information may be readily available from an archive or a model, or may be processed from information in an archive or 
available from a model.  Here a model is a simulation of some portion of the geographic environment able to produce 
geographic imagery.  Some additional processing may be needed of the archive or model outputs in order to meet the 
customers request. 

The customers request for geographic imagery may require collection of new imagery.  Tasking determines the 
available sensors and platforms and develops an imagery acquisition request. The sensor is tasked to acquire the raw 
data and the acquisition is performed. Acquisition of the imagery data is done in accordance with the acquisition 
policies. 

Whether the customers request is to be satisfied from an archive holding, a model output, or a data acquisition, 
typically some type of additional processing is needed.  This could range from changing the encoding format of the 
imagery to creating of derived imagery or image knowledge products.  The resulting imagery information many be 
applied with additional information to form a response that meets the customers needs.  Distribution of the imagery 
information response is done in accordance with the distribution policies. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 11

 

 
Figure 3  Geographic imaging scenario 

 

7.4 Geographic imagery policies 

7.4.1 Introduction to policies 

A policy, as defined in ISO/IEC 10746-2, is a set of rules related to a particular purpose.  A rule can be expressed as 
an obligation, a permission or a prohibition. Not every policy is a constraint.  Some policies represent an 
empowerment.  

7.4.2 Policy development guidelines 

Guidelines for development of policies for geographic imagery are listed in Table 2.  Here "policy" refers primarily to 
issues of ownership, terms and conditions of use and charging for geographic information. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 12

 

Table 2 - Policy development guidelines 

Stability Stability of data and services over time is essential so that investment 
decisions can be made with a correct understanding of the conditions of the 
future marketplace. 

Specific policies include continuity in data collection, consistency in format, 
frequency of observations, and access to comparable data over time. 

Simplicity Access to geographic imagery is subject to many interpretations driven by 
the variety of people and organizations with informed opinions about the 
subject. Simple policies that avoid the pitfalls of becoming too deeply 
entrenched in implementation are necessary. 

Fair treatment. Given that much geographic imagery is publicly funded, there is a concern 
for fair treatment to be applied and to be seen to be applied.  This means 
explicit conditions of access that do not arbitrarily favor one group or 
penalize another group. 

Growth. Growth in the types, extent and volume of geographic imagery is desired. 
Policies that support growth are critical.  

Maximum access There is widespread interest in maximizing the use of geographic imagery. 
Image access should follow open standards to allow the integrated use of 
imagery from multiple sources. 

Sustainablity A combination of high investment costs plus a high potential value of the 
data in the long-term means that the value of a sustainable geographic 
imagery sector should not disappear shortly after applications have been 
brought to a mature stage. 

Data preservation shall be addressed by all image archiving as a routine 
part of the data production process to ensure continuity of the data record 
and to avoid inadvertent loss of usable data. 

 

7.4.3 Geographic imagery policies 

7.4.3.1 Introduction 

This clause contains geographic imagery policies promulgated by international organizations that may apply to a 
particular geographic imagery system. 

7.4.3.2 Imagery acquisition policies 

The Principles Relating to Remote Sensing of the Earth from Space was adopted by the United Nations on 3 
December 1986 (Resolution 41/65) through the efforts of the UN Committee on the Peaceful Uses of Outer Space 
(COPUOS) as part of the progression of formulating international rules to enhance opportunities for international 
cooperation in space.  These principles are contained in an Annex of this Technical Specification. 

The World Meteorological Organization (WMO) has drafted a Handbook Use of Radio-Frequency Spectrum for 
Meteorology.  This handbook identifies radio frequencies that are critical to meteorological measurements.  These 
measurements would be degraded by radio transmission from non-meteorologic sources.  This handbook is under 
consideration by the IEC.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 13

 

7.4.3.3 Imagery distribution policies 

WMO Resolution 40 --"WMO Policy and Practice for the Exchange of Meteorological and Related Data and Products 
Including Guidelines on Relationships in Commercial Meteorological Activities"  to be published as an ITU-R 
Handbook 

7.4.3.4 Enterprise development policies 

A policy of standardization for data and interfaces is one of the essential building blocks of the Information Society. 
There should be particular emphasis on the development and adoption of international standards. The development 
and use of open, interoperable, non-discriminatory and demand-driven standards that take into account needs of users 
and consumers is a basic element for the development and greater diffusion of Information and Communication 
Technologies and more affordable access to them.   [World Summit on the Information Society, 12 December 2003, 
Declaration B.44] 

8 Information viewpoint  knowledge based decisions 

8.1 Introduction to information viewpoint 

8.1.1 Creating knowledge from Imagery 

The geographic imagery information viewpoint in this Technical Specification identifies the various types of geographic 
information and shows the relationships of raw sensed data to higher semantic content information and knowledge. As 
defined in ISO/IEC 10746-1, an information viewpoint specification of an ODP system focuses on the semantics of 
information and information processing.  The information viewpoint is structured following a semiotic approach to 
geographic imagery.  The resulting structure of the viewpoint is reflected in the UML packages (Figure 4).  The 
contents of these packages are addressed in the following clauses of this viewpoint. 

 
Figure 4  - Information viewpoint packages 

 

Geographic images are used to signify something about the environment; as such images are signs.  Semiotics is the 
systematic investigation of the nature, properties and kinds of signs in general.  Images are non-linguistics signs, i.e., 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 14

 

icons.  Elements of semiotics form the approach of this information viewpoint on geographic imagery.  Semiotics 
comprises the syntactics, semantics and pragmatics of signs.  Figure 5 presents the semiotic-derived structure for the 
information viewpoint2. 

Decisions

Knowledge

Information

Data

Data with meaning
assigned

Integrated model of
information

Pragmatic application of
knowledge

Representation subject to
interpretation

Compression of
redundancies

Representation is
described

Goals of multiple
stakeholders

 
Figure 5  Semiotic derivation of the information viewpoint 

 
Data (Figure 5, bottom layer) is a reinterpretable representation of information in a formalised manner suitable for 
communication, interpretation, or processing [ISO/IEC 2382-1]. For imagery, data is the result of a measurement by a 
sensor at a location. 

Applying conventions or agreed-upon codes is the transition from data to information.  Structuring the sensor data in a 
standard syntax allows for transmission of the data to entities in the open distributed processing system.  Information 
then is meaning currently assigned to data by means of the conventions applied to these data 

(Editors note: ISO 19118 uses this definition of Information: knowledge concerning objects, such as facts, events, 
things, processes, or ideas, including concepts, that within a certain context has a particular meaning [ISO/IEC 2382-
1].  ISO 19118 defines information as a type of knowledge whereas this Technical Specification explicitly separates 
information and knowledge.) 

As information is gathered, regularities that are observed, are generalized and models are developed forming the 
transition to knowledge.  Knowledge is an organized, integrated collection of facts and generalizations.  Imagery can be 
interpreted based on a model of feature types that correspond to a universe of discourse.  The resulting feature-based 
description of a scene is described in the General feature model clause. 

The knowledge base is used in the formation of pragmatic decisions that addresses the goals of multiple stakeholders.  
Key to effective decisions is identifying the context in which the decision applies.  The context determines what 
information is relevant to the decision. 

8.1.2 General feature model 

Geographic imagery is a type of geographic information.  The ISO 19100-series of International Standards define a 
conceptual modeling approach for geographic information.  ISO 19101, Geographic Information  Reference Model, 
defines Conceptual Modeling and the Domain Reference Model that this Technical Specification extends for 

                                                   

2 Adapted from A Theory of Computer Semiotics, Peter Andersen, Cambridge Press, 1997 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 15

 

geographic imagery.  ISO 19109 defines the General Feature Model that is used throughout the ISO 19100-series.  
The Conceptual Modeling approach that is the basis for the General Feature Model is extended to geographic Imagery 
in Figure 6. 

 
Figure 6 - Feature modeling extended to imagery 

The left side of Figure 6, derived from ISO 19109, shows the process of structuring data from the universe of discourse 
to the geographic dataset. The definitions of the feature types and their properties, as perceived in context of an 
application field, are derived from the universe of discourse. A feature catalogue documents the feature types. An 
application schema defines the logical structure of data and may define operations that can be performed on or with 
the data.  

The right side of Figure 6 shows the process of sensing data in the environment that can be processed to provide 
measurements of physical quantities or to be interpreted as a set of discrete features.  The physical quantities and their 
properties, as perceived in context of an application field, are derived from the universe of discourse.  An attribute 
catalog documents the physical quantities as attribute types.  Derived images are specializations of geographic 
images.  An interpreted scene is not an image, but rather a discrete coverage or feature collection. 

Elements on the right side of Figure 6 are defined in this Information Viewpoint. Sensors and the resulting data are 
described in the Data clause.  Image, Derived image, and the physical quantities in an attribute catalogue are 
described in the Information clause.  Interpreted image is described in the Knowledge clause. 

8.1.3 Topics relevant across data, information, and knowledge 

8.1.3.1 Resolution 

Resolution is the smallest difference that can be distinguished in a data element.  For a digital device, this is the 
change in the indication when the least significant digit changes by one bit. Resolution is a measure of the ability of a 
sensor to render a sharply defined image. It may be expressed in many ways depending on the sensor.  For imagery, 
resolution refers to radiometric, spectral, spatial and temporal resolutions.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 16

 

Radiometric resolution is the amount of energy required to increase a pixel value by one quantization level or 'count'. 
Radiometric resolution measures sensitivity in discriminating between intensity levels. 

Spectral resolution is the total range of reflectance (the width and number of bands in the electromagnetic spectrum) of 
a given band to produce an image.  Spectral resolution measures sensitivity in discriminating between wavelengths. 

Spatial resolution is expressed in digital images as pixel ground resolution. Pixel ground resolution defines the area of 
the ground represented in each pixel in X and Y components.  Sometimes this is referred to as the ground sample 
distance (GSD) or ground sample interval (GSI).    

Related to the spatial resolution is the Instantaneous Geometric Field of View (IGFOV).  IGOV is the geometric size of 
the image projected by the detector on the ground through the optical system. IGOV is also called pixel footprint.  ISO 
19123 defines the related concept of CV_Footprint.   A CV_Footprint is the sample space of a grid in an external 
coordinate reference system, e.g., a geographic CRS or a map projection CRS. 

8.1.3.2 Uncertainty in Imagery 

Understanding and estimating the uncertainty in image data is important for absolute measurements of phenomena as 
well as for data integration.  Example sources of error in geographic imagery (Table 3) arise from across the many 
elements of image processing. 

Table 3 - Sources of error in geographic imagery 

Acquisition Geometric aspects 

Sensor systems 

Platforms 

Ground Control 

Scene Considerations 

Data Processing Geometric Rectification 

Radiometric Rectification 

Data Conversion 

Data Analysis Quantitative Analysis 

Classification system 

Data Generalization 

Data Conversion Raster to Vector 

Vector to Raster 

Error Assessment Sampling 

Spatial Autocorrelation 

Locational Accuracy 

Error Matrix 

Discrete Multivariate Statistics 

Reporting Standards 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 17

 

Final Product Presentation Spatial Error 

Thematic Error 

Decision Making  
 

(Ed. Note: table of sources of error needs to be improved.  Change to match sections of 19101-2.  Relate to ISO 
19113) 

8.1.3.3 Imagery Fusion 

Imagery fusion is the combining of imagery and other sources of geospatial information to improve the understanding 
of a specific phenomena.  Fusion may be performed at several levels: pixel, feature, decision.  These different types of 
fusion are addressed in the multiple clauses of the information viewpoint. 

8.2 Geographic imagery data  raw data 

8.2.1 Sensors and platforms 

Clause 8.2, focuses on the data as produced by the sensor, e.g., DNs and radiances at the sensor inputs.  Estimating 
the phenomenon at the remote object, e.g, reflectances, is discussed in a later clause. 

Sensors are describe in two major classes passive and active.  Passive sensors include optical and microwave 
sensors.  Active sensors include radar, lidar, and sonar 

UML classes defined in this clause are shown in Figure 7. 

(Editors note: Remember to discuss these classes as abstract classes. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 18

 

 

Figure 7 - IG_Sensor and associated classes 
 

8.2.2 IG_Sensor 

The attribute values of an image are a numerical representation of a physical parameter.  The values for a physical 
parameter at a given time and place are obtained by conducting a measurement using a sensor.  An imaging sensor 
performs multiple measurements to populate a grid of values.  This clause focuses on sensors, the data they produce, 
the methods for creating a grid of values, and the uncertainty of the sensor data.   

Most imagery data is obtained by remote sensing which aims to measure attributes of a real world phenomenon 
without being in mechanical contact with the phenomenon.  The main type of remote sensing is radiometry  the 
measurement of the quantities associated with radiant energy, i.e., electromagnetic radiation.   

Electromagnetic radiation is commonly classified as a function of wavelength across the Electromagnetic Spectrum 
(Figure 8).  Sensors are designed to be sensitive to particular bands of the spectrum, e.g. visible band.  A band is 
range of wavelengths of electromagnetic radiation specified to produce a single response to a sensing device.  Multi-
spectral radiometers measure radiance in several wavelength bands over a given spectral region. Hyperspectral 
radiometers detect hundreds of very narrow spectral bands throughout the visible and infrared portions of the 
electromagnetic spectrum.   

The immediate output of a digital sensor is Digital Numbers (DNs). Prior to deployment, a sensor is calibrated in a 
laboratory using standard radiation sources.  Using a calibration curve, DNs are mathematically converted to sensor 
input radiances.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 19

 

The resolution of a sensor is defined by several quantities.  The band structure for a sensor determines its spectral 
resolution.  The radiometric sensitivity of a sensor for a specific band is the radiance increment for a single bit change 
in the DN.  The spatial resolution of the sensor is the solid angle for which the sensor measures radiances.   

In addition to sensing the radiance in a band, additional measurements can be made.  An interferometer is a device 
combining two different parts of the same wave front into a single wave, causing the two parts to alternatively reinforce 
and cancel one another.  

 

 
Figure 8 - Electromagnetic spectrum 

 
8.2.3 Passive sensors 

8.2.3.1 Optical sensing 

8.2.3.1.1 General description 

Optical radiation is electromagnetic radiation at wavelengths between region of transition to X-rays (λ ~ 1 nm) and the 
region of transition to radio waves (λ ~ 1mm).  [CIE publication 17.4]   Optical radiation includes infrared, visible and 
ultraviolet radiation (Table 4). 

Visible radiation is any optical radiation capable of causing a visual sensation directly [CIE publication 17.4].  There are 
no precise limits for the spectral range of visible radiation since they depend upon the amount of radiant power 
reaching the retina and the responsivity of the observer.  The lower limit is generally taken between 360 nm and 400 
nm and the upper limit between 760 nm and 830 nm. 

Infrared radiation is Optical radiation for which the wavelengths are longer than those for visible radiation. [CIE 
publication 17.4] 

Ultraviolet radiation is Optical radiation for which the wavelengths are shorter than those for visible radiation. [CIE 
publication 17.4] 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 20

 

Table 4  Optical sensing wavelengths 

Ultraviolet radiation From 100 nm to 400 nm 

Ultraviolet UV-A Band 315 to 400 nm 

Ultraviolet UV-B Band 280 to 315 nm 

Ultraviolet UV-C Band 100 to 280 nm 

Visible Radiation (no precise limits) Lower limit between 360 nm 
and 400 nm 
Upper limit between 760 nm 
and 830 nm. 

Infrared radiation 780 nm to 1 mm 

Infrared IR-A Band 780 to 1400nm 

Infrared IR-B Band 1.4 to 3 µm 

Infrared IR-C Band 3 µm to 1mm 
 

8.2.3.1.2 Measurements 

Optical sensors measure the radiant energy in bands. 

Table 5  - Optical measurements  
 

 

An image is a grid of values from a geographic extent.  Different sensors produce the grid of values in different 
manners, e.g., in a single measurement, scanning and measuring over time.  Examples of scan geometries: 

o Frame camera or sensor array 

o Scan linear array 

Quantity  ISO 31-6 Quantities and Units - Light and related 
electromagnetic radiations 

Radiant Energy  Energy emitted, transferred or received as radiation 

Radiant Flux (power)  Power emitted, transferred or received as radiation 

Irradiance  At a point on a surface, the radiant energy flux incident on an 
element of the surface, divided by the area of that element 

Radiance  At a point on a surface and in a given direction, the radiant 
intensity of an element of the surface, divided by the area of 
the orthogonal projection of this element on a plane 
perpendicular to the given direction 

Radiant Intensity  In a given direction from a source, the radiant energy flux 
leaving the source, or an element of the source, in an element 
of solid angle containing the given direction, divided by that 
element of solid angle 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 21

 

o Push-broom sensor 

o Whisk-broom sensor 

o Conic scanning sensor 

(Editors note:  This section needs to be reviewed with respect to topics in common with ISO19130.) 

8.2.3.1.3 Derivable information 

(Editors note: provides summary of optical remote sensing applications.) 

8.2.3.2 Passive microwave 

8.2.3.2.1 General description 

Microwave radiation is Electromagnetic radiation at frequencies above 1 Ghz [derived from IEEE]. 

Vertically and horizontally polarized measurements are taken for all frequencies. 

8.2.3.2.2 Measurements 

An imaging radiometer maps the brightness temperature distribution over a field of view (FOV). An aperture radiometer 
does it by scanning the FOV either mechanically or electrically across.  Brightness temperature is the measurand. 

The temperature equivalent power detected by a  radiometer (TRAD) can be decomposed into several sources. The 
first source  is the brightness temperature (TB), defined as the beam averaged thermal  emission incident on the 
radiometer antenna from the direction of its main  beam. TB is itself a component of the antenna temperature (TA), 
which is the beam averaged thermal emission incident on the antenna from all directions.  The relationship between TA 
and TRAD depends on the method used to calibrate  the radiometer. If calibration is referenced to the input of the 
antenna  (e.g. by surrounding it by warm or cold absorber loads), then they are  equal. If calibration is achieved by 
switching the input to the radiometer  from the antenna to separate warm or cold loads, then the reference point is  the 
input to that switch. In the latter case, the contribution of TA to TRAD  is reduced by hardware losses between the 
antenna and the switch, and an  additional component of TRAD is contributed by thermal emission from the  lossy 
hardware.  

Absolute calibration of a radiometer implies a conversion  from measurements of TRAD to estimates of TB (TB is then 
the input to  subsequent geophysical data processing and analysis). The conversion from  TRAD to TB can be 
decomposed according to the sources of TRAD. TA  calibration implies conversion from TRAD to TA. This step 
accounts for  thermal emission by and losses due to the radiometer hardware, as noted  above, and also corrects for 
non-ideal emission/reflection properties of the  calibration loads. TB calibration implies conversion from TA to TB. This  
step is essentially an antenna deconvolution process, which typically  involves an estimate of the relative sensitivity of 
the antenna within and  outside of its main beam, together with an estimate of the thermal emission  incident on the 
antenna outside of its main beam. 

8.2.3.2.3 Derivable information 

Passive microwave measurements can be used to derive the following geophysical quantities: rainfall, sea surface 
temperature, vertical water vapor, ocean surface wind speed, sea ice parameters, snow water equivalent, soil surface 
moisture. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 22

 

Over land, the standard products include soil moisture, rainfall, and snow cover water content.  

Geophysical quantities derived from microwave measurements enable investigation of atmospheric and surface 
hydrologic and energy cycles.  

Spatial resolution of passive microwave data is from multiple to 10s of kilometers 

8.2.4 Active sensors 

8.2.4.1 Radar 

8.2.4.1.1 General description 

Radar is an electromagnetic system for the detection and location of objects that operates by transmitting 
electromagnetic signals, receiving echos from objects (targets) within its volume of coverage, and extracting location 
and other information from the echo signal. [IEEE Std 686-1997] 

Radar is an active radio detection and ranging sensor that provides its own source of electromagnetic energy.  A radar 
sensor emits microwave radiation in a series of pulses from an antenna.  When the energy reaches the target, some of 
the energy is reflected back toward the sensor.  This backscattered microwave radiation is detected, measured, and 
timed.  The time required for the energy to travel to the target and return back to the sensor determines the distance or 
range to the target.  By recording the range and magnitude of the energy reflected from all targets as the systems 
passes by, an image of the surface can be produced.  Because radar provides its own energy source, images can be 
acquired day or night.  Also microwave energy is able to penetrate clouds and most rain. 

Table 6 - Radar band designations  [IEEE Std 686-1997] 

L-band 1 GHz and 2 GHz 
S-band 2 GHz and 4 GHz 
C-band 4 GHz and 8 GHz 
X-band 8 GHz and 12 GHz 
Ku-band 12 GHz and 18 GHz 
K-band 18 GHz and 27 GHz 
Ka-band 27 GHz and 40 GHz 
V-band 40 GHz and 75 GHz 
W-band 75 GHz and 110 GHz 

 

8.2.4.1.2 Measurements 

Radar systems make the following measurements: 

• Intensity of microwave radiation at sensor 

• Time taken for the emitted pulse of radiation to travel from the sensor to the ground and back 

• Doppler shift in the frequency of the radiation echo as a result of relative motion of sensor and the ground 

• Polarization of the radiation 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 23

 

Table 7  - Radar measurements 
 

 

Spatial resolution for radar is defied by a resolution cell. a resolution cell is a one-dimensional or multidimensional 
region related to the ability of a radar to resolve multiple targets.   For radar dimensions that involve resolution can 
include range, angle, and radial velocity (Doppler frequency). 

8.2.4.1.3 Derivable information 

Imaging radar is high-resolution radar whose output is a representation of the radar cross section with the resolution 
cell (backscatter coefficient) from the object or scene resolved in two or three spatial dimensions. The radar may use 
real aperture (such as a sidelooking airborne radar), synthetic-aperture radar (DAR), inverse synthetic aperture radar 
(ISAR), interferometric SAR, or tomographic techniques. 

SAR is coherent radar system that generates a narrow cross range impulse response by signal processing (integrating) 
the amplitude and phase of the received signal over an angular rotation of the radar line of sight with respect to the 
object (target) illuminated. [IEEE Std 686-1997]  Due to the change in line-of-sight direction, a synthetic aperture is 
produced by the signal processing that has the effect of an antenna with much larger aperture (and hence a much 
greater angular resolution). 

SAR Imaging Modes: 

o Stripmap: antenna pointing is fixed relative to flight line(usually normal to the flight line). The result is a 
moving antenna footprint that sweeps along a strip of terrain parallel to the path motion. 

o Spotlight: The sensor steers its antenna beam to continuously illuminate a specific (predetermined) spot or 
terrain patch while the platform moves in a straight line. 

Quantity  Measurand [IEEE Std 686-1997] 

Backscatter Energy reflected or scattered in a direction opposite to that of 
the incident wave 

Backscatter coefficient Normalized measure of radar return from a distributed 
scatterer.  

- For area targets, backscatter is expressed in decibels 
and denoted by σo, which is dimensionless but is 
sometimes written in units of m2/m2 for clarity.   

- For volume scatter, such as that from rain, chaff, or 
deep snow cover, it is defined as the average 
monostatic radar cross section per unit volume and is 
express in units of m2/m3 or  m-1.  The volume 
backscatter coefficient is often expressed in decibels 
and denote by the symbol ην. 

Radar cross section 
(RCS) 

Measure of the reflective strength of a radar target; usually 
represented by the symbol σ and measured in square meters.  

RCS is defined as 4π times the ratio of the power per unit 
solid angle scattered in a specified direction of the power unit 
area in a plane wave incident on the scatterer from a specified 
direction.  More precisely, it is the limit of that ratio as the 
distance from the scatterer to the point where the scattered 
power is measured approaches infinity. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 24

 

o ScanSAR: The sensor steers the antenna beam to illuminate a strip of terrain at any angle to the path of 
the platform motion. 

A radar altimeter uses radar principles for height measurement.  Height is determined by measurement of  propogation 
time of a radio signal transmitted from the vehicle and reflected back to the vehicle form the terrain below. 

Civilian radar systems have concentrated on radiometric accuracy and investigation of natural targets; the priority of 
military systems is the detection and recognition of man-made targets (often vehicles) against a clutter background. 
Ground based radar measures the rainfall density and line-of-sight velocity, e.g., NEXRAD.  Ground-penetrating radar 
may be applied to detection of buried objects and determination of geophysical parameters below the surface. 

8.2.4.2 Lidar sensor  

8.2.4.2.1 General description 

Lidar is a light detection and ranging sensor that uses a laser to transmit a light pulse and a receiver with sensitive 
detectors to measure the backscattered or reflected light.  Distance to the object is determined by recording the time 
between transmitted and backscattered pulses and by using the speed of light to calculate the distance traveled.  
Lidars can determine atmospheric profiles of aerosols, clouds, and other constitutes of the atmosphere. 

Multiple pulse returns 

Relevant standards: TBS 

8.2.4.2.2 Measurements 

TBS 

8.2.4.2.3 Derivable information 

TBS: Altimetry, terrain 

8.2.4.3 Sonar sensor  

TBS 

8.2.4.4 Seismic sensor  

TBS 

8.2.5 Calibration, validation and metrology 

(Editors note: This clause will be built in part from the summary report of December CEOS/ISPRS joint task force on 
cal/val meeting.  The summary report is also to be a base document for a TC211/WG6 project on remote sensing 
calibration and validation.) 

Calibration is the process of quantitatively defining the system responses to known, controlled signal inputs [CEOS] 

Calibration is a set of operations that establish, under specified conditions, the relationship between values of 
quantities indicated by a measuring instrument or measuring system, or values represented by a material measure or a 
reference material, and the corresponding values realized by standards  [VIM] 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 25

 

Validation is the process of assessing, by independent means, the quality of the data products derived from the system 
outputs [CEOS] 

Calibration of sensor data is critical for comparison of observations over time and between sensors.  Sensor data 
traceable to standard sources is critical to the use of observations in science-based activities.   For example, UV 
monitoring from space offers the opportunity to achieve global coverage of the UV radiation field. Derived information is 
only useful to policy makers if the underlying data are rigorously quality assured, i.e. are of known quality and 
adequate for their intended use.  

Calibration is not always critical.  For small target detection in single-channel data, image calibraion is often 
unnecessary because there is no concern for precise measurements only the contrast between the target and its 
background. 

Techniques for calibration are based on metrology that establishes general rules for evaluating and expressing 
uncertainty in measurement. Metrology is mainly concerned with the uncertainty in the measurement of a well-defined 
physical quantity - the measurand - that can be characterised by an essentially unique value. It also covers the 
evaluation and expression of uncertainty associated with the experiment design, measurement methods, and complex 
systems. 

Metrology is focused on measurable quantities. A measurable quanity is an attribute of a phenomenon, body or 
substance that may be distinguished qualitatively and determined quantitatively  [VIM].  A measurement  is a set of 
operations having the object of determining a value of a quantity [VIM].  A measurand is a particular quantity subject to 
measurement [VIM].   

A focus of calibration is to determine the accuracy of measurement.  Accuracy is a qualitative concept that described 
the closeness of the agreement between the result of a measurement and a true value of the measurand [VIM].  
Quantiatively the uncertainty of measurement characterizes the dispersion of the values that could reasonably be 
attributed to the measurand. 

 (Editors note ISO 19113 references ISO 3534-1 for definition of accuracy which differs from VIM definition) 

Uncertainty of measurement comprises, in general, many components. Some of these components may be evaluated 
from the statistical distribution of the results of series of measurements and can be characterized by experimental 
standard deviations. The other components, which can also be characterized by standard deviations, are evaluated 
from assumed probability distributions based on experience or other information.  

It is understood that the result of the measurement is the best estimate of the value of the measurand, and that all 
components of uncertainty, including those arising from systematic effects, such as components associated with 
corrections and reference standards, contribute to the dispersion. 

For calibration, metrology defines the techniques of traceability.  Traceablility is the property of the result of a 
measurement or the value of a standard whereby it can be related to stated references, usually national or international 
standards, through an unbroken chain of comparisons all having stated uncertainties [VIM] 

For image sensing data requiring calibration, the uncertainty of the sensor shall be measured.  Determination of 
uncertainty for an imaging sensor traceability shall be defined.  

8.2.6 Position and attitude determination 

Concurrent with attribute value data, the imaging sensor and its associated positioning system shall record location and 
attitude information.  This information may be applied immediately to geo-located the data or may be carried with the 
data, supporting geolocation at a later time.  A positioning system is a system of instrumental and computational 
components for determining position.  Examples of positioning systems is provided in  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 26

 

ISO 19116, Geographic infomation  Positioning services, specifies the data structure and content of an interface that 
permits communication between position providing device(s) and position using device(s) so that the position using 
device(s) can obtain and unambiguously interpret position information and determine whether the results meet the 
requirements of the use.  

Table 8  -  Positioning systems 

Inertial positioning 
system 

Positioning system employing accelerometers, gyroscopes, and 
computer as integral components to determine coordinates of 
points or objects relative to an initial known reference point 

Satellite positioning 
system 

Positioning system based upon receipt of signals broadcast from 
satellites  

In this context, satellite positioning implies the use of radio signals 
transmitted from active artificial objects orbiting the Earth and 
received by passive instruments on or near the Earths surface to 
determine position, velocity, and/or attitude of an object. Examples 
are GPS and GLONASS. 

Integrated 
positioning system 

Positioning system incorporating two or more positioning 
technologies  

Measurements produced by each positioning technology in an 
integrated system may be any of position, motion, or attitude. 
There may be redundant measurements. When combined, a 
unified position, motion, or attitude is determined. 

 

8.2.7 Image acquisition request 

(Editors note: develop a UML class definition for image acquisition request) 

Issues: data type and quality, observation/visibility requirements, data for planning and tasking 

8.3 Geographic imagery information  processed, located, gridded 

8.3.1 IG_Image 

8.3.1.1 Introduction 

This clause defines a geographic image as the class IG_Image.  IG_Image is an information object.  IG_Image is a 
type of geographic coverage. 

The preceding clause described sensors for acquiring data that are used to create images.  When the sensor data is 
combined with descriptive representation information an imagery information object is created.  Information is a 
combination of data and representation information (ISO 14721).  In this Technical Specification, data is a grid of image 
values, e.g., sensor data, and the representation information is, for example, metadata defined in ISO 19115 and ISO 
19115-2. This clause defines how imagery information objects are to be structured. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 27

 

A geographic image is a type of coverage. Consistent with ISO 19101 and ISO 14721, IG_Image (Figure 9) is an 
aggregation of an image dataset.  IG_Image may have an association with image metadata. IG_Image is a subtype of 
a gridded Coverage with a constraint on the values in the Coverage CV_GridValuesMatrix.  The IG_ImageValues shall 
be sensor data or a derivation of sensor data.  The Grid of an image may have not specific georeferencing or it may 
have georeferencing information available that allows for the gelocation of the grid cells, or the grid may be 
georectified.  Table 9 provides examples of IG_Image. 

Data Models with respect to several standards and formats have been described in the ISO 19129 on Imagery and  
gridded data framework.  

(Editors note:  This section needs to be reviewed with respect to topics in common with ISO19129.  By covering all of 
coverage and gridded data, 19129 is broader than 19101-2.  By focusing on a data framework, 19129 is narrower than 
19101-2.) 

 
Figure 9 - IG_Image 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 28

 

Table 9   IG_Image Examples 

Spatial\attribute properties IG_SensorData IG_DerivedData 

CV_ReferenceableGrid Ungeorectified images (e.g. Landsat 
scene, digital aerial photo, NASA EOSDIS 
Swath, SAR) 

Ungeorectified derived data (e.g. leaf 
area index, soil moisture; usually 
intermediate products only until 
rectified.) 

CV_RectifiedGrid Georectified Georectified images (e.g. 
orthoimages, image maps) 

Georectified derived data (e.g. gridded 
leaf area index, soil moisture) 

 

8.3.1.2 Domain of IG_Image: CV_ReferenceableGrid and CV_RectifiedGrid 

The spatial domain of IG_Image shall be an instance of one of two subclasses CV_Grid: CV_ReferenceableGrid and 
CV_RectifiedGrid (SeeFigure 9).  The difference between these two subclasses is the method in which the geolocation 
information is used to determine the spatial coordinates of a CV_GridCell based on the cells grid coordinate.   

A rectified grid shall be defined by an origin in an external coordinate reference system, and a set of offset vectors that 
specify the direction and distance between the grid lines.  There is an affine transformation between the grid 
coordinates and the external coordinate reference system, e.g, projected coordinate reference system.  

An important type of image with a rectified grid is an orthoimage.  An orthoimage is a rectified digital image in which 
displacement of objects in the image, due to sensor orientation and terrain relief, have been removed. 

A referencable grid has information that can be used to transform grid coordinates to external coordinates, but the 
transformation shall not be required to be an affine transformation.  Geolocation information for a Georeferenceable 
Grid is defined in 19130.  ISO 19130 describes techniques to geolocate georeferenceable imagery, e.g., sensor 
models, functional fit models, spatial registration using control points. 

(editors note: 19130 should change from Georeferenceable Dataset to Georeferenceable Grid as the georeferenceable 
modifier does not pertain to Sensor measurements, i.e., the values.) 

(editors note: develop discussion of Geolocation quality:  Spatial Resolution  GSD,  Methods for reporting geolocation 
accuracy, affect of regridding on attribute values.) 

(editors note: develop discussion on Spatial-Temporal Schema: Sensors moving in 4-D, New project in TC211) 

8.3.1.3 Range of IG_Image: IG_ImageValues 

The attribute range of IG_Image shall be one of three subclasses of IG_ImageValues: IG_SensorDN, 
IG_SensorPhysicalData, or IG_DerivedData (See Figure 10). 

IG_SensorDN, a subtype of IG_ImageValues, shall contain the Digital Numbers (DN) produced by an image sensor. 

IG_SensorPhysicalData, a subtype of IG_ImageValues, shall contain values of the measurand of the sensor.  For 
example, for a optical radiation sensor, the IG_SensorPhysicalData are radiances at the sensor.  
IG_SensorPhysicalData is calculated from IG_SensorDN using IG_Sensor:Calibration determined by laboratory testing 
or vicarious calibration. 

IG_DerivedData, derived from IG_SensorData. is discussed in a later clause.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 29

 

 
Figure 10 - IG_ImageValues 

 

8.3.1.4 IG_PhysicalQuantity 

IS0 31-0 Quantities and units - Part 0: General principles 2.1 Physical quantity, unit and numerical value 

Physical quantities used for the quantitative description of physical phenomena.  Conventional scales, such as the 
Beaufort scale, Richter scale and colour intensity scales, and quantities expressed as the results of conventional tests, 
e.g. corrosion resistance, are not treated here, neitherare currencies nor information contents. 

Physical quantities may be grouped together into categories of quantities which are mutually comparable. Lengths, 
diameters, distances, heights, wavelengths and so on would constitute such a category.   Mutually comparable 
quantities are called quantities of the same kind. 

If a particular example of a quantity from such a category is chosen as a reference quantity called the unit, then any 
other quantity from this category can be expressed in terms of this unit, as a product of this unit and a number.  

8.3.1.5 Operations on IG_Image 

Several operations on IG_Image are inherited from CV_Continuous QuadrilateralGridCoverage (Table 10).   

Operations specific to IG_Image are listed in Table 11.  IG_Operations are limited to mathematical calculations with no 
meaning regarding geographic information.  Use of IG_Operations may allow a knowledgeable person to discern 
geographic information from an IG_Image, e.g., portrayal of a response from IG_Image:Threshold. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 30

 

Table 10  - IG_Image operations inherited from CV_Coverage 

Operation ISO 19123 Class Description 

list CV_Coverage Returns the dictionary of CV_GeometryValuePairs that contain 
the CV_DomainObjects in the domain of the CV_Coverage 
each paired with its record of feature attribute values 

select CV_ContinuousCoverage  Accepts a GM_Object and a TM_Period as input and returns 
the set of CV_GeometryValuePairs that contain 
CV_DomainObjects that lie within that GM_Object and 
TM_Period.  

evaluate CV_Continuous 
QuadrilateralGridCoverage 

Accepts a DirectPosition as input and returns a record of 
feature attribute values interpolated from the feature attribute 
values at the DirectPosition from the CV_GridPointValuePairs 
at the corners of the for that direct position. 

evaluateInverse CV_ContinuousCoverage  Accepts a Record of feature attribute values as input, locates 
the CV_GeometryValuePairs for which value equals the input 
record, and returns the set of CV_DomainObjects belonging to 
those CV_GeometryValuePairs. 

locate CV_Continuous 
QuadrilateralGridCoverage 

Accepts a DirectPosition as input and returns the 
CV_GridValueCell that contains that DirectPosition. 

 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 31

 

Table 11  -  IG_Image operations 

Operation Description 

ChangeCRS Changes the Coordinate Reference System when the IR_Image contains a 
CV_ReferencableGrid 

ChangeGrid Resamples an IG_image by changing the CV_Grid which defines the geometry of 
IG_ImageValuesMatrix.  Changes to CV_Grid may include changes to the evaluation 
structure of CV_GridCell and changes to the organization of the grid in CV_GridPoint. 

ChangeSequenceRule Changes the CV_SequenceRule of the IG_ImageValuesMatrix.   

Statistics Returns statistical measures for an element of a record in IG_ImageValues, e.g., 
minimum, maximum, mean, median, mode and standard deviation from the mean. 

Histogram Returns the relative frequencies of the values exhibited by an element of a record in 
IG_ImageValues. 

Texture Returns texture characteristics of an element of a record in IG_ImageValues, e.g., the 
size of repeating items (coarseness), brightness variations (contrast), and the 
predominant direction (directionality). 

Correlation Returns a measure of the correlation between multiple elements of a record in 
IG_ImageValues 

Scatterplot Returns a scatterplot for multiple elements of a record in IG_ImageValues 

Browse Returns a reduced-resolution encoded image suitable for portrayal, leaving IG_Image 
unchanged. 

Enhance Changes IG_ImageValues to improve the contrast of  values which have a small 
range of data values. Enhancement methods include mathematical operations on 
individual grid-point values: linear, root, equalization, and infrequency enhancement  

SpatialFilter Changes IG_ImageValues to by filtering that alters the grid values on the basis of the 
neighborhood grid values.  Filter types include: Mean, Mode Median, Gaussian, 
LaplacianType Filters  

Threshold Returns an encoded grid with an attribute of Boolean value based on a threshold of an 
element of a record in IG_ImageValues. 

BandRatioing Returns an encoded grid with an attribute formed from the ratio of two elements of a 
record in IG_ImageValues:  (value of element 1)/(value of element 2) 

DensitySlice If the number of breakpoints specified is n, then the grid coverage source sample 
dimension will be classified into n + 2 values. 

RangeTag Returns an encoded grid with an attribute value from a list of tags where each tag is 
defined non-overlapping range of an element of a record in IG_ImageValues. 

 

8.3.2 Derived Imagery  

8.3.2.1 Introduction 

Remote sensors indirectly measure physical properties of a remote object.  For example, optical and microwave 
sensors measure electromagnetic flux at the sensor which must be converted into values such as leaf area and soil 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 32

 

moisture on the surface. Deriving the desired values from the sensor data requires addressing issues such as the 
following: 

• Remote sensing data contains undesired influences.  In the optical spectral range the atmosphere strongly 
influences the measured signal.  This must be eliminated using atmospheric correction schemes.  SAR 
backscatter strongly influences the speckle effect, that makes pixel-based land surface parameter retrieval 
difficult.   

• Sensor viewing angle is variable.  Sensor data must be corrected for variations in sensor viewing 
geometry, e.g., scan angle, sun angle, off nadir corrections  

• Spectral information can be ambiguous.  Multiple solutions of an inversion of a radiative transfer model are 
possible especially if the equation system for the retrieval is underdetermined.  Retrieval of surface 
variables is dependent on the use of ancillary data, which restricts ambiguities in the remote sensed data. 

• Environmental parameters of interest may not be identical to the variables derivable from the remote 
sensed data.  For example, with C-band SAR surface soil moisture can be estimated to a depth of 2 cm, 
whereas what is needed for water balance calculations is the soil moisture of the whole root zone which 
may reach to a depth of 250 cm. 

The first two complications above can be handled through processing images on an individual basis resulting in derived 
imagery, i.e., IG_DerivedImage  The third complication above is an example where multiple images and a physical 
process model is required to estimate the parameter of interest.  Models for imagery are addressed in the Image 
Knowledge clause (Clause 8.4). 

8.3.2.2 IG_DerivedImage 

To obtain the observations of interest, derived imagery must be created. 

(Editors note:  IG_DerivedImage needs to include operations appropriate for image processing.) 

 
Figure 11 - IG_DerivedImage 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 33

 

 

8.3.2.3 Derived Geophysical Values: IG_DerivedData 

Optical and microwave sensors measure electromagnetic flux at the sensor which must be converted into values such 
as leaf area and soil moisture.  Deriving information about the scene can be done in multiple ways.  Two approaches 
are described here: Forward Problem and Inverse Problem. 

In the Forward Problem the properties of the scene along with the incoming radiation (e.g., radar or sunlight) are 
specified and used to predict the observed measurement. 

In the Inverse Problem the unknown properties of the scene are inferred from the observed measurements.  The 
number of parameters needed to characterize the target exceeds the number of independent measurements available 
at the sensor.  In this case the dimensionality of the parameter space may be reduced by assuming some parameters 
are known or the solutions is insensitive to them (these parameters then remain unmeasurable for the observations, 
but access to the other parameters becomes possible).  Even when a proper inversion is possible measurements have 
often failed to confirm the theory, reflecting in some way the failure of the theory to capture the relevant physics of the 
observation process. 

8.3.2.4 Atmospheric Correction 

The apparent radiance of ground reflection as measured by a remote sensor differs from the intrinsic surface radiant 
because of the presence of the intervening atmosphere.  The atmosphere can selectively scatter, absorb, re-emit, and 
refract radiation that traverses through it.  The atmosphere has a filtering or distorting function that changes spatially, 
spectrally, and temporally.  Correcting measured radiance data using a model of the atmosphere improves the 
accuracy of pattern recognition and image interpretation.  

 
Figure 12 - Effects of atmospheric scattering 

 

(Editors note: many satellite processing uses Modtran for atm model.) 

Current solutions to atmospheric corrections of imagery involve applying a standard radiative transfer model and 
atmospheric input data to produce a correction. Significant correction improvements can be achieved by accurately 
representing the dynamic variability of the intrinsic atmospheric optical parameters that serve as input to the radiative 
transfer model (primarily aerosols and water vapour). 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 34

 

Accordingly, the challenge is to render the existing array of ground and satellite based (input) atmospheric optical 
measurements coherent, standard and available. Physical coherency and standardization are accomplished by 
assimilating the atmospheric optical measurements and their expected errors with a micro-physical atmospheric model 
driven by measured, meteorological-scale wind fields. Such models act (at least to the measurement community) as 
intelligent interpolators in space and time, and as a tool for product quality assurance and standardization.  

8.3.2.5 Atmospheric Sounding 

Atmospheric sounding provides a vertical distribution of atmospheric parameters such as temperature, pressure, and 
composition, e.g, aerosols, using data from a sensor above the atmosphere.  The atmospheric profile is a derived 
image. 

8.3.2.6 Pixel Fusion 

Combine remote sensing data with other sources of geospatial information to improve the understanding of specific 
phenomena.  Fusion Levels: (I-GRSS reference) 

Pixel level fusion  - Data Fusion 

8.3.3 Imagery Metadata 

Metadata is data about data (ISO 19115). It is a schema required for describing geographic information and services. It 
provides information about the identification, the extent, the quality, the spatial and temporal schema, spatial reference, 
and distribution of digital geographic data.  

ISO 19115-2 Geographic Information  Metadata  Part 2 Extensions for imagery 

8.3.4 IG_Image application specialization 

(Editors note: 19101-2 WD1 defines a conceptual schema for IG_Image.  IG_Image is a specialization of grid coverage 
from 19123.  There certainly are application-specific specializations of IG_Image, e.g., for SPOT image, for Landsat 
image, for MODIS image, etc.  Perhaps this should be stated in 19101-2?  A later volume (19109-2) could define rules 
for specialization of IG_Image for applications.) 

Also consider product specification of types of IG_Image 

8.3.5 Encoding rules for imagery 

(Editors note: develop this section using NWIP for Geographic Information  Encoding  Part 2 - Encoding Rules 
Imagery and Gridded Data.)  

The information encoded depends upon the purpose of encoding: long-term archive vs. rapid distribution, visualization 
vs. processing, etc. 

A multi-tiered approach to metadata is shown graphically in Figure 13 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 35

 

 
 
 
 
 
 
 
 
 
 
 
 
 

Figure 13  -  Multi-tiered imagery encoding 
 

8.4 Geographic imagery knowledge  inference and interpretation 

8.4.1 Knowledge from imagery 

Knowledge is an organized, integrated collection of facts and generalizations. Imagery based knowledge is 
accumulated by systematic study and organized by general principles; "mathematics is the basis for much scientific 
knowledge."  One aspect of moving from information to knowledge is the identification of redundancies. Knowledge 
differs from data or information in that new knowledge may be created from existing knowledge using logical inference. 

Knowledge is more than a static encoding of facts, it also includes the ability to use those facts in interacting with the 
world. 

Figure 14 provides shows the image knowledge packages.  Each package is addressed in the following clauses 

 
Figure 14  Image knowledge packages 

 

8.4.2 Image understanding and classification 

Processing of imagery is one method to identify a collection of named features, where the features are of types 
identified by in a feature catalogue (See Figure 6).  

Interpretation of image is a semiotic process.  Sensors provide partial information about phenomena occurring in the 
environment.  From this source of information, regions in an image can be aggregated under a single concept, i.e. a 
named feature.  The process moves raw sensed data to higher semantic content information, e.g., polygonal 
coverages.  This process may also be called image understanding: knowledge-based interpretation of visual scenes by 
computers. 

IG_ImageValuesMatrix Encoding 

IG_Image Encoding 

MD_ Metadata Encoding 

Imagery Dataset Encoding 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 36

 

A primary objective of image understanding systems (IUSs) is to construct a symbolic description of the scene depicted 
in an IG_image.  Contrast this with image processing which transforms one IG_Image into another.  IUSs analyze an 
image or images to interpret the scene in terms of the feature models given to the IUSs as knowledge about the world.  
Here interpretation refers to the correspondence between the description of the scene and the structure of the image.  
It associates features in the scene (e.g., houses, roads) with geometric objects identified in the image (e.g., points, 
lines, regions). 

IG_Scene is modeled in Figure 15.  IG_Scene is a heterogeneous collection of features interpreted from an image.  As 
part of creating IG_Scene an intermediate product, IG_SegmentedImage, may be created. IG_SegmentedImage is the 
result of pattern-recognition peformed on an image.  The geometry of IG_Image is defined indepenendet of the 
attribute values, i.e., a grid.   The gemotery of IG_SegmentedImage and IG_Scene are dependent upon the attribute 
data. 

(Ed note: image understanding and classfication is based upon a world view that is used to interepret the image.  
Except for unsupervised classification. 

Table 12 - Image classification and understanding classes 

 Attribute Value Type Feature Type Lineage 
IG_Image Sensor data or derived 

values 
Continuous Grid Coverage Measured or derived from 

measurement 
IG_SegmentedImage Value range label  Discrete Polygon Coverage Clustering or edge detection 

of an IG_image 
IG_ClassifiedImage Labels on pixels, e.g., 

land cover 
Discrete Grid Coverage Supervised classification of 

an IG_Image 
IG_Coverage Labels on polygons Discrete Polygon Coverage Clustering or edge detection 

of IG_ClassifiedImage or 
processing of an IG_Image 

IG_Feature Linguistic named feature 
type from a feature 
catalogue 

Collection of discrete 
features 

Identification of discrete 
features in an IG_Image 

 

NOTE  The terminology in 19101-2 is consistent with the ISO 19100 series of International Standards.  
Terminology from the field of image understanding is different.  A feature in the 19100-series is an object in image 
understanding terminology.  A geometric object identified in an image in the 19100-series is a feature in image 
understanding terminology. 

Most geographic scenes are composed of features of various kinds related to each other through their functions.  Thus, 
to understand the scene, knowledge about (spatial) relations between features as well as knowledge about their 
intrinsic properties.  Using knowledge about feature relations and properties, IUSs conduct reasoning about the 
structure of the scene.  For features with semantic basis, a set of named feature types is required.  ISO 19110 - 
Methodology for feature cataloguing provides the International Standard for organizing feature types. 

(Editors note: Of particular relevance to geographic imagery is a controlled vocabulary for land cover.  Land Cover 
Classification system:  NWIP in ISO TC211 to begin a land cover classification system based on FAO.  Replace this 
note with the project information when approved.) 

(Editors note: discuss the use of spectra catalog, e.g., USGS Spectroscopy Lab  http://speclab.cr.usgs.gov, in the 
process of image interpretation.  Similarly consider geologic and soil mapping.)  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 37

 

 
Figure 15  Image classification and understanding class diagram 

 

8.4.3 IG_KnowledgeBase 

8.4.3.1 Introduction 

IG_KnowledgeBase is a systematic aggregation and organization of IG_Image.  IG_KnowledgeBase subtypes support 
operations for inferring some aspect of the knowledge base.  IG_Scene is result of applying geographic information 
modeling to IG_Imagery.   

IG_KnowledgeBase provide operations for the reasoning involved in drawing a conclusion or making a logical 
judgment on the basis of circumstantial evidence and prior conclusions rather than on the basis of direct observation.   

Different IG_KnowledgeBases use different inferencing methods to draw conclusions: IG_OrganizingPrinciple. 
IG_OrganizingPrinciple has three subtypes (Figure 14): Fusion, Modeling and Data Mining. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 38

 

 
Figure 16  -  IG_KnowledgeBase 

 

8.4.3.2 Models and data assimilation: IG_PhysicalProcess 

Geographic imagery models are computer based mathematical models that realistically simulate spatially distribute 
time dependent environmental processes in nature.  Simulations are of physical phenomena.  Output of model is an 
IG_Image or other type of geographic information.  Data assimilation, a type of modeling is the melding of observations 
with model simulations to provide accurate estimation of the state of the atmosphere, oceans, and land-surface, etc. 

The term model reflects that any natural phenomena can only be described to a certain degree of accuracy and 
correctness.  It is important to seek the simplest and most general description that still describes the observations with 
minimum deviations.  It is the power and beauty of the basic laws of physics that even complex phenomena can be 
understood and quantitatively be described on the base of a few simple and general principles. 

(Editors note: Investigate relevance of ISO/IEC JTC 1/SC24 projects to this clause.) 

8.4.3.3 Data Mining: IG_InferenceRules 

Data mining is the process of discovering hidden, previously unknown and usable correlations in data. The data is 
analyzed without the necessity of any hypothesis (expected result).  Data mining delivers knowledge that can be used 
for a better understanding of the data. ISO/IEC 13249-6:2002 

During the last decades, imaging satellite sensors have acquired huge quantities of data.  Optical, synthetic aperture 
radar (SAR), and other sensors have delivered several millions of scenes that have been systematically collected, 
processed, and stored.  The state-of-the-art systems for accessing remote sensing data and images, in particular, 
allow only queries by geographical coordinates, time of acquisition, and sensor type.  This information is often less 
relevant than the content of the scene, e.g., structures, patterns, objects, or scattering properties.  Thus, only few of the 
acquired images can actually be used.  In the future, the access to image archive will become more difficult due to the 
enormous data quantity acquired by a new generation of high-resolution satellite sensors.  As a consequence, new 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 39

 

technologies are needed to easily and selectively access the information content of image archives and finally to 
increase the actual exploitation of satellite observations. [Datcu, et. al.] 

Data mining, also known as knowledge discovery from databases, is the higher-level process of obtaining information 
through distilling information into knowledge (ideas and beliefs about the mini-world) through interpretation of 
information and integration with existing knowledge.   Data mining is concerned with investigators formulating new 
predictions and hypotheses from data as opposed to testing deductions from theories through a sub-process of 
induction from a scientific database. 

Data mining uses an IG_KnoweledgeBase as a repository that integrates IG_Image from one or more sources.  In 
contrast to transactional database design, good IG_KnoweledgeBase design maximizes the efficiency of analytical 
data processing or data examination for decision making.  In addition to data mining, a IG_KnoweledgeBase often 
supports online analytical processing (OLAP) tools.  OLAP tools provide multidimensional summary views of the 
IG_KnoweledgeBase, e.g., roll-up (increasing the level of aggregation), drill-down (decreasing the level of 
aggregation), slice and dice (selection and projection) and pivot (re-orientation of the multidimensional data view). 

As a specialization of data mining for broader information, geospatial specifics are utilized.  Examples include: 
geographic measurement frameworks (geometry and topology); spatial dependency and heterogeneity; complexity of 
spatio-temporal objects and rules; and diverse datatypes for geographic imagery. 

(Editors note: an item for IT Roadmap Languages to describe data mining patterns; Describe patterns to be found and 
those found. Relate to ISO 19109 Feature Cataloguing?) 

8.4.3.4 Feature fusion 

Fusion is the process of combine remote sensing data with other sources of geospatial information to improve the 
understanding of specific phenomena. 

8.5 Geographic imagery for decisions  application context 

8.5.1 Decision Context (IG_Context) 

(Ed note: discuss common operating picture) 

Imagery is useful to a specific application context if the geometric and attribute values are appropriate to the context.  
For example the spatial resolution must be appropriate to the mapping scale in the application. 

An example is to use imagery as a base map in which case the imagery must have: 
o a set of natural colors, directly interpretable by non-specific users, and uniform radiometry 
o reach accurate geometrical details at least one meter resolution. 

To be used as an information source, the satellite image will have : 
o to be available as a value added product allowing an updating at least annual, available on hand, according 

to a very flexible limit, at reasonable cost ; 
o to cover large territories in order to lay out the most uniform possible radiometry and thus to overcome one of 

the problems encountered on orthophotographs. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 40

 

Table 13  Applications and spatial resolution 

Scales of applications in urban areas Image data used for these Applications 
Applications Scales Images Resolution 
Technical 
management 

1:200 to 1:500 Orthophotograph 20 cm 

Basic mapping 1:1000 to 1:2000 Orthophotograph 20 to 50 cm 
Urban planning 1:5000 to 1:10000 Orthophotograph 50 cm to 1 m 
Prospective 1:10000 to 

1:1000000 
SPOT P and XS / 
Landsat 

10 to 30 m 

 

 
Figure 17 - Applications based on resolution 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 41

 

 
Figure 18 - Imagery requirements for selected applications 

Table 14 provides a taxonomy of geographic application areas. The categories are orthogonal, i.e., non-overlapping 
(although some existing applications may be in more than one category.) The number of categories is manageable, 
i.e., 7 +/- 2.   

A decision tree for selecting an Application Area is provided in an Annex. 

8.5.2 Decision fusion 

Combine remote sensing data with other sources of geospatial information to improve the understanding of specific 
phenomena. 

Fusion Levels: (I-GRSS reference) 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 42

 

Table 14 - Application area taxonomy 
Societal Surveillance Defense and Intelligence 

Law Enforcement 
History or Archaeology Research 

Societal Infrastructure Electric and Gas Utilities 
Telecommunications 
Transportation (including Aviation and Aerospace) 

Societal Commerce Business Site Determination 
Architecture 
Engineering and Construction 

Natural Resource Stewardship Earth, Ocean, or Atmospheric Research 
Health Care 
Ecology and Conservation 
Pollution Monitoring and Control 

Natural Resource Exploitation Agriculture 
Mining and Petroleum 
Forestry and Lumber 
Fisheries and Marine Resource Use 
Water Distribution and Resources 
Waste Disposal and Management 

Societal Impact Reduction Emergency Management 
Property Insurance 

Education K-12 Education 
University Education 
Museums 

Public Consumers Tourism 
Real Estate  
Entertainment 
Journalism  
Employment Services 

 

8.5.3 Visualization 

8.5.3.1 Human observers 

Interpreting a geographic image is an open-ended task.  It is not known in advance what pattern is going to appear in 
an image.  Determining features from an image is a context dependent task.  The job of a human interpreter is to make 
this link between the image and the features.  With the increasing volumes of geographic imagery, emphasis has been 
on automated feature detection.  However, pattern recognition and automatic image processing techniques remain 
inadequate for some applications.  For many applications a human-in-the-loop is required.   

Critical is the interpreters knowledge, skill and experience in the interpretation of geographic imagery.  

ISO TR 19122 Geographic information - Qualification and certification of personnel  

ASPRS maintains a certification process for:  
  Certified Photogrammetrist  
  Certified Mapping Scientist - Remote Sensing  
  Certified Mapping Scientist - GIS/LIS 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 43

 

8.5.3.2 Scientific visualization  

Scientific visualization is the use of computer graphics and image processing to present models or characteristics of 
processes or objects for supporting human understanding. (ISO 2382-13:1996) 

Until recently the rendering of GIS results primarily has been restricted to the same set of display techniques used in 
manual cartography (Berry, Buckley, and Ulbricht, 1998, p. 47). These techniques, the result of hundreds of years of 
cartographic experience and decades of cartographic research, have proven appropriate for conventional map 
products but have yet to demonstrate their efficacy in simulated environments and in modes of acquisition that include 
movement of the users point-of-view. 

from Haber and McNabb (1990, p. 75): visualization as a process composed of transformations that convert raw 
simulation data into a displayable image. The goal of the transformation is to convert information into a format 
amenable to understanding by the human perceptual system.  

McCormick et al. (1987, p. 3) further defines the discipline of scientific visualization as a discipline concerned with 
developing the tools, techniques and systems for computer-assisted visualization. It studies those mechanisms in 
humans and computers which allow them in concert to perceive, use and communicate visual information. 

 See also: An IT Roadmap to Geospatial Future, NAS, 2003: 
- Representing uncertainty 
- Category-representation; ontology portrayal 
- Portrayal - Urban representations 
- Distributed portrayal  
- Fusing CAD and GI info [geometry, coordinates] 

8.5.3.3 3D visualization 

(Editors note: need to reference ISO standards 3D visualization and how they apply to geographic information.) 

8.5.3.4 Color models 

(Editors note: get CIE reference from Doug OBrien ) 

9 Computational viewpoint  services for imagery 

9.1 Task-oriented computation 

The computational viewpoint provides a transition from the information viewpoint to the distributed deployment 
represented in the engineering viewpoint.  The computational viewpoint enables distribution through functional 
decomposition of the system into objects which interact at interfaces.  For geographic imagery the computational 
viewpoint identifies abstract objects necessary for the process flow for acquiring, storing, processing, viewing imagery.   

The key objective of the computational viewpoint is to enable interoperability. Interoperability capability to 
communicate, execute programs, or transfer data among various functional units in a manner that requires the user to 
have little or no knowledge of the unique characteristics of those units.  The next clause defines two models for 
developing interoperable components. 

Robust computational models are needed for the reuse of remote-sensing information and services to be used by a 
wider community.  Elements of this model are reusable service interaction patterns, e.g., service chaining, and 
methods to aid analyst selection of services, e.g., taxonomy of service types. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 44

 

In order that remote-sensing science yield the greatest value to society and to business, it is critical that data analysis 
becomes accessible to the layperson who may have the data access and the analytical ability but not necessarily the 
mathematical background to delve into algorithmic minutiae.   

From Knowledge to decisions through integration of the goals of multiple stakeholders. 

Decisions for Applications:  application of knowledge and information to address the goals of multiple stakeholders. 

Decision Support System: ``interactive computer programs that utilize analytical methods, such as decision analysis, 
optimization algorithms, program scheduling routines, and so on, for developing models to help decision makers 
formulate alternatives, analyze their impacts, and interpret and select appropriate options for implementation'' 
(Adelman, L., Evaluating Decision Support and Expert Systems, John Wiley and Sons, New York, 1992. ) 

 

Sensing

Imagery
Information

Imagery
Knowledge

Base

Information

Predictions

Observations

Decision
Support
Systems ManagementDecisions

Policy
Decisions

Data

 
Figure 19  -  Imagery for decision support 

Decision Support Systems (DSS) that operate within a spatial or spatial-temporal context represent special forms of 
more general decision support systems. Their intent is to permit planners and policy makers to: (1) integrate large 
quantities of existing space-time data, (2) use these data as inputs to sophisticated forecasting models for predicting 
the results of alternative policy choices, and (3) display the model results in easily understood ways to public officials 
and private citizens as well as to the scientific community. Basic to the use of the DSS is the ability to examine various 
"what if" situations within the operational context of DSS. Some of these systems are purely spatial in nature, but the 
"what if" basis of their operations clearly calls for the incorporation of an explicit temporal component in nearly all 
cases.  

 (Editors note: Review paper from IGARSS on Decision Support Systems) 

9.2 Computational patterns 

The computational viewpoint provides a transition from the information viewpoint to the distributed deployment 
represented in the engineering viewpoint.  Two approaches may be used to define an interoperable computation 
viewpoint based on the information viewpoint. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 45

 

1) Interaction between deployed components are performed through invocation of operations on the classes 
defined in the information viewpoint.  In this case Information viewpoint interfaces generally match 
computational viewpoint interfaces.  The Object factory computational pattern typifies this approach  

2) Interaction between deployed components are performed by invocation of interfaces on services defined using 
the semantics of the information viewpoint.  In this Services Model the Computation viewpoint interfaces 
generally do not match information viewpoint interfaces.  The Message-oriented computational pattern typifies 
this approach (Table). 

The computational viewpoint addresses services in an abstract approach, i.e., independent of hardware computing 
hosts and networks.  Approaches to deployment of services including issues of distribution are addressed in Clause 9. 

As defined in RM-ODP, the objects in the computational viewpoint can be application objects, service support objects, 
or infrastructure objects.   

Table 15  Object factory computational pattern 

Element of a pattern Description of element 

Name Factory.  Variations: Abstract Factory, Independent Objects 

Problem Provide an interface for creating related objects without specifying their concrete 
classes.  Provides flexibility in configuring implementations; an implementation of 
an object may be located separately from where it was created. 

Context Interfaces are defined using object-oriented techniques.  Clients manipulate 
instances through their abstract interfaces.  Because a factory creates a complete 
family of product specific implementation objects, product specifics are isolated to 
the factory. 

Forces Dependent upon use of a distributed-object computing platform.  Concentrating 
implementation specifics in the factory object means any extensions are done to 
the factory interface, which may be difficult.  Design considerations are critical to 
keep the factory object from becoming a bottleneck. 

Structure Client invokes a Create (IG_Image:data) operation on the Factory Object.  The 
factory object instantiates an object with the IG_Image interface to data as 
identified in the Create operation and returns a handle to the Client.  Subsequent 
operation invocations by the Client are done using the object handle and the 
IG_Image operations. 

 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 46

 

Table 16  Message-oriented computational pattern 

Element of a pattern Description of element 

Name Messaging.  Variations: Message Oriented Middleware, Message Exchange 
Pattern. 

Problem Decoupling the interaction between agents and services by defining a message 
exchange pattern that lacks any semantic significance of the content of the 
messages. However, the pattern does focus on the structure of messages, on the 
relationship between message senders and receivers and how messages are 
transmitted. The pattern includes normal and abnormal termination of any  
message exchange 

Context Some DCPs natively support certain messaging, e.g., HTTP natively supports 
request-response messaging.  The pattern is used in Service-oriented 
architectures.  The message-oriented pattern focuses on those aspects of the 
architecture that relate to messages and the message processing.  The pattern 
must be applied to specific applications. 

Forces While the pattern is defined to be semantically neutral, typically in practice 
domain semantics are added to the pattern resulting in message exchange 
operations typed by inclusion in an interface defined by a domain community, 
e.g., imagery request interface.  Deployed services conform to the abstract 
message-oriented interfaces.  Example imagery related services are defined in 
the following clause. 

Structure Services are defined to accomplish a domain relevant computation, e.g., image 
processing.  Interfaces composed of message-oriented operations are bound to 
the service.  A client, acting on behalf of an agent, invokes the operation. 

 

9.3 Geographic imagery services 

This clasue defines taxonomies for geographic imagery services which are extensions of broader information 
technology service taxonomies.  The method is to subtype a general service taxonomy to identify services specific to 
geographic imagery.  The purpose of this method is to guide the standardization of geographic information in order to 
enable the interoperability of GIS in distributed computing environments. 

Taxonomies for classification are not unique.  Multiple classification schemes may be provided for a given system.  
Three types of taxonomies are defined here: semantic capability, service interface and service binding.3 

A service is defined by more than an interface: instances of the same service type may differ in some non-
computational, behavioural, and/or non-functional aspects (such as the cost of using the service).  Even if the interface 
signature is identical, the semantics may be very different (e.g. a LIFO Stack vs. a FIFO Queue). 

                                                   

3 Reference:  OGC Web Services  Service Registry, Version: 0.2, OpenGIS Project Document OGC 01-082, Date: 2001-12-21 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 47

 

 

 

 

 

 

 

 

 

 

 

 

Figure 20 - Types of service description 
 

This Technical Specification provides examples of services categorized using a taxonomy based on semantic 
characteristics of geographic services.  ISO 19119 defines the geographic services taxonomy for semantic 
characteristics of a service.  The taxonomy consists of the titles of the categories and the definitions for the categories.   

Systems compliant to this Technical Specification shall use the geographic services taxonomy to organize their 
geographic imagery services. A specific service shall be categorized in one and only one category, unless it is an 
aggregate service that may perform services from more than one category. 

The following sub-clauses provide examples of geographic services within the geographic services taxonomy.  It is not 
required that a system provide any service listed in these sub-clauses.  It is required that if a system provides a service 
named in these sub-clauses that the service shall be categorized as defined in these sub-clauses. A service catalogue 
compliant with this International Standard shall categorize service metadata instances in the categories of the 
geographic service taxonomy. 

If a service uses the name of an example service, the service shall provide the functionality that is defined in these sub-
clauses. For example, if a service titled catalogue viewer is provided, it shall perform the services defined for the 
catalogue viewer in the geographic human interaction services category.  Systems providing services should name 
services as found in the service examples.  

 

Service 

Capability_Profile 

Service_Binding 

Service_Interface 

binding

capabilities implement

*

references

semantic characteristics protocol characteristics

refinement 

abstraction 

binding characteristics



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 48

 

Table 17   Geographic services taxonomy 

Geographic human interaction services  Services for management of user interfaces, graphics, 
multimedia, and for presentation of compound documents. 

Geographic model/information management 
services 

 Services for management of the development, manipulation, and 
storage of metadata, conceptual schemas, and datasets. 

Geographic workflow/task management 
services 

 Services for support of specific tasks or work-related activities 
conducted by humans. These services support use of resources 
and development of products involving a sequence of activities or 
steps that may be conducted by different persons. 

Geographic processing services 

Geographic processing services  spatial 
Geographic processing services  thematic 
Geographic processing services  temporal  
Geographic processing services  metadata 

 Services that perform large-scale computations involving 
substantial amounts of data. A processing service does not 
include capabilities for providing persistent storage of data or 
transfer of data over networks. 

 Geographic processing services are sub-typed by the geographic 
attribute that the processing modifies. Attribute types are defined 
in the general feature model 

Geographic communication services  Services for encoding and transfer of data across communications 
networks 

 

 

9.3.1 Geographic imagery human interaction services  

Geographic human interaction services shall be a category in the geographic service taxonomy.  Examples of human 
interaction services for working with geographic data and services: 

 Geographic viewer  imagery.  Client service that allows a user to view imagery including the mapping of image 
bands to colours in the display. 

 Geographic viewer  image mosaicing.  Geographic viewer that allows combination of imagery of geographic data 
for adjacent areas into a single view.  

9.3.2 Geographic imagery model/information management services  

Examples of model/information management services for working with geographic data and services: 

 Image access service.  Service that provides a client access to and management of an image store. An access 
service may include a query that filters the data returned to the client.  This service implements image distribution 
policies. 

 Image Access Service  sensor.  Service that provides access to an image where the source of the image is a 
real-time sensor, i.e., not a persistent store. This service implements image distribution policies. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 49

 

 Sensor description service.  Service that provides the description of a coverage sensor, including sensor location 
and orientation, as well as the sensors geometric, dynamic, and radiometric characteristics for geoprocessing 
purposes. 

 Order handling service - Imagery.   Service that provides a client with the ability to order imagery from a provider 
including: formulation of quotes on orders, selection of geographic processing options, submission of an order, 
statusing of orders, and billing and accounting of users' orders. 

9.3.3 Geographic imagery workflow/task management services  

NOTE No geographic imagery-specific workflow/task management services have been identified. 

Examples of workflow/task management services for working with geographic data and services include a Chain 
definition service, Workflow enactment service, subscription service. 

9.3.4 Geographic imagery processing services  

9.3.4.1 Geographic imagery processing services  spatial  

The following is a non-exhaustive listing of geographic processing services  spatial. 

 Coordinate conversion service. Service to change coordinates from one coordinate system to another coordinate 
system that is related to the same datum. In a coordinate conversion the parameters values are exact. Coordinate 
conversion services include map projection services. ISO 19111 is relevant to coordinate conversion. 

 Coordinate transformation service. Service to change coordinates from a coordinate reference system based on 
one datum to a coordinate reference system based on a second datum. A coordinate transformation differs from a 
coordinate conversion in that the coordinate transformation parameter values are derived empirically: therefore 
there may be several different estimations (or realizations). ISO 19111 is relevant to coordinate transformation. 

 Image coordinate conversion service. A coordinate transformation or coordinate conversion service to change the 
coordinate reference system for an image. A standard relevant to image coordinates is ISO 19123; standardization 
relevant to image coordinates is also discussed in ISO/TR 19121.  

 Ground coordinate transformation services (OGC doc. 00-115) 

 Image coordinate transformation services(OGC doc. 00-115) 

 Accuracy conversion services(OGC doc. 00-115) 

 Geodata registration services(OGC doc. 00-115) 

 Dimension measurement services(OGC doc. 00-115) 

 Rectification service. Service that projects a tilted or oblique image onto a selected plane or other surface. The 
plane is often horizontal, but can be tilted to achieve some desired condition, such as to better fit the local surface 
of the earth. 

 Orthorectification service. A rectification service that removes image displacement due to variation in terrain 
elevation.  Orthorectification requires use of digital elevation data, usually in grid form.  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 50

 

 Sensor geometry model adjustment service. Service that adjusts sensor geometry models to improve the match of 
the image with other images and/or known ground positions. 

 Image geometry model conversion service. Service that converts sensor geometry models into a different but 
equivalent sensor geometry model. 

 Image subsetting service. Service that extracts data from an image in a continuous spatial region either by 
geographic location or by grid coordinates.  

 Image sampling service. Service that extracts data from an image using a consistent sampling scheme either by 
geographic location or by grid coordinates. 

 Image tiling change service. Service that changes the tiling of geographic image. 

9.3.4.2 Geographic imagery processing services  thematic  

The following is a non-exhaustive listing of geographic processing services  thematic. 

 Image classification service. Service to classify regions of geographic image based on thematic attributes. 
Classification of images subdivides a coverage into regions based on attribute values.  

 Image subsetting service. Service that extracts image elements, e.g., from a larger set based on thematic 
characteristics. 

 Geographic information extraction services. Services supporting the extraction of feature and terrain information 
from remotely sensed and scanned images. 

 Image processing service. Service to change the range values of an image using a mathematical function.  
Example functions include: convolution, data compression, feature extraction, frequency filters, geometric 
operations, non-linear filters, and spatial filters. 

 Image modification services(OGC doc. 00-115) 

 Automated image matching services(OGC doc. 00-115) 

 Reduced resolution generation service. Service that reduces the resolution of an image. 

 Image Manipulation Services. Services for manipulating data values in images: changing colour and contrast 
values, applying various filters, manipulating image resolution, noise removal, "striping", systematic-radiometric 
corrections, atmospheric attenuation, changes in scene illumination, etc. 

 Image understanding services. Services that provide automated image change detection, registered image 
differencing, significance-of-difference analysis and display, and area-based and model-based differencing.  

 Image interpretation service.  Inferring symbolic scene descriptions from image data. 

 Image synthesis services. Services for creating or transforming images using computer-based spatial models, 
perspective transformations, and manipulations of image characteristics to improve visibility, sharpen resolution, 
and/or reduce the effects of cloud cover or haze. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 51

 

 Multi-band image manipulation. Services that modify an image using the multiple bands of the image.  Examples 
include: ratioing; principal components transformation, Intensity-Hue-Saturation colour space transformation, de-
correlation-stretching. 

 Object detection service. Service to detect real-world objects in an image. 

9.3.4.3 Geographic imagery processing services  temporal  

The following is a non-exhaustive listing of geographic processing services  temporal. 

 Image change detection services. Service to find differences between two images that represent the same 
geographical area at different times. 

 Image subsetting service. Service that extracts data from an image in a continuous interval based on temporal 
position values. 

 Image sampling service. Service that extracts data from an image using a consistent sampling scheme based on 
temporal position values. 

9.3.4.4 Geographic imagery processing services  metadata  

The following is a non-exhaustive listing of geographic processing services  metadata. 

 Image statistics service. Service to calculate the statistics of an image, e.g., mean, median, mode, and standard 
deviation; histogram statistics and histogram calculation; minimum and maximum of an image; multi-band cross 
correlation matrix; spectral statistics; spatial statistics; other statistical calculations. 

 Image annotation services. Services to add ancillary information to an image (e.g., by way of a label, a hot link, or 
an entry of a property for a feature into a database) that augments or provides a more complete description. 

9.3.5 Geographic communication services  

Examples of communications services for working with geographic data and services: 

 Image encoding service.  Service that provides implementation of an encoding rule and provides an interface to 
encoding and decoding functionality for imagery.  (A standard relevant to encoding is ISO 19118-2 TBR). 

 Image compression service.  Service that converts spatial portions of an image to and from compressed form. 

 Image format conversion service. Service that converts from one image encoding format to another. 

9.4 Service chaining for imagery 

Image processing typically involves multiple steps.  Some steps can be of long duration. ISO 19119 defines a 
computational model for combining services in a dependent series to achieve larger tasks. ISO 19119 addresses the 
syntactic issues of service chaining, e.g., data structure of a chain; as well as the semantic issues associated with 
service chaining. 

ISO 19119 enables users to combine data and services in ways that are not pre-defined by the data or service 
providers.  This capability is enabled by the infrastructure of the larger domain of IT. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 52

 

Quality of a service chain operating on imagery depends upon several issues, e.g., order of the individual services and 
compatability of the individual services.  See ISO 19119 for a further discussion of service chaining quality. 

9.5 Service metadata  extensions for imagery 

ISO 19119 defines service metadata for geographic services. Service metadata records can be managed and 
searched using a catalogue service as is done for dataset metadata.  In order to provide a catalogue for discovering 
services, a schema for describing a service is needed.  ISO 19119 defines a metadata model for service instances.  

Extensions to ISO 19119 for imagery services: 

10 Engineering viewpoint  deployment approaches 

10.1 Introduction 

The Engineering viewpoint on an ODP system and its environment focuses on the mechanisms and functions required 
to support distributed interaction between objects in the system. [ISO/IEC 10746-1].  Key concepts for the engineering 
viewpoint are node and channel.   

An engineering viewpoint node, according to RM-ODP, is a configuration of engineering objects forming a single unit 
for the purpose of location in space, and which embodies a set of processing, storage and communication functions.  In 
this technical specification, engineering viewpoint nodes will be modelled as UML nodes showing the allocation of 
information and computational viewpoints to specific nodes. 

An engineering viewpoint channel, according to RM-ODP, is a configuration of stubs, binders, protocol objects and 
interceptors providing a binding between a set of interfaces to basic engineering objects, through which interaction can 
occur.  This Technical Specification will not use the specific list of RM-ODP channel items, but rather will discuss 
channels in terms of networks and distributed computing platforms. 

Consistency between Computational and Engineering viewpoints: 

• Computational interfaces must correspond to engineering interfaces. (RM-ODP-1) 

• Basic engineering objects correspond to computational objects. (RM-ODP-1) 

• Engineering viewpoint adds  code packaging and operating systems (RM-ODP-1) 

• Computational interactions correspond to chain of engineering interactions (RM-ODP-3) 

 

10.2 Distributed system for geographic imagery 

This Technical Specification defines a distributed system for geographic image processing as shown in Figure 21.  The 
system defined in Figure 21 is comprised of five node types, connected by a set of channels.   

The Deployment diagram of Figure 21 reflects these requirements: 
o Imagery collection nodes may be located on variety of platforms; mobile/fixed, airborne/satellite 
o Control of an Imagery collection nodes shall be performed by a single Sensor processing node instance 
o Data from an Imagery collection node may be distributed to multiple Sensor processing nodes 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 53

 

o Sensor processing nodes shall process data from a single Imagery collection node 
o Imagery archive nodes may contain data from one or several Imagery collection nodes 
o Imagery archive nodes may be replicated and federated including metadata 
o Value added processing nodes may process data from multiple Sensor processing nodes 
o Value added processing nodes may provide information to Decision support nodes. 
o Value added processing nodes shall develop products for a specific application area (Table 14). 
o Decision support nodes may be mobile or fixed 
o Decision support nodes may be hosted on a range of computation hardware: from handheld device to a 

situation room with multiple screens and computing hosts 

 

 

 
Figure 21 -  Geographic imagery system deployment diagram  

 

Systems compliant to this Technical Specification shall use the geographic imagery system deployment (Figure 21) to 
define deployment of their geographic imagery systems.   

Nodes shall be defined in the following clauses.  Computational and information viewpoint artifacts shall be as 
allocated to the various nodes.  A system need not implement every artifact allocated to the node and may add artifacts 
as needed.  It is required that if a system provides a node named in these sub-clauses that the node shall used the 
interfaces as defined in these sub-clauses.  

Multiple nodes of various types may be located in the same physical locations. 

Node Deployment diagrams in the following clauses are shown with both information viewpoint interfaces and 
computational viewpoint services.  The various patterns defined in the computational pattern are not constrained in the  
engineering viewpoint.  Nodes may be developed with the distributed object pattern or with the messaging pattern.  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 54

 

Internal to a node this decision can be made without coordination.  A channel between nodes must agree on 
computational pattern approaches. 

Nodes involved in development of a new image sensor may evolve as development proceeds.  Initial development will 
have a tight coupling of the Image collection node and the Sensor processing node. This is to assure proper analysis 
and extraction of the information from the sensor data. As the development proceeds towards operational deployment, 
one instrument will serve many users, i.e., multiple Sensor processing nodes will process the data from an Image 
collection node. 

Many tasks require data input from many sources (e.g., many data collection passes, data from multiple sensors, 
maps, point data, etc.)  This places a burden on the system and on analysis to assure that various data are made 
compatible.  As secondary users begin to combine sensor data with information derived by others, the understanding 
of separately developed information becomes more important to obtain correct results. 

10.3 Imagery collection node 

An Imagery collection node shall contain a imaging sensor, platform, mount coupling the sensor to the platform, 
position/attitude sensors and a time sensor. 

An imagery collection node may be able to georectify the collected data.   

 

 

Figure 22  - Imagery collection node deployment diagram 
 

Imagery collection nodes may be located on a variety of platforms.  One platform is a earth orbiting satellite, which may 
be government or commercially owned.  Different satellites have different orbits:  Low Earth Orbit (LEO), 
Geosynchrnous Earth Orbit (GEO).  Orbital dynamics affect the frequency that a spot on the Earth can be see, i.e., the 
revisit time.  Sattellite based instruments may be pointable or have a fixed pointing with respect to platform attitude.  
Distribution of data from a satellite may be directly to the ground or through other satellites.  Once data is received by a 
ground located Sensor Processing facility, the data may be forwarded by network or media to may remain in place at 
the ground station with only the metadata being forwarded to a central archive. 

Imagery collection nodes may also be located on an airborne platform: airplane, helicopter, balloon/blimp, long-duration 
flyers, etc.  The airborne platform may be human occupied or un-occupied.  Acquisition planning for airborne includes 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 55

 

definition of a flight plan.  Relevant considerations for a airborne flight planning include: light conditions including solar 
altitude and cloud cover; flight path considerations include forward overlap and side overlap.  Data distribution from an 
airborne Imagery collection node may occur as an in-flight transmission or post-flight.  Recent advances in airborne 
geographic imagery acquistion provide for on-board processing of the imagery based on concurrent position and 
attitude determination, allowing for rectification of the imagery on-board. 

Table 18  - Imagery collection node examples 
Measures 

Mobility 

In-Situ Sensor Remote Sensing 

Fixed Platform Stationary O2 Probe Doppler Radar station 

Mobile Platform Diving Salinity probe Airborne LIDAR 

 

10.4 Sensor processing node 

A Sensor processing node is affiliated with a specific sensor in an imagery collection node.  A sensor processing node 
provides imagery containing sensor data as well as derived imagery as standard products from the sensor. 

A single Sensor processing node instance provides command and control for a Imagery collection node. 

 
Figure 23  -  Sensor processing node deployment diagram 

 

10.5 Image archive nodes 

An Imagery archive node preserves imagery information for access and use by a designated community.  An imagery 
archive node may provide preservation and access to  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 56

 

Imagery Archive functions as defined ISO 14721 are:  Ingest, Archival storage, Data management, Preservation 
planning, Access.  

 
Figure 24  -  Imagery archive node deployment diagram 

 

 
Figure 25 -  Image archive node component diagram 

 

Imagery may be stored in multiple technologies in a Image archive node.  Data may be stored in off-line media which 
must be mounted for access, near-line with robotic access to media, or on-line storage in spinning disk technology or 
random access memory. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 57

 

Imagery archive nodes may be distributed.  Distributed archives  can be implemented as a distributed database system 
as a collection of data repositories distributed across multiple, widely separated sites and machines which appear to 
users as a single data base. 

References 
o ISO 14721:2003, Space data and information transfer systems  Open archival information system   

Reference model 
o STANAG 4559 NATO Standards Image Library Interface (NSILI) 
o OGC OWS 1.2 Image Handling Architecture, OGC Document 03-016. 
o OGC OWS1.2 Image Handling Design, OGC Document 03-018r1. 
o OGC Image Handling Implementation, OGC Document 03-019 

10.6 Value-added processing and exploitation nodes 

Use data from multiple sensors for a user community.  

Example functions  
o generation of consistent time-series parameters 
o image processing/exploitation (e.g. mosaicing and registration) 
o geospatial analysis (e.g. line-of-sight analysis, terrain masking, and mobility analysis).  
o data fusion tools and algorithms, especially tools for rapid application,  
o Process chaining for value added products 

 
Figure 26  -Value-added processing node deployment diagram 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 58

 

 

10.7 Decision support nodes 

Decision support nodes focus on human interaction providing imagery and other geographic information in support of 
policy, strategic or tactical decision making.  A decision support node provides interactive access to distributed nodes.  
Decision support nodes may utilize analytical methods, such as decision analysis, optimization algorithms, program 
scheduling routines, and so on, for developing models to help decision makers formulate alternatives, analyze their 
impacts, and interpret and select appropriate options for implementation.  

Decision Support Systems with spatial content 
o Interactive system to help decision makers select  options 
o Large quantities of space-time data 
o Models for predicting results of alternative policy choices - what-if studies 
o Display results in easily understood ways to multiple communities 

 

Figure 27  - Decision support node deployment diagram 
 

10.8 Channels: networks and DCPs 

10.8.1 Imagery considerations for channels 

Channels between imagery system nodes have considerations specific to geographic imagery: 
o Geographic imagery data volumes are considerably larger than many other geographic applications and IT 

applications.  Data volume gets smaller going from right to left in the image processing system deployment 
diagram.  

o In some cases, channels between nodes need to provide for asynchronous communication for sensor data 
acquisition and long duration processing 

o Communications methods are needed to separate control messages from data flows due to the size of imagery 
data. 

o Channels must be provided for fixed and mobile location nodes, in particular, Imagery collection nodes and 
Decision support nodes may be mobile. 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 59

 

10.8.2 Space to ground communications 

In support of satellite platforms, ISO/TC20/SC13 has defined these standards for space to ground communications. 

o ISO 15891:2000, Space data and information transfer systems -- Protocol specification for space 
communications -- Network protocol 

o ISO 15892:2000, Space data and information transfer systems -- Protocol specification for space 
communications -- Security protocol 

o ISO 15893:2000. Space data and information transfer systems -- Protocol specification for space 
communications -- Transport protocol 

o ISO 15894:2000, Space data and information transfer systems -- Protocol specification for space 
communications -- File protocol 

 
10.8.3 Internet 

Many of the node to node channels will be implemented using the Internet.   
 

 

 

 

 

 

 

 

 

 

 

10.9 Persistent implementation 

 

On the Nature of Things.... 
Titus Lucretius Carus (c.99-55 BCE) 

No single thing abides; but all things flow. 
Fragment to fragment clings-the things thus grow 

Until we know and name them. By degrees 
They melt, and are no more the things we know. 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 60

 

Annex A  Abstract test suite 

(Normative) 

 

 

 

TBS 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 61

 

Annex B  ISO Reference model for open distributed processing (RM-ODP) 

The framework defined in this Technical Specification provides a reference model for geographic imagery using the 
viewpoints defined in ISO 19101.  Currently there exist a large number of imagery standards that describe such data.  
Currently the processing of imagery across multiple organizations and information technologies is hampered by lack of 
a common abstract architecture. The establishment of a common framework will foster  convergence at the framework 
level.  In the future, multiple implementation standards are needed for data format and service interoperability to carry 
out the architecture defined in this standard.  

This Technical Specification is developed based on a system architecture approach known as the Reference Model of 
Open Distributed Processing [ISO/IEC 10746]. Architecture is defined as a set of components, connections and 
topologies defined through a series of views.  The geographic infrastructure enabled by this Technical Specification will 
have multiple users, developers, operators, and reviewers.  Each group will view the system from their own 
perspective.  The purpose of architecture is to provide a description of the system from multiple viewpoints. 
Furthermore, architecture helps to ensure that each view will be consistent with the requirements and with the other 
views.  

Table B-1 shows how the RM-ODP viewpoints are applied in this Technical Specification. 

Table B-1  Use of RM-ODP viewpoints in this Standard 

Viewpoint 
Name 

Definition of RM-ODP Viewpoint 
[ISO/IEC 10746-1] 

How viewpoint is addressed in this 
specification 

Enterprise 
viewpoint 

A viewpoint on an ODP system and its 
environment that focuses on the purpose, scope 
and policies for that system. 

See clause 7 - Enterprise viewpoint. 

Typical lifecycle and policies for acquiring, 
storing and using geographic imagery.  

Computational 
viewpoint 

A viewpoint on an ODP system and its 
environment that enables distribution through 
functional decomposition of the system into 
objects which interact at interfaces. 

See clause 8 - Computational viewpoint. 

View of functional components that collect 
and make geographic imagery available 
to applications. 

Information 
viewpoint 

A viewpoint on an ODP system and its 
environment that focuses on the semantics of 
information and information processing. 

See clause 9 - Information viewpoint 

View of the semantic transitions from the 
data as collected to the knowledge used 
as the basis of decisions. 

Engineering 
viewpoint 

A viewpoint on an ODP system and its 
environment that focuses on the mechanisms and 
functions required to support distributed 
interaction between objects in the system. 

See clause 10 - Engineering viewpoint 

Approaches to implementation assuming 
distributed services and the coordination 
of institutions. 

Technology 
viewpoint 

A viewpoint on an ODP system and its 
environment that focuses on the choice of 
technology in that system. 

 

 

 

 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 62

 

Annex C  Imagery use cases 

(Informative) 

C.1 Agricultural irrigation use case 

This use cases was developed for the OGC Web Services, Phase 1.2 Interoperability Initiative and are documented in 
OGC Document 03-105. 

Table C.1  Agricultural irrigation use case 
Use case description 

Name Agricultural irrigation 
Description Agricultural company buys and exploits images to determine irrigation needs of crop fields 

in central California. 
Precondition Suitable data archive and catalog servers are available to the companies involved, and 

they support data schemas for all needed types of data and metadata. The needed data 
and metadata types are also already known by these companies. The available archive 
and catalog servers may already store some of the needed metadata and data. 

Flow of events  basic path 
1)  An agricultural company hires a mapping company to collect images of their crop fields in 

central California. 
2)  The mapping company collects digital images of specified crop fields. 
3)  The mapping company inputs the collected images into a data archive connected to the 

Internet 
4)  The mapping company places metadata for collected images in a data catalog, and 

perhaps an archive, connected to the Internet. That metadata includes the relevant image 
collection conditions, such as time of the day, cloud cover, sun direction. etc. 

5)  The agricultural company accesses the data catalog through the Internet, and searches it 
for images taken in areas on dates needed to estimate field irrigation patterns. For 
example, the catalog search might produce five image IDs that the agricultural company 
later uses to retrieve these images from the archive.  

6)  The agricultural company retrieves the needed images from the data archive. 
7)  If needed for following step(s), the agricultural company georectifies and perhaps mosaics 

the retrieved images, using image georeferencing metadata. 
8)  The agricultural company evaluates the images to determine irrigation needs. This 

information allows the agricultural company to improve field irrigation and to increase 
productivity. (Note 1) 

Flow of events  alternative paths 
 (none) 

Postcondition Agricultural company has determined irrigation needs for selected crop fields. 
NOTE 1 Georectified images are likely to be needed in this step if two or more images must be directly 
compared. Whether georectified or georeferenced images are used, image georeferencing metadata is 
likely to be used in this step, to convert image coordinates to ground coordinates and/or to convert ground 
coordinates to image coordinates. 

 

C.2 Vehicle traffic use case 

This use cases was developed for the OGC Web Services, Phase 1.2 Interoperability Initiative and are documented in 
OGC Document 03-105. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 63

 

Table C.2  Vehicle traffic use case 
Use case description 

Name Vehicle traffic 
Description A civil engineering company obtains and uses aerial images to evaluate traffic conditions 

on the I 5 freeway in the city of Portland, OR. 
Precondition Suitable data archive and catalog servers are available to the companies involved, and 

they support data schemas for all needed types of data and metadata. The needed data 
and metadata types are also already known by these companies. The available archive 
and catalog servers already store all of the needed data and metadata. 

Flow of events  basic path 
1)  A civil engineering company contracts with an aerial photography company to gain access 

to their image archive(s) covering Portland. 
2)  The engineering company searches the aerial photography company's online catalog for 

existing digital images taken in the desired area of Portland on a certain date at different 
times of the day. 

3)  The engineering company uses image IDs retrieved from the catalog to retrieve images 
from an online archive.  

4)  The images retrieved are enhanced for easier viewing by defining portrayal criteria with a 
Styled Layer Descriptor definition. (Note 1) 

5)  The enhanced images are searched for car features on the freeway under evaluation. 
6)  The numbers of car features are used to evaluate traffic conditions on the freeway during 

a particular time of the day. This extracted traffic information can be used to improve 
driving conditions. 

Flow of events  alternative paths 
 (none) 

Postcondition The civil engineering company has evaluated traffic conditions on the I 5 freeway in the 
city of Portland, OR.  

NOTE 1 We assume that image georectification and mosaicking are not needed in this use case. 
 

C.3 Natural resources use case 

This use cases was developed for the OGC Web Services, Phase 1.2 Interoperability Initiative and are documented in 
OGC Document 03-105. 

Table C.3  Natural resources use case 
Use case description 

Name Natural resources 
Description A natural resources company performs a broad search on a single-access image catalog 

to find information on a particular aerial photography image that they have received from 
one of their field analysts. 

Precondition Suitable data catalog servers are available to and already known by the natural resources 
company, and they support data schemas for all needed types of metadata. The needed 
data and metadata types are also already known by the natural resources company. The 
available catalog servers already store all of the needed metadata. 

Flow of events  basic path 
1)  A natural resources company receives an image from one of their field analysts. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 64

 

Use case description 
2)  The natural resources company formulates a catalog query for needed information about 

the received image. 
3)  The natural resources company sends a query to a single-access catalog that searches a 

number of network-accessible catalogs for the required information. 
4)  The single-access catalog searches other catalogs for the desired information. 
5)  The single-access catalog consolidates the metadata returned by other catalogs, and 

sends the result back to the natural resources company. 
6)  The natural resources company used the metadata returned to evaluate and identify the 

image received. 
Flow of events  alternative paths 

 (none) 
Postcondition The natural resources company has found and retrieved the needed metadata about the 

received image.  
 

C.4 Hurricane evacuation use case 

This use cases was developed for the OGC Web Services, Phase 1.2 Interoperability Initiative and are documented in 
OGC Document 03-105. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 65

 

Table C.4  Hurricane evacuation use case 
Use case description 

Name Hurricane evacuation 
Description Command center gets immediate, continuous input on approaching tropical storm, 

assesses the potential danger, and determines the best routes for escape if necessary. 
Precondition The available data of relevance to an image archive service is: 

a) Goes Satellite data - visible, IR 
b) Doppler Radar data 
c) Aerial photography/Video 
d) Dropsondes, Balloons, Station Data for various meteorological parameters (Features?) 
e) Flood stage data 

Flow of events  basic path 
1)  Prior to event, image archive is continually populated with Goes Satellite data and 

Doppler Radar data in real-time. (Note 1) 
2)  Prior to event, aerial photography/video is obtained for region of interest (ROI), to be used 

as a baseline. (Note 1) 
3)  Command Center is placed on alert due to incoming tropical system. 
4)  During period of alert, aerial photography/video is captured every N hours and added to 

the Image Archive. (Note 1) 
5)  During period of alert, image archive is continually populated with Goes Satellite data and 

Doppler Radar data in real-time. (Note 1) 
6)  Command center constantly monitors progress of tropical system as it approaches ROI, 

by accessing georeferenced Goes Satellite data. (Note 2) 
7)   If available, dropsonde and profiler data from aircraft overflights and ground profiler 

systems are accessed to monitor strength of tropical storm. 
8)  Command Center accesses Map/Feature data for all outgoing traffic routes from ROI. 

Near-real time Aerial Photography/Video of ROI is also obtained and orthorectified, so 
that Command Center can plan optimal escape routes. (Note 2) 

9)  If the decision is made to evacuate, command center continues to monitor near-real time 
status of outgoing routes and traffic flow. Escape routes are modified as needed. (Note 2) 

Flow of events  alternative paths 
 This use case could be extended to include monitoring of flood stages, damage 

assessment, recovery efforts, etc. Of course, aerial photography will grow increasingly 
difficult to obtain as weather conditions degenerate. Also, other satellite platforms, such 
as NOAAs AMSU may be available to monitor the tropical system. The availability of this 
data is more limited, however, as these platforms are polar arbiters, and will only cross 
the ROI twice daily. 

Postcondition Command center monitors approaching tropical storm, assesses the potential danger, 
and determines the best routes for escape if necessary. 

NOTE 1 Image exploitation services used: Put data and metadata into archive 
NOTE 2 Image exploitation services used: Display images with overlaid graphics 

 

 

C.5 Commercial airborne photogrammetry 

From: AERIAL MAPPING: METHODS AND APPLICATIONS, SECOND EDITION 

Description of Tasks 

The contractor will: 

1. Develop a project plan that will include flight lines, ground control locations for the project, and a brief text describing 
the project location (including a map with the project boundary, flight lines and photo frame locations, and ground 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 66

 

control locations). This plan will note the scale of the photography, the type of film, the forward lap and sidelap of the 
photography, the horizontal and vertical datums to be used for the ground control and photogrammetric mapping 
products, and an anticipated time line for completion of the project. The project plan will also include a brief description 
of quality control procedures that will be used by the contractor to validate the accuracy of the final mapping products. 

2. Establish all necessary horizontal and vertical ground control for the project. Ground control may be a combination of 
ground panels and photo-identifiable features. Photo-identifiable features will require location data to be established 
after photography is completed. All ground control points shall be referenced and tied to at least two other features 
near each point site. A neat sketch of each site describing the point, its location, and the location of the tie points shall 
be prepared. A ground control report shall be prepared describing the ground control plan, control points used, 
expected accuracies, and final accuracies. This report, to be signed and stamped by a registered land surveyor of the 
state of Illinois, will also provide a map indicating the location of the actual points (a copy of the 7.5-ft USGS 
quadrangle) and control points used. Any problems encountered and how they were resolved will be discussed in the 
report. 

3. Fly and photograph the site with black and white film during leaf-off conditions during the early spring of the year. 
The photography will be captured with minimal cloud cover (less than 5% in any frame), no snow on the ground, and 
no flood waters that would obscure ground information collection. Aerial photography shall be collected during a period 
of the day when the sun angle is 30% or higher and captured at an approximate photo scale of 1 in. = 500 ft with a 
forward lap of 60% and sidelap of 30%. The camera used shall be a typical 9 x 9 in. format metric aerial photography 
camera with a 6-in. focal length lens. The camera shall have a current (within the last three years) USGS certification. 
A copy of the USGS certification shall be furnished as part of the final product for this project. The film will be 
processed and labeled, and two sets of paper black and white prints (9x9 in.) will be produced of each exposure. Film 
labeling shall be across the top of each exposure with the date of photography, project name (Elsah, IL), photo scale (1 
in. = 500 ft), flight line, and frame numbers. 

4. Mark the ground control locations on the back of one set of prints to be used for aerotriangulation and mapping. The 
location and type of control point (horizontal and/or vertical) shall be marked on (he front of required control prints.  

5. Generate diapositives or scanned images to be utilized in the aerotriangulation process and subsequent map feature 
compilation. 

TYPICAL PHOTOGRAMMETRIC MAPPING PROJECT COST ESTIMATION 

6. Utilize the ground control and diapositives with appropriate software and hardware to generate a suitable 
aerotriangulation process that will allow map compilation that will meet or exceed ASPRS Class I standards for 1 in. = 
100 ft mapping with 2-ft contours. 

7. Generate an aerotriangulation report that will include the procedures, software, and hardware used in the 
aerotriangulation effort. This report will indicate the expected accuracy of the final aerotriangulation process, as well as 
the results of the process, and will discuss any problems encountered and how they were resolved, including ground 
points withheld from the solution, why they were withheld, and how this affected the final solution. The report will be 
signed by the author and the project manager. 

8. Employ either softcopy or analytical stereoplotter methods to collect the plani- metric features within the project 
boundaries. Feature collection will follow and be in compliance with the FGDC standards. All planimetric features that 
can be seen and plotted shall be collected. Feature collection will include, but is not limited to, all roads, trails, 
buildings, permanent structures, bridges, utility poles, edges of water bodies, dams, walls, parking lots, tanks, silos, 
sporting facilities, cemeteries, levees, aboveground pipelines, and airoort facilities. 

9. Collect topographic features (in ASCII format) throughout the project area, which includes mass points and 
breaklines and contour files that will describe the char- acter of the earth's surface within the project boundary. In 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 67

 

addition, the topographic detail in the contour files will note areas of major high and low points as spot elevations. 
Sufficient topographic detail in flat areas will be collected and dis- played to depict the general lay of the land. 

10. Provide the final data sets on CDROM disks. Two copies of planimetric data and contour files will be submitted in 
AutoCad Version 14, and the mass points and breakline files will be submitted in the ASCII format that is fully 
compatible with AutoCad Version 14. 

11. Produce metadata for the entire project to include the aerial photography, ground control, and all feature collection 
that is fully compliant with the FGDC "Content Standard for Digital Geosoatial Metadata,"  FGDC-STD-001-1998. 

Deliverables 

The final deliverables will include: 

• A project plan 

• All exposed film 

• Two sets of prints (one clean set and one control set) 

• One copy of the USGS camera calibration report for the cameras used for the project 

• All ground control information and ground control reports 

• Aerotriangulation report 

• Two sets of final data on CD; final data sets include planimetric features in AutoCad version 14, mass points 
and breaklines, and contour files 

• One digital set of the standards compliant metadata 

 

C.6 Intelligence, surveillance and reconnaissance 

The NATO Intelligence, Surveillance, and Reconnaissance (ISR) Interoperability Architecture (NIIA) provides the basis 
for the technical aspects of an architecture that provides interoperability between NATO nations ISR systems.   

The NIAA defines how reconnaissance and surveillance assets within Air Group IVs (AG IV) area of responsibility will 
achieve interoperability.  The main aim of the NIIA is to outline a top-level architecture which will provide a context and 
structure for Air Group IVs STANAGs and other interoperability initiatives. Air Group IV has the basic responsibility for 
interoperability of airborne ISR reconnaissance systems.  Specifically, it has the responsibility for specifying standards 
for surveillance and reconnaissance assets to achieve interoperability within coalition and NATO environments.  The 
goal of the NIIA will be to develop a concept to achieve data exchange interoperability between NATO reconnaissance 
and surveillance assets.   

Figure 2 is a key element of the NIIA as it shows AG IVs area of responsibility and the broader area of interest that 
makes up the reconnaissance cycle.   



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 68

 

Collection
Platform Mgt

Sensor MgtSensor Plan

Flight Plan
Planning 

Air 
Tasking 
Order 

Collection Planning 

Exploitation

FRAG Order
Primary Imagery

Local DB
Archive

Remote 

DB 
Archive 

Request For 
Intelligence 

Requestor 

Query
Report

Exploitation 
Product 

Request 

Intel
Report

Secondary
Imagery

Sensor

Platform

NIIA Area Of Responsibility

CCIRM 

NIIA Area Of Interest 
 

Figure 28 - NIIA Scope 
 

C.7 Controlling wildfires 

This scenario is from the US National Academies report: IT Roadmap to a Geospatial Future. 

This scenario illustrates how geospatial data from a wide array of sources could be integrated with powerful 
computational models, enabling us to predict more accurately the onset and behavior of wildfires. The size and severity 
of wildfires depend on how quickly and effectively firefighting resources are deployed and how successfully the areas 
of high risk can be evacuated. In our hypothetical future, a wildfire hazard system is in constant operation:  

The wildfire hazard system automatically monitors the national landscape to ensure early detection of fire 
outbreaks. Although dry fuel load (biomass with low water content) is the most direct indicator of potential fire 
severity, it is too difficult to measure over large areas, because remote optical instruments respond to the 
radiation reflected from the leaves rather than the dry fuel. Because ground-based sensors are impractical 
over vast areas, the new system monitors data (e.g., lightning strikes, Doppler weather radar, soil surface 
properties, and wind data) harvested from satellites. A wide array of satellitessome of them engaged in 
classified or proprietary reconnaissancehas been deployed in recent years, making it possible to acquire 
data updates at coarse spatial resolution almost continuously, with higher-resolution (~1 km) data available at 
intervals of several hours. The wildfire hazard system warns of the possibility of fires by combining these 
measurements with spatially distributed models of plant growth and drying (as functions of energy and water 
inputs, which vary at the synoptic scale as well as locally with elevation and slope orientation) and with 
spatiotemporal data about historical wildfire occurrences (Callaway and Davis, 1993). Once a fire starts, 
satellites sensing radiation in the infrared portion of the spectrum can detect small, hot areas as long as their 
view is not obscured by clouds (Giglio and Kendall, 2001). Not all of these hot targets are fires, however, so to 
avoid false alarms, the hazard system must integrate, mine, analyze, and cross-compare data to reliably 
identify wildfire outbreaks.  

When an apparent wildfire is detected, a standby alert is issued to emergency response authorities. The 
measurements from the remote sensing instruments are passed to a system component that calculates the 
geographic boundaries of the fire itself and of the area affected by smoke. The system automatically identifies 
potentially relevant data sets, and it harvests data on vegetation/biology, wildfire-spread factors (vegetation 
flammability, location of natural and man-made fire barriers, etc.), and meteorological conditions. Weather 
prediction and chemical plume diffusion models are activated to forecast how the fire and smoke/debris will 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 69

 

spread. A wildfire is especially complicated because its behavior depends on the three-dimensional flow of air 
over terrain, which in turn depends on both synoptic weather conditions and the convection that the fire itself 
causes. The hazard system combines models of the airflow with the Doppler wind profilers to estimate the 
state of the overlying atmosphere. As the wildfire spreads, the hazard system rapidly updates the models to 
predict the future behavior of the fire.  

An emergency response component is activated to cross-analyze the simulation results with data on the 
locations of population centers, remote dwellings or businesses, and evacuation routes. Results are 
presented to a distributed control team that reviews the data, evaluates the risks, and collaboratively selects a 
plan of action. Public agencies are alerted to begin the evacuation process, with detailed routing information 
provided automatically to all cell phones, pagers, PDAs, and other location-aware devices4 in the affected 
area. Meanwhile, a fire control component is activated. This cross-analyzes the original simulation results 
the wildfire-spread prediction model continues to run, using constantly updated sensing datawith data on 
access paths for firefighting equipment and personnel. The component proposes strategies for combating the 
fire and predicts the relative effectiveness of each strategy in containing damage to natural resources and 
property. As firefighting crews are dispatched, they are provided with strategic scenarios and routing 
information. Real-time updates flowing through the system make it possible to adjust strategies and routing as 
conditions change.  

In this scenario, a number of new challenges arise because predictive models have been coupled with the time-critical 
analysis of extremely large amounts of data: 

 Development of systems that can harvest classified and proprietary data, with appropriate barriers to unlawful access; 

 Methods for integrating computational, observed, and historical data in real time; 

 Methods for dynamically coupling independent numerical models and infusing external data into them to develop, 
evaluate, and continuously refine strategies for emergency response; 

 Algorithms capable of tracking moving and evolving objects and predicting their future state; 

 Methods for automatically identifying and communicating with persons in the affected area via wired and wireless 
communication mechanisms (household and cellular telephone numbers, pagers, PDAs, satellite TV and radio, cable 
TV, and the Internet) based on geographic location; and 

 User interfaces empowering a range of users (from emergency responders to local government officials) with little or 
no training to collaboratively evaluate proposed plans and coordinate actions. 

 

C.8 Digital earth  

This scenario is from the US National Academies report: IT Roadmap to a Geospatial Future. 

This scenario, taken from Gore (1998), illustrates how new technologies and methods could enrich our understanding 
of the world and the historical events that have shaped it. Imagine that a grade-school student is visiting an exhibit in a 
local museum. The Digital Earth exhibit is a multiresolution, three-dimensional representation of the world that allows 
her to interactively explore the vast amounts of physical, cultural, and historical information that have been gathered 
about the planet.5 The exhibit also provides tutorials that explain difficult concepts and guide their exploration (e.g., 
What is ocean productivity? How is it measured?).  

After donning a head-mounted display, she sees Earth as it appears from space. Using a data glove, she 
zooms in, using higher and higher levels of resolution, to see continents, then regions, countries, cities, and 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 70

 

finally individual houses, trees, and other natural and man-made objects. Having found an area of the planet 
she is interested in exploring, she takes the equivalent of a magic carpet ride through a 3D visualization of 
the terrain. Of course, terrain is only one of the many kinds of data with which she can interact. Using the 
systems voice recognition capabilities, she is able to request information on land cover, distribution of plant 
and animal species, real-time weather, roads, political boundaries, and population.  

This information can be seamlessly fused with the digital map or terrain data. She can get more information 
on many of the objects she sees by using her data glove to click on a hyperlink. To prepare for her familys 
vacation to Yellowstone National Park, for example, she plans the perfect hike to the geysers, bison, and 
bighorn sheep that she has just read about. In fact, she can follow the trail visually from start to finish before 
she ever leaves the museum in her hometown.  

She is not limited to moving through space; she also can travel through time. After taking a virtual fieldtrip to 
Paris to visit the Louvre, she moves backward in time to learn about French history, perusing digitized maps 
overlaid on the surface of the Digital Earth, newsreel footage, oral history, newspapers, and other primary 
sources. She sends some of this information to her personal e-mail address to study later. The time line, 
which stretches off in the distance, can be set for days, years, centuries, or even geological epochs, for those 
occasions when she wants to learn more about dinosaurs.  

As envisioned in 1998, Digital Earth was intended to support individuals or, at most, co-located groups. Although many 
of the goals for Digital Earth have not yet been realized (and remain research challenges), one can imagine a next-
generation Digital Earth that can connect distributed individuals through teleimmersive environments. In the scenario 
sketched above, the young girl on her virtual field trip could interact directly with a child in another country or with 
distributed groups of students engaging in collaborative learning activities that take advantage of their collective 
abilities, resources, and access to real-world locations. Realizing this vision will require not just advances in 
technology, but overcoming significant challenges related to human capabilities:  

o Data integration techniques capable of merging data of vastly different types, spatial resolutions, and temporal 
scales in response to human queries; 

o Supporting technologies for extremely large and diverse geospatial databases, including complex data models, 
scalable searching and navigation techniques, and scalable analysis on the fly; 

o Distributed virtual-reality environments that are uncomplicated and responsive enough to suit the general 
public; and 

o Intuitive, multimodal interfaces capable of supporting unconstrained navigation through virtual space and time 
as well as guided exploration of the concepts. 

C.9 Earth science vision 

The Earth Science Vision is a roadmap for a future where a proactive Earth system prediction capability enables a 
richer relationship of people with our home planet. This includes all the means and benefits of climate, weather, and 
natural hazard prediction, such as: 

• 10 year climate forecasts 
• 15-20 month El Nino / La Nina prediction 
• 12 month regional rainfall rates 
• 5 day hurricane track prediction to +/- 30 Km 
• 2 day air quality notification 
• 1 hour volcano and earthquake warning 
• 30 minute tornado warning. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 71

 

Earth observing satellites and related research have led scientists to view the Earth as a systemas a complex 
dynamic set of interactions among the land surface, atmosphere, oceans and ice caps, and the Earths interior. Human 
activities long apparent at the local level, are now seen as causing global-scale impacts, first in stratospheric ozone 
depletion and now perhaps in changing climate. Our planet continues to offer disruptions of its own in the form of 
earthquakes, volcanic eruptions, and severe weather. These profound realizations have given rise to the birth of the 
new interdisciplinary field of Earth System Science. This way of studying the Earth is critical to understanding how 
global climate responds to the forces and feedbacks acting on it. 

Researchers have constructed computer models to simulate the Earth system, and to explore the possible outcomes of 
potential changes they introduce in the models. This way of looking at the Earth as a system is a powerful means of 
understanding changes we see around us. 

That has two implications for Earth Science. First, we need to characterize (that is, identify and measure) the forces 
acting on the Earth system and its responses. Second, we have to peer inside the system to understand the source of 
internal variability: the complex interplay among components that comprise the system. Earth system changes are 
global phenomena. 

Historically Earth remote sensing has consisted primarily of a single spacecraft with multiple instruments in a classic 
stove-pipe campaign. The science collected by each campaign tended to be focus on one particular focused area or 
science discipline (such as land cover) and not interrelated to other science disciplines. Each individual mission or 
campaign was operated independently of other science missions. Typically there is no real time sharing of information 
between sensors, other spacecraft or investigators. We would fly over a particular area, image or sense the area and 
re-visit the same area sometime in the future (e.g., Landsat has a 14 day revisit period.) Earth remote sensing was 
effectively remote monitoring. 

In the vision (2020) timeframe, we envision a system where: A million miles from Earth, deep space sentinels provide 
interferometric characterization of our atmosphere day and night, feeding cloud and temperature data to scientists 
models to produce a ten year forecast of climate variability. Closer to Earth, observations from satellites and buoys 
enable a 15 month advance warning of the next El Nino event. Regionally-specific, seasonal forecasts of precipitation 
are updated, allowing farmers in the southeastern U.S. to select between drought and flood-resistant crops, and Forest 
Service officials to redistribute fire fighting resources based on adjusted fire potential indices. Meanwhile, a 
combination of sensors measuring wind vectors and precipitation rates drives a 3-D model of the structure of Hurricane 
Hattie, enabling the U.S. Hurricane Center to nail the landfall prediction and minimize the evacuation area. 

By the year 2020 we plan to revolutionize our understanding of the Earths environment and climate, through radical, 
new paradigm. Rather than simply monitor and response to changes in the Earths environment, we will heavily 
involved in actively modeling and forecasting changes in our environment. Rather than just detecting changes and 
natural hazards after they have occurred, we will be anticipating these changes and natural hazards before they begin. 
We will be able to offer the public 5-day hurricane track prediction, 1 hour earthquake warnings, and 30 minute tornado 
warnings routinely. 

To accomplish this, by the year 2020, we envision a world where a global, intelligent web of space-based, air-based 
and in-situ sensors coordinate observations and collaboratively gather relevant data. Where networks of computers co-
operatively collected and processing the vast qualities of data. Where distribution systems will create and deliver 
information products directly to the users throughout the world. 

Two major areas of challenges do exist. Both of which are being worked; 

• One challenge is that a greater scientific understanding of basic phenomenology is required. Our current set of 
EOS are providing us extensive insight into the phenomenology. 

• The second set of challenges are the key technical capabilities needed to implement these systems. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 72

 

While some of these challenges may seem far-reaching, there is work already in progress within NASA, otheragencies 
and the private sector which when developed, will facilitate many elements of this vision. Already the Earth Science 
Constellation (ESC) is one of the first step toward developing our web of sensors in space. ESE is striving to 
coordinate and identify coincident imaging among its EOS missions. To achieve this, the operational coordination of 
the entire Sun-synchronous ESC will be viewed as a whole system. (This planned constellation currently consists of at 
least 9 identified missions, four (LANDSAT-7, EO-1, SAC-C and TERRA) with AM node crossings (morning train) and 
five (Aqua, PICASSOCENA, CloudSat, Aura and Parasol) with PM node crossings (afternoon train).)  Even this recent 
accomplishment is showing great promise in improving our understanding of our environment. 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 73

 

Annex D  Service chaining examples 

 

Scene
(reality)

Observable
Phenomena

Sensor
subsystem

Image
Data

Package

Information
products of

socio/economic &
scientific merit in
the marketplace

Image/scene link
distortions in EM

spectrum

Archive
&

Distribution

Search

Distributed
archives

Pre-
processing

Decision Criteria
Image interpretation

Classification

Algorithms

Image processing

 
Figure 29 - Geographic imagery processing chain  IEEE/GRSS 

 

(Orde
r)

(Resul
t)

 
Figure 30 - Geographic imagery processing chain  OGC 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 74

 

Annex E  Application area decision tree 

 

Figure 31 provides a decision tree to determine the application area for a specific project. The categories are 
orthogonal, i.e., non-overlapping (although some existing applications may be in more than one category.) The number 
of categories is manageable, i.e., 7 +/- 2.  (multiple detailed examples can be provided in each category.) 

 

Are users performing the task
as a professional obligation?

What type of features are
predominant?

Professional Consumer Student

What business sector?

humans and human construction natural
neither
predominant

What business sector?

public public/commercial

Defense and Intelligence
Law enforcement
History or Archealogy Research

Electric and gas utlities
telecommunications
engineering and construction
Transportation

Business site determination

commercial public public/commercial

Earth, Oceanor Atmos Research
Health care/disease
Ecology and conservation
Pollution Monitoring & Control

Emergency Management(FEMA)
Property Insurance

Business site location

commercial

Real estate
Tourism
Entertainment
Journalism

K-12 education
University education
Museums

Societal surveilance

Education

Societal Infrastructure

Societal commerce N atural resource stewardship

Natural resource exploitation

Societal Impact Reduction

Public Consumers

Agriculture
Mining and Petroleum
Forestry & lumber
Fishersies & Marine Rescources
Waste Disposal and Management  

Figure 31  Application Area Decision Tree 
 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 75

 

Annex F  Principles relating to remote sensing of the Earth from space 

United Nations 
General Assembly 
3 December 1986 

 
     41/65.  Principles relating to remote sensing of the Earth from space 
  
     The General Assembly, 
  
     Recalling its resolution 3234 (XXIX) of 12 November 1974, in which it recommended that the Legal Sub-Committee 
of the Committee on the Peaceful Uses of Outer Space should consider the question of the legal implications of remote 
sensing of the Earth from space, as well as its resolutions 3388 (XXX) of 18 November 1975, 31/8 of 8 November 
1976, 32/196 A of 20 December 1977, 33/16 of 10 November 1978, 34/66 of 5 December 1979, 35/14 of 3 November 
1980, 36/35 of 18 November 1981, 37/89 of 10 December 1982, 38/80 of 15 December 1983, 39/96 of 14 December 
1984 and 40/162 of 16 December 1985, in which it called for a detailed consideration of the legal implications of remote 
sensing of the Earth from space, with the aim of formulating draft principles relating to remote sensing, 
  
     Having considered the report of the Committee on the Peaceful Uses of Outer Space on the work of its twenty-ninth 
session and the text of the draft Principles Relating to Remote Sensing of the Earth from Space, annexed thereto,    
 
     Noting with satisfaction that the Committee on the Peaceful Uses of Outer Space, on the basis of the deliberations 
of its Legal Sub-Committee, has endorsed the text of the draft Principles Relating to Remote Sensing of the Earth from 
Space, 
  
     Believing that the adoption of the Principles Relating to Remote Sensing of the Earth from Space will contribute to 
the strengthening of international co-operation in this field, 
  
     Adopts the Principles Relating to Remote Sensing of the Earth from Space set forth in the annex to the present 
resolution. 
  
  
                                    ANNEX 
        Principles Relating to Remote Sensing of the Earth from Space 
                                 Principle I 
  
     For the purposes of these principles with respect to remote sensing activities: 
  
     (a)  The term "remote sensing" means the sensing of the Earth's surface from space by making use of the 
properties of electromagnetic waves emitted, reflected or diffracted by the sensed objects, for the purpose of improving 
natural resources management, land use and the protection of the environment; 
  
     (b)  The term "primary data" means the raw data that are acquired by remote sensors borne by a space object and 
that are transmitted or delivered to the ground from space by telemetry in the form of electromagnetic signals, by 
photographic film, magnetic tape or any other means; 
  
     (c)  The term "processed data" means the products resulting from the processing of the primary data, needed to 
make such data usable; 
  
     (d)  The term "analysed information" means the information resulting from the interpretation of processed data, 
inputs of data and knowledge from other sources;  
  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 76

 

     (e)  The term "remote sensing activities" means the operation of remote sensing space systems, primary data 
collection and storage stations, and activities in processing, interpreting and disseminating the processed data. 
  
  
                                 Principle II 
  
     Remote sensing activities shall be carried out for the benefit and in the interests of all countries, irrespective of their 
degree of economic, social or scientific and technological development, and taking into particular consideration the 
needs of the developing countries. 
  
  
                                Principle III 
       Remote sensing activities shall be conducted in accordance with international law, including the Charter of the 
United Nations, the Treaty on Principles Governing the Activities of States in the Exploration and Use of Outer Space, 
including the Moon and Other Celestial Bodies, and the relevant instruments of the International Telecommunication 
Union. 
  
  
                                 Principle IV 
  
     Remote sensing activities shall be conducted in accordance with the principles contained in article I of the Treaty on 
Principles Governing the Activities of States in the Exploration and Use of Outer Space, including the Moon and Other 
Celestial Bodies, which, in particular provides that the exploration and use of outer space shall be carried out for the 
benefit and in the interests of all countries, irrespective of their degree of economic or scientific development, and 
stipulates the principle of freedom of exploration and use of outer space on the basis of equality.  These activities shall 
be conducted on the basis of respect for the principle of full and permanent sovereignty of all States and peoples over 
their own wealth and natural resources, with due regard to the rights and interests, in accordance with international 
law, of other States and entities under their jurisdiction. Such activities shall not be conducted in a manner detrimental 
to the legitimate rights and interests of the sensed State. 
  
                                 Principle V 
  
     States carrying out remote sensing activities shall promote international co-operation in these activities.  To this 
end, they shall make available to other States opportunities for participation therein.  Such participation shall be based 
in each case on equitable and mutually acceptable terms. 
  
                                 Principle VI 
  
     In order to maximize the availability of benefits from remote sensing activities, States are encouraged, through 
agreements or other arrangements, to provide for the establishment and operation of data collecting and storage 
stations and processing and interpretation facilities, in particular within the framework of regional agreements or 
arrangements wherever feasible. 
  
                                Principle VII 
  
     States participating in remote sensing activities shall make available technical assistance to other interested States 
on mutually agreed terms. 
  
                                Principle VIII 
  
     The United Nations and the relevant agencies within the United Nations system shall promote international co-
operation, including technical assistance and co-ordination in the area of remote sensing. 
  



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 77

 

                                 Principle IX 
  
     In accordance with article IV of the Convention on Registration of Objects Launched into Outer Space and article XI 
of the Treaty on Principles Governing the Activities of States in the Exploration and Use of Outer Space, including the 
Moon and Other Celestial Bodies, a State carrying out a programme of remote sensing shall inform the Secretary-
General of the United Nations.  It shall, moreover, make available any other relevant information to the greatest extent 
feasible and practicable to any other State, particularly any developing country that is affected by the programme, at its 
request. 
  
                                 Principle X 
  
     Remote sensing shall promote the protection of the Earth's natural environment.  To this end, States participating in 
remote sensing activities that have identified information in their possession that can be used to avert any phenomenon 
harmful to the Earth's natural environment shall disclose such information to States concerned. 
  
                                 Principle XI 
  
     Remote sensing shall promote the protection of mankind from natural disasters.  To this end, States participating in 
remote sensing activities that have identified processed data and analysed information in their possession that may be 
useful to States affected by natural disasters, or likely to be affected by impending natural disasters, shall transmit such 
data and information to States concerned as promptly as possible. 
  
                                Principle XII 
  
     As soon as the primary data and the processed data concerning the territory under its jurisdiction are produced, the 
sensed State shall have access to them on a non-discriminatory basis and on reasonable cost terms. The sensed 
State shall also have access to the available analysed information concerning the territory under its jurisdiction in the 
possession of any State participating in remote sensing activities on the same basis and terms, particular regard being 
given to the needs and interests of the developing countries. 
  
                                Principle XIII 
  
     To promote and intensify international co-operation, especially with regard to the needs of developing countries, a 
State carrying out remote sensing of the Earth from space shall, upon request, enter into consultations with a State 
whose territory is sensed in order to make available opportunities for participation and enhance the mutual benefits to 
be derived therefrom. 
  
                                Principle XIV 
  
     In compliance with article VI of the Treaty on Principles Governing the Activities of States in the Exploration and Use 
of Outer Space, including the Moon and Other Celestial Bodies, States operating remote sensing satellites shall bear 
international responsibility for their activities and assure that such activities are conducted in accordance with the 
provisions of the Treaty and the norms of international law, irrespective of whether such activities are carried out by 
governmental or non-governmental entities or through international organizations to which such States are parties.  
This principle is without prejudice to the applicability of the norms of international law on State responsibility for remote 
sensing activities. 
  
                                 Principle XV 
  
     Any dispute resulting from the application of these principles shall be resolved through the established procedures 
for the peaceful settlement of disputes. 
 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 78

 

Bibliography 

(Informative) 

 

Remote Sensing and Image Interpretation - 4th edition, Lillesand and Kiefer 2000 (ASPRS reference) 

 Comprehensive Large Array-data Steward-ship System (CLASS) - IT Architecture Description, for NOAA NESDIS 
Central Satellite Data Processing Center, by Computer Sciences Corporation July 20, 2001 

 Independent Architecture Study Evaluation Document, for NASA ESDIS Project, by EOSDIS Core System Project, 
Hughes Applied Information Systems, document 170-WP-001-001, March 1995 . 

 ECS System Design Specification, for NASA ESDIS Project, by EOSDIS Core System Project, Hughes Applied 
Information Systems, document 194-00436TPW, June 1994. 

ENVISAT-1 Mission and System Summary, European Space Agency, March 1998. 

 THE INTEGRATED GLOBAL OBSERVING STRATEGY (IGOS) PARTNERSHIP PROCESS, May 2003, 
http://ioc.unesco.org/igospartners/igosdocs.htm 

ENISAT Payload Data Segment (http://styx.esrin.esa.it:5000/pds/pds_dd01.html) 

 The use of " image" in Geographical Information Market : results of an inquiry on the needs of end-users in urban 
studies, Anne Puissant & Christiane Weber, Laboratoire Image et Ville, ULP Strasbourg, 3 rue de lArgonne , F- 67 
000 Strasbourg 

SPOT Image Presentation, Didier Giacobbo, 2002. 

Transforming Remote Sensing Data into Information and Applications, Steering committee on Space Applications and 
Commercialization, National Research Council, 2001, National Academy Press, Washington DC. 

USIGS Architecture Framework, NIMA NUAF-B, 23 June 1998 

 IT Roadmap to a Geospatial Future, Committee on Intersections Between Geospatial Information and Information 
Technology, National Research Council, 2003, National Academy Press, Washingtosn DC. 

The Earth Science Vision: An Intelligent Web of Sensors, Dr. Mark Schoeberl, Senior Scientist NASA GSFC, et.al, 
paper presented at IEEE GRSS - International Geoscience and Remote Sensing Symposium (IGARSS), 2002. 

A Process Model for Remote Sensing Data Analysis, V. Madhok and D. A. Landgrebe, IEEE Transactions on 
Geoscience and Remote Sensing, Vol. 40, No. 3, March 2002. pp 680-686. 

Information Mining in Remote Sensing Image Archives: System Concepts, Mihai Datcu, et. al., IEEE Transactions on 
Geoscience and Remote Sensing, Vol. 41, No. 12, December 2003. pp 2923-2936. 

Data Policy Issues and Barriers to Using Commercial Resources for Mission to Planet Earth. Rand Document No: DB-
247-NASA/OSTP, 1999) 

http://www.codata.org/databases/data_access/policies.html 



Working Draft V3   ISO/TS 19101-2 

© ISO 2001 All rights reserved 79

 

WORLD METEOROLOGICAL ORGANIZATION - GLOBAL ATMOSPHERE WATCH, No. 146, Quality Assurance in 
Monitoring Solar Ultraviolet Radiation: the State of the Art 2003 

Guide to the Expression of Uncertainty in Measurement (GUM) by BIPM, IEC, IFCC, ISO, IUPAC, IUPAP, OIML ,1993: 

US National Academies report: IT Roadmap to a Geospatial Future, 2003; 

 Geographic Data Mining and Knowledge Discovery, Miller and Han, 2001. 

RADIOMETRIC CALIBRATION  STANDARDS, Tech Brief by IEEE GRSS Instrmentation and Future Technologies 
Committee, Christopher S. Ruf, The Pennsylvania State University (http://www.ewh.ieee.org/soc/grss/ift/ruf12.html) 


