
 
 
 
 
 

Open GIS Consortium 
35 Main Street, Suite 5 
Wayland, MA 01778 

Telephone: +1-508-655-5858 
Facsimile: +1-508-655-2237 

 
Editor:  

Telephone: +1-703-830-6516 
Facsimile: +1-703-830-7096 

ckottman@opengis.org 
 

 
 

The OpenGIS™ Specification Model  
Topic 15: Image Exploitation Services

 
 

Version 6 
 
 
 

 
 
 
 

OpenGIS™ Project Document Number 00-115.doc 



   

Copyright © 1999, 2000, Open GIS Consortium, Inc.  

NOTICE

The information contained in this document is subject to change without notice. 

The material in this document details an Open GIS Consortium (OGC) specification in accordance with the license and 
notice set forth on this page. This document does not represent a commitment to implement any portion of this 
specification in any companies’ products. 

While the information in this publication is beleived to be accurate, the Open GIS Consortium makes no warranty of 
any kind with regard to this material including but not limited to the implied warranties of merchantability and fitness 
for a particular purpose. The Open GIS Consortium shall not be liable for errors contained herein or for incidental or 
consequential damages in connection with the furnishing, performance or use of this material. The information 
contained in this document is subject to change without notice. 

The Open GIS Consortium is and shall at all times be the sole entity that may authorize developers, suppliers and 
sellers of computer software to use certification marks, trademarks, or other special designations to indicate compliance 
with these materials. 

This document contains information which is protected by copyright. All Rights Reserved. Except as otherwise 
provided herein, no part of this work may be reproduced or used in any form or by any means (graphic, electronic, or 
mechanical including photocopying, recording, taping, or information storage and retrieval systems) without the 
permission of the copyright owner. All copies of this document must include the copyright and other information 
contained on this page. 

The copyright owner grants member companies of the OGC permission to make a limited number of copies of this 
document (up to fifty copies) for their internal use as a part of the OGC Technology Development process. 

The Open GIS Abstract Specification 



   

Revision History 
 
Date Description 
15 January 1999 New topic volume from project document 98-025r4. 
31 March 1999 Update Section 1 for new document template; move introduction of Section 2 and Section 2.1 in 

99-115 to Section 1.2 of this version. 
22 June 1999 Update sections 2.1.1.1, 2.1.1.2 and 2.1.3 with change proposal 99-025 (w/ friendly changes), 

approved at April 1999 TC meeting. 
14 December, 1999 Update Section 2.1.1.1 with change proposal 99-059, approved at the October 1999 TC meeting. 

 

The Open GIS Abstract Specification  Page i 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

 

This page is intentionally left blank. 

 

The Open GIS Abstract Specification  Page ii 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Table of Contents 
1. Introduction.............................................................................................. 5 

1.1. The Abstract Specification ..................................................................................5 
1.2. Introduction to Image Exploitation Services .....................................................5 
1.3. References for Section 1.......................................................................................5 

2. Background for Image Exploitation Services ....................................... 6 
2.1. Use Cases ...............................................................................................................6 

2.1.1. The Information Consumer Perspective................................................................................6 
2.1.1.1. The Farmer ................................................................................................................................... 6 
2.1.1.2. The Prospective Home Buyer....................................................................................................... 8 
2.1.1.3. The Soldier ..................................................................................................................................10 

2.1.2. The Information Producer Perspective ...............................................................................12 
2.1.2.1. Produce Feature Product..............................................................................................................13 
2.1.2.2. Extract Feature from Image.........................................................................................................14 
2.1.2.3. Edit Elevation Data .....................................................................................................................15 
2.1.2.4. Prepare Feature Source Package..................................................................................................16 
2.1.2.5. Register Images ...........................................................................................................................17 

2.1.3. Description of Some Services...............................................................................................19 
2.1.3.1. Display Image With Overlaid Graphics ......................................................................................19 
2.1.3.2. Generate Perspective Scene.........................................................................................................20 
2.1.3.3. Classify Pixels and Segment Image.............................................................................................20 
2.1.3.4. Automated Feature Detection......................................................................................................20 

2.2. Image Exploitation Services Categorization and Taxonomy .........................20 
2.2.1. Notes on the image exploitation service taxonomy .............................................................25 

2.3. Uses of Other Services........................................................................................26 
2.4. References for Section 2.....................................................................................27 

3. Abstract Specification for Image Exploitation Services .................... 28 
3.1. Ground Coordinate Transformation Services.................................................28 

3.1.1. Function ...............................................................................................................................28 
3.1.2. Service subtypes....................................................................................................................28 

3.1.2.1. Ground coordinate conversion (exact) services...........................................................................28 
3.1.2.2. Ground coordinate transformation (approximate) services..........................................................28 
3.1.2.3. Concatenated ground coordinate transformation services ...........................................................28 

3.1.3. Results Data..........................................................................................................................28 
3.1.4. Needed data ..........................................................................................................................29 
3.1.5. Discussion.............................................................................................................................29 

3.2. Image Coordinate Transformation Services....................................................30 
3.2.1. Function ...............................................................................................................................30 
3.2.2. Results Data..........................................................................................................................30 
3.2.3. Needed data ..........................................................................................................................30 
3.2.4. Service subtypes....................................................................................................................30 

3.2.4.1. Image-ground position transformation services...........................................................................30 
3.2.4.2. Image position transformation services (2-D to 2-D) ..................................................................31 
3.2.4.3. Concatenated image coordinate transformation services.............................................................31 

3.2.5. Discussion.............................................................................................................................31 
3.3. Imaging Time Determination Service...............................................................31 

3.3.1. Function ...............................................................................................................................31 

The Open GIS Abstract Specification  Page i 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.3.2. Service subtypes....................................................................................................................32 
3.3.2.1. Determine imaging time for one or more image positions ..........................................................32 

3.3.3. Results Data..........................................................................................................................32 
3.3.4. Needed data ..........................................................................................................................32 
3.3.5. Discussion.............................................................................................................................32 

3.4. Image Modification Services .............................................................................32 
3.4.1. Function ...............................................................................................................................32 
3.4.2. Service Subtypes ...................................................................................................................33 

3.4.2.1. Change pixel values services.......................................................................................................33 
3.4.2.2. Change pixel positions services...................................................................................................33 
3.4.2.3. Change image data format services .............................................................................................33 

3.4.3. Results Data..........................................................................................................................34 
3.4.4. Needed data ..........................................................................................................................34 
3.4.5. Discussion.............................................................................................................................35 

3.5. Dimension Measurement Services ....................................................................35 
3.5.1. Function ...............................................................................................................................35 
3.5.2. Service Subtypes ...................................................................................................................35 

3.5.2.1. Line segment dimensions services: .............................................................................................35 
3.5.2.2. Multi-segment line length service: ..............................................................................................35 
3.5.2.3. Area dimensions services: ...........................................................................................................35 
3.5.2.1. Height dimension service: ...........................................................................................................36 
3.5.2.2. Volume dimension service: .........................................................................................................36 
3.5.2.3. Temporal dimension service:.......................................................................................................36 

3.5.3. Results...................................................................................................................................36 
3.5.4. Needed data ..........................................................................................................................36 

3.6. Geodata Registration Services ..........................................................................37 
3.6.1. Function ...............................................................................................................................37 
3.6.2. Service Subtypes ...................................................................................................................37 

3.6.2.1. Adjust one SRS (Spatial Reference System) to another SRS. .....................................................37 
3.6.2.2. Adjust multiple SRSs to each other (but not adjust to a fixed SRS)............................................37 
3.6.2.3. Adjust multiple SRSs to a fixed SRS and to each other ..............................................................37 

3.6.3. Results Data..........................................................................................................................37 
3.6.4. Needed data ..........................................................................................................................37 
3.6.5. Discussion.............................................................................................................................38 
3.6.6. Related Services....................................................................................................................38 

3.7. Automated Image Matching Services...............................................................38 
3.7.1. Function ...............................................................................................................................38 
3.7.2. Service Subtypes ...................................................................................................................38 

3.7.2.1. Basic image matching services (services used by following subtypes): ......................................38 
3.7.2.2. Tie point extraction service .........................................................................................................38 
3.7.2.3. Control point transfer service ......................................................................................................39 
3.7.2.4. Elevation extraction service ........................................................................................................39 
3.7.2.5. Image pattern following services.................................................................................................39 
3.7.2.6. Fiducial mark measurement service ............................................................................................39 
3.7.2.7. Sample image matching services.................................................................................................39 

3.7.3. Results Data..........................................................................................................................39 
3.7.4. Needed data ..........................................................................................................................39 

3.8. Accuracy Conversion Services ..........................................................................40 
3.8.1. Function ...............................................................................................................................40 
3.8.2. Service Subtypes ...................................................................................................................40 

3.8.2.1. Convert covariance matrices to other forms ................................................................................40 
3.8.2.2. Convert other forms to covariance matrices ................................................................................40 

3.8.3. Results Data..........................................................................................................................40 
3.8.4. Needed data ..........................................................................................................................40 
3.8.5. Discussion.............................................................................................................................40 

3.9. Metadata Access Services ..................................................................................40 
3.9.1. Function ...............................................................................................................................40 

The Open GIS Abstract Specification  Page ii 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.9.2. Service Subtypes ...................................................................................................................41 
3.9.2.1. Image geometry model metadata access service .........................................................................41 
3.9.2.2. Spatial reference system (SRS) metadata access service.............................................................41 
3.9.2.3. Coordinate transformation metadata access service ....................................................................41 
3.9.2.4. Image format metadata access service.........................................................................................41 
3.9.2.5. Values (of pixels) metadata access service..................................................................................41 
3.9.2.6. Service capabilities metadata access service ...............................................................................41 
3.9.2.7. Service properties (or strategies) metadata access service...........................................................41 
3.9.2.8. Support Metadata Retrieval Services...........................................................................................41 
3.9.2.9. Support Metadata Modification Services ....................................................................................41 

3.9.3. Discussion.............................................................................................................................41 
3.10. Image Geometry Model Transformation Services.........................................41 

3.10.1. Function .............................................................................................................................41 
3.10.2. Consequences .....................................................................................................................41 
3.10.3. Service Subtypes .................................................................................................................42 

3.10.3.1. Fit approximate image geometry model to point positions computed using existing image 
geometry model........................................................................................................................42 

3.10.3.2. Convert image geometry model to different, mathematically equivalent model, by converting 
geometry parameters of existing image geometry model .........................................................42 

3.10.4. Results Data........................................................................................................................42 
3.10.5. Needed data ........................................................................................................................42 

4. Well Known Types and Structures ...................................................... 43 
4.1. Metadata..............................................................................................................43 
4.2. Image Pixels ........................................................................................................44 
4.3. Desired Image Section........................................................................................44 
4.4. Point Position Coordinates ................................................................................44 
4.5. Position Accuracy Estimates .............................................................................44 

4.5.1. Covariance Matrix Data Structures.....................................................................................45 
4.6. Elevation Data.....................................................................................................46 
4.7. Elevation Accuracy Estimates...........................................................................46 
4.8. Image SRS Definition.........................................................................................47 
4.9. Features With Geometry ...................................................................................48 
4.10. Strategy Parameters .........................................................................................48 
4.11. Selection of Service Operation.........................................................................48 
4.12. Other Inputs and Outputs................................................................................49 

4.12.1. Accuracy Conversion Parameters......................................................................................49 
4.13. Other Possible Outputs.....................................................................................50 
4.14. Hierarchical Name Value Lists........................................................................51 
4.15. Input and Output Specifications .....................................................................52 

4.15.1. Name Value List Use Objects.............................................................................................53 
4.16. ISO Standard IDL ............................................................................................54 

5. Future Work........................................................................................... 55 
5.1. Software Frameworks........................................................................................55 

6. Appendix A. Acronyms and Glossary ................................................. 56 
6.1. Acronyms ............................................................................................................56 
6.2. Definitions ...........................................................................................................56 

7. Appendix B. The Geospatial Data Extraction Process ...................... 63 

The Open GIS Abstract Specification  Page iii 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

8. Appendix C. OGC Image Levels .......................................................... 65 

The Open GIS Abstract Specification  Page iv 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

1. Introduction 

1.1. The Abstract Specification 
The purpose of the Abstract Specification is to create and document a conceptual model sufficient 
enough to allow for the creation of Implementation Specifications. The Abstract Specification 
consists of two models derived from the Syntropy object analysis and design methodology [1].  

The first and simpler model is called the Essential Model and its purpose is to establish the 
conceptual linkage of the software or system design to the real world. The Essential Model is a 
description of how the world works (or should work).  

The second model, the meat of the Abstract Specification, is the Abstract Model that defines the 
eventual software system in an implementation neutral manner. The Abstract Model is a description 
of how software should work. The Abstract Model represents a compromise between the paradigms 
of the intended target implementation environments. 

The Abstract Specification is organized into separate topic volumes in order to manage the 
complexity of the subject matter and to assist parallel development of work items by different 
Working Groups of the OGC Technical Committee. The topics are, in reality, dependent upon one 
another⎯ each one begging to be written first. Each topic must be read in the context of the entire 
Abstract Specification.  

The topic volumes are not all written at the same level of detail.  Some are mature, and are the basis 
for Requests For Proposal (RFP). Others are immature, and require additional specification before 
RFPs can be issued. The level of maturity of a topic reflects the level of understanding and 
discussion occurring within the Technical Committee. Refer to the OGC Technical Committee 
Policies and Procedures [2] and Technology Development Process [3] documents for more 
information on the OGC OpenGIS™ standards development process. 

Refer to Topic Volume 0: Abstract Specification Overview [4] for an introduction to all of the topic 
volumes comprising the Abstract Specification and for editorial guidance, rules and etiquette for 
authors (and readers) of OGC specifications. 

1.2. Introduction to Image Exploitation Services 
This topic volume is the portion of the OpenGIS™ Abstract Specification that describes the 
categories and taxonomy of image exploitation services needed to support the use of images and 
certain related coverage types. The Image Exploitation Services SIG of the Core Task Force is 
using this categorization to organize their work, especially development of more detailed abstract 
specification material for each service category. 

Image exploitation services are required to support most aspects of image exploitation, including 
precision measurement of ground positions and of object dimensions. For example, a variety of 
services are needed for extracting features from images, or digital elevations from stereoscopic 
images. Image exploitation services are widely implemented and used in photogrammetric systems, 
currently using custom interfaces. Although the focus of this document is on services for using 
images, many of these services are expected to also be applicable to using other types of grid 
coverages and some non-grid coverages. 

1.3. References for Section 1 
[1] Cook, Steve, and John Daniels, Designing Objects Systems: Object-Oriented Modeling with 

Syntropy, Prentice Hall, New York, 1994, xx + 389 pp. 
[2] Open GIS Consortium, 1997. OGC Technical Committee Policies and Procedures, Wayland, 

Massachusetts. Available via the WWW as <http://www.opengis.org/techno/development.htm>. 
[3] Open GIS Consortium, 1997. The OGC Technical Committee Technology Development Process,  

Wayland, Massachusetts. Available via the WWW as 
<http://www.opengis.org/techno/development.htm>. 

[4] Open GIS Consortium, 1999.  Topic 0, Abstract Specification Overview, Wayland, Massachusetts.  
Available via the WWW as <http://www.opengis.org/techno/specs.htm>. 

The Open GIS Abstract Specification  Page 5 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

http://www.opengis.org/techno/development.htm
http://www.opengis.org/techno/development.htm
http://www.opengis.org/techno/specs.htm


   

2. Background for Image Exploitation Services 

2.1. Use Cases 
This Section presents a set of use cases that have been defined to support the definition the needed 
image exploitation services. That is, most listed steps in each use case will use one or more image 
exploitation services. These use cases start to show how image exploitation services are used in the 
“real world.” This Section also starts to define the image exploitation services that are needed by 
each use case. These use cases are grouped into two types: information consumer and information 
producer. 

2.1.1. The Information Consumer Perspective 
The following “use cases” describe several possible situations in which information consumers 
could perform activities that require uses of image exploitation services.  

2.1.1.1. The Farmer 
A farmer has the goal of making management decisions on the application of insecticide, fertilizer, 
and irrigation to his fields. To do this: 

1)  The farmer obtains a map of his fields, through an interface to a local or remote map library or 
to a map creation service. (Note that this interface determines the spatial datum and projection and 
scale, or units, of the map). The farmer overlays this map with: 

a) One or more previous images of his fields, orthorectified to overlay the map (obtained from 
a local or remote crop image library),  

b) One or more previous years crop yield results (note that the yield information might be grid 
coverages, linear features, or polygon features),  

c) Soil sample results, recent and previous (note that the soil samples are point features), 

d) Selected scouting reports (note that the scouting reports may be point features). 

2)  Using this data, the farmer assesses the need for fertilizer as a function of location in his fields. 
(Note that the algorithm which estimates the fertilizer need requirements may be provided by the 
local farmer's cooperative. That algorithm uses the map, current crop image, previous years yields, 
and soil samples as input.) The fertilizer need function produces a coverage that aligns with the 
farmer’s fields, where each polygon represents certain fertilizer application requirements. 

3)  The farmer can use historical data to find areas of crop damage due to insects, and determine 
appropriate corrective action. The need for insecticide is estimated using multispectral images from 
each of the past five years that have been processed to highlight insect infestation. (Note that the 
multispectral images are obtained via an interface to USDA's database, with rectification 
parameters that ensure that it will fit the map automatically. The "insecticide need" is a partition of 
the farmer’s fields into polygons, each of which specifies a certain mixture and concentration of 
chemicals. The algorithm that computes these polygons and concentrations from the multispectral 
imagery is provided by the local extension service.) 

4)  To help minimize the environmental impact of applying fertilizer and pesticides, the decision 
support tools would use additional data. These tools overlay the "insecticide need" polygons and 
values, and the “fertilizer need” polygons, with wetlands data from the county or state (note that the 
wetlands data is a vector file), together with sensitivity factors from the Fish and Wildlife office 
(this is a raster file). Then, using an algorithm from the EPA, the farmer modifies his insect and 
fertilizer plans to protect a creek natural habitat of an endangered species.  

5)  The farmer generates an irrigation schedule for today and tomorrow. The irrigation need is 
determined by an algorithm using weather data (obtained from a weather prediction service), soil 
samples, and the current soil moisture profile (obtained through an interface to NASA's real-time 
data). 

6)  The farmer can review all the data to detect small areas (or points) where needed or useful data 
is missing or ambiguous. The farmer can then select a few specific areas where future scouting 
reports would probably be beneficial. 

The Open GIS Abstract Specification  Page 6 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Notice the various actors: the farmer, the state university extension service (with insect data), the 
EPA, fish and wildlife, the farmer's cooperative (with algorithms), the image library (could be a 
commercial or a government source), USGS, etc.  

Note that the selective application of fertilizer, insecticide, and irrigation probably would be done 
by computer controlled farm equipment using GPS. Similarly, crop yield information would be 
automatically collected by harvesting equipment using GPS. 

Notes: The above discussion assumes irrigation is being used. In some farming areas, irrigation is 
always used. However, irrigation is never used in other farming areas. Other aspects of the above 
use case are probably applicable to some farming areas but not to other areas. 

The above discussion assumes that algorithms and data are supplied by outside agencies such as the 
farmer's cooperative, the state university extension service, etc. However, outside sources 
(particularly those supplying material and services) may not be the best source of algorithms. The 
farmer has a personal and vital interest in the results, and wants to avoid bias if possible. The 
farmer must at least retain understanding and customizing capability. He also needs to retain data 
ownership rights over his operation. That said, there can be value in getting the viewpoint of 
someone who sees a lot of other surrounding operations for comparison. 

Table 2-1 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. 

 

The Open GIS Abstract Specification  Page 7 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Use Case Step Image Exploitation Services Used 

1) Obtains map of his fields  
a) overlays it with images of his 

fields 
Display image with overlaid graphics 

b) overlays that with crop yield 
results 

Display image with overlaid graphics 

c) overlays that with soil sample 
results 

Display image with overlaid graphics 

d) overlays that with scouting 
reports 

Display image with overlaid graphics 

2) Assesses need for fertilizer as 
function of location in fields 
(displaying fertilizer need) 

Classify pixels and segment image, 
Display image with overlaid graphics 

3) Overlays all previous data with 
multispectral images from each of 
past 5 years 

Display image with overlaid graphics 

a) processed to highlight insect 
infestation 

Classify pixels and segment image 

b) assesses need for insecticide 
(displaying insecticide need)  

Classify pixels and segment image, 
Display image with overlaid graphics 

4) Overlays (above) with wetlands 
data  

Display image with overlaid graphics 

a) together with sensitivity 
factors 

Display image with overlaid graphics 

b) modifies insect and fertilizer 
plans to protect creek 

Classify pixels and segment image, 
Display image with overlaid graphics 

5) Generates irrigation schedules   
a) overlays all above with soil 

moisture profile 
Display image with overlaid graphics 

b) determines irrigation need Classify pixels and segment image, 
Display image with overlaid graphics 

6) Reviews all data to detect areas 
where useful data is missing or 
ambiguous 

Display image with overlaid graphics 

a) selects areas for future 
scouting reports 

Classify pixels and segment image, 
Display image with overlaid graphics 

Table 2-1. Image Exploitation Services Needed by “The Farmer” 

2.1.1.2. The Prospective Home Buyer 
The buyer, in the real estate broker's office or from home, selects a neighborhood (from an Internet 
service provided to support home-buying in a region), and is provided an aerial view of it. Service 
functions allow the buyer to zoom and roam through the region covered by the broker or service 
provider. Houses for sale appear in a red tint. Service interfaces allow the buyer to state a price 
range and mandatory features. Houses for sale in the desired price range and with the mandatory 
features flash red and green.   

A few candidate green-and-red homes are selected through interfaces provided to the prospective 
buyer.   

Functions using elevation data produce a three-dimensional perspective that allows the buyer to 
assess the view from each back porch.   

A function that allows a virtual walk-through of the rooms of the house may be available.   

The Open GIS Abstract Specification  Page 8 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Using orthorectified county imagery from 5, 10, 15, and 20 years ago, the buyer assesses the age of 
the roof, the health of the trees, and the trends in the neighborhood.  

Using city, county and state data, the imagery is superimposed with: 

1. Underground pipe and wire information (linear features);  

2. The assigned school districts and schools (point and area features) 

3. The nearest hospital and fire station  

4. The lot lines  

5. All easements and right-of-ways.   

Using chamber of commerce data, the nearest shops and supermarket and auto repair shops are 
located and superimposed.   

Using Automobile Association data, a family of alternate routes to work are determined, with the 
conditions that make each optimal. Each route is displayed, registered to the image backdrop.  

Using thermal infrared imagery from the department of energy, the prospective buyer assesses the 
heat loss in winter, and the need for new insulation. The algorithm is provided by EPA and DoE, 
jointly. 

Using measuring tools, the sizes of the lot and house are separately measured. The size of the 
parking area is assessed and compared to the number of cars owned by the buyer.   

Using census tract data and interfaces provided to the buyer, the demographics of the 
neighborhoods are visualized.  

Table 2-2 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. 

Use Case Step Image Exploitation Services Used 

1) Selects neighborhood and is provided 
aerial view of (neighborhood) 

 

a) Selects neighborhood  

b) provided aerial view of 
(neighborhood) 

Display image 

c) Houses for sale appear in red tint 
(or) flash red and green 

Display image with overlaid graphics 

2) A few candidate homes are selected by 
prospective buyer 

Display image with overlaid graphics 

3) (Display) artificial perspective (of) 
view from each back porch 

Generate perspective scene, 

Display image (with overlaid graphics?) 

4) Virtual walk-through of rooms of 
house 

Generate perspective scene, 

Display image (with overlaid graphics?) 

5) Assess age of roof, health of trees, and 
trends in neighborhood, using county 
imagery from 5, 10, 15, and 20 years 
ago 

Classify pixels and segment image, 

Display image with overlaid graphics 

The Open GIS Abstract Specification  Page 9 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

6) Imagery is superimposed with: 

a) underground pipe and wire 
information 

b) school districts and schools 

c) nearest hospital and fire station 

d) lot lines 

e) easements and rights of way 

Display image with overlaid graphics 

7) Nearest shops and supermarket and 
auto repair shops are located and 
superimposed 

Display image with overlaid graphics 

a) Using chamber of commerce data 
or images 

Classify pixels and segment image? 

8) Family of alternate routes to work are 
charted, with conditions that make 
each optimal 

 

a) Using Automobile Association 
data 

 

b) Each is registered to image 
backdrop 

Display image with overlaid graphics 

9) Assesses heat loss in winter, and need 
for new insulation, using thermal 
infrared imagery. The algorithm is 
provided by EPA and DoE jointly. 

Classify pixels and segment image 

a) (display color coded heat loss 
rating results) 

Display image with overlaid graphics 

10) Size of lot and house are independently 
measured 

Compute area of polygon visible in image 

11) Size of parking area is assessed and 
compared to number of cars owned by 
buyer 

Compute area of polygon visible in image, 

Compute length of object visible in image 

12) Demographics in neighborhoods are 
visualized, using census tract data 

Display image with overlaid graphics 

Table 2-2. Image Exploitation Services Needed by "The Home Buyer" 

The image exploitation services listed above assume: 

1. All displays are in a (scaled and windowed) ground coordinate system (not in an unrectified 
image coordinate system). 

2. Selection of a neighborhood is done using either a text menu or a graphic map display (not using 
an image display). 

3. Virtual walk-through of a house is done using images of the house interior. 

2.1.1.3. The Soldier 
The soldier is on a peacekeeping mission.  He uses information from surveillance cameras in 
planes, drones, and satellites.  He receives video day and night in a continuous stream from 
lightweight airborne platforms, and he receives still images periodically. [Interfaces allow the 
soldier to selectively archive interesting imagery, and to retrieve it using categories of interest.] 

He is able to pass the imagery through feature detection algorithms (looking for airplanes, rockets, 
artillery, etc.) that may be local or remote.  The soldier (or the detection algorithm) can 

The Open GIS Abstract Specification  Page 10 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

automatically bring up yesterday's image whenever something is suspicious in order to reduce the 
number of false "hits".  If an interesting spot wasn't covered yesterday, older imagery is can be 
provided and used.   

The image detection algorithms need to know where the roads are in the images, so an interface is 
provided that projects roads into the image geometry.  Of course this assumes a prior interface that 
registers the road data to the images. 

Image coordinates  (pixel row and column) are automatically converted to the position data needed 
by his ordnance (that is, point and aim information).  All the types of ordnance understand the 
target position objects; conversion is not necessary. [That is, a common interface exposes target 
positions.] 

The soldier is in contact with his command authority; they share a common view of the battle 
space.  [That is, there is a single interface (or family of interfaces) exposing a view of the battle 
space.] 

The soldier finds something of interest on an image. He points at it and with a simple interface 
generates a report instantly that is understood by other analysts, who check his finding using other 
sources.   

The other analysts are coalition members who speak a different language, and are supported with 
different technology, and who use different datums and projections.  Yet interfaces bridge these 
gaps.  

The soldier in his spare time makes contingency mission plans: selects potential targets, finds 
optimum access and egress paths, prepares flight folders that pilots and other weapon control 
officers can use to train, navigate, execute, escape, etc.   [Note that interfaces exist to create and 
modify mission plans, and that mission plans include coordinated maps, images, vector and 
coverage features, …] 

Table 2-3 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. 

 

Use Case Step Image Exploitation Services Used 

1) Uses information from surveillance 
cameras in planes, drones, and 
satellites 

 

a) receives video in a continuous 
stream, and receives still images 
periodically 

Display still image, 

Display video images 

b) selectively archive interesting 
imagery 

Capture selected frame of video image 

c) retrieve (archived images) using 
categories of interest 

 

2) Pass imagery through feature detection 
algorithms 

Automated feature detection 

a) bring up yesterday's (or older) 
image whenever something is 
suspicious 

Display images, 

Automated feature detection 

b) to reduce the number of false 
"hits" 

Automated feature detection 

3) Know where roads are in images  

a) projects roads into image 
geometry 

Display image with overlaid graphics 

b) registers road data to images Register images to ground control 

The Open GIS Abstract Specification  Page 11 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

4) Image coordinates ... converted to 
position data needed by ordnance 
(point and aim information) 

Compute ground from image positions, 

Transform ground coordinates 

5) Share common view of battle space 
with command authority 

Transform ground coordinates, 

Compute ground from image positions, 

Compute image from ground positions 

6) Points at something of interest on 
image and generates report instantly, 
understood by other analysts, who 
check his finding 

Compute ground from image positions, 

Transform ground coordinates, 

Automated image report generation, 

Display image with overlaid graphics 

7) Other analysts speak a different 
language, are supported with different 
technology, and use different datums 
and projections 

Transform ground coordinates 

8) Makes contingency mission plans:   

a) selects potential targets Compute ground from image positions, 

Transform ground coordinates 

b) finds optimum access and egress 
paths 

 

c) prepares flight folders, etc. Automated image report generation 

Table 2-3. Image Exploitation Services Needed by "The Soldier" 

The listed services assume that all displays are in a (scaled and windowed) un-rectified image 
coordinate system (not in a ground coordinate system).  

2.1.2. The Information Producer Perspective 
Figure 2-1 is a UML diagram of the five use cases defined in this Section. Each of these five use 
cases is defined and described in the following subsections. These five use cases show steps of a 
workflow used by information producers to extract geospatial data from images. They were derived 
from the conceptual process for geospatial data extraction described in Section 7 (Appendix B. The 
Geospatial Data Extraction Process). The five use cases presented in this section represent only a 
few of the many possible image exploitation scenarios that can be derived from the conceptual 
model of Section 7. Refer also to Section 8 (Appendix C. OGC Image Levels) for a description of 
the OGC standard set of image levels to be used in labeling processed images.  

Produce
Feature
Product

User

Edit
Elevation Data

«uses»

Extract Feature
From Image

«uses»

Register
Images

«uses»

Prepare
Feature Source

Package

«uses»

 

The Open GIS Abstract Specification  Page 12 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Figure 2-1. Use Cases for Extracting Geospatial Information from Images 

2.1.2.1. Produce Feature Product 
In the Produce Feature Product use case, the actor is a user of a photogrammetric system 
(sometimes called an operator, a photogrammetrist, or a cartographer). This use case is started 
when the user starts to produce a specific feature product. The assumptions made in this use case 
include: 

1. A feature product is (all or mostly) a collection of features with geometry, and/or one or more 
coverages based on feature collections. 

2. Images plus existing vector feature data are used to produce the new feature product. 

3. Elevation data is needed to obtain correct horizontal positions from feature positions in images. 

4. A feature product may include elevation data, in feature geometry vertices and/or separately 

5. An external use case handles decisions to produce feature products, plus any needed assignment 
and scheduling of users and systems. 

Table 2-4 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. Some of the use case listed in the table are optional. Several of these steps 
could be lower level use cases, such as the fourth step “Edit existing feature”. This table also lists 
some of the metadata used and generated by each step. 

 

Use Case Step Image Exploitation 
Services Used 

Metadata Used Metadata Generated 

1) Prepare feature source 
package, to be used to 
produce product 

(see separate use case) (see separate use case) (see separate use case) 

2) If needed, edit elevation data 
covering product area (see separate use case) 

(see separate use case) (see separate use case) 

3) Display features graphically 
overlaid on images (display 
both existing and newly 
extracted features) 

Display images with overlaid 
graphics, 
Enhance images 

SRS for features, 
SRS for images 

- 

4) If needed, edit existing 
feature for inclusion in new 
product (repeat for each 
existing feature to be 
included in product) 

Classify and segment image Quality of existing 
features 

Quality for new 
product 

5) Extract feature from image  
(repeat for each new feature 
to be included in product) 

(see separate use case) (see separate use case) (see separate use case) 

6) Check new product    

a) Review all features in 
product, separately and 

overlaid on images 

Display images with overlaid 
graphics, 
Enhance Images, 
Classify and segment image 

SRS for features, 
SRS for images 

Quality for new 
product 

b) Evaluate quality of new 
product 

 ? Quality for new 
product 

7) Release new feature product  - Store all metadata for 
new product 

Table 2-4. Image Exploitation Services Used to Produce Feature Product 

Some of the possible variations in this use case are: 

1. Nature of feature product, either: 

1.1. Updated existing product 

The Open GIS Abstract Specification  Page 13 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

1.2. New product 

2. Elevation values attached to feature vertices, either: 

2.1. No elevation values recorded 

2.2. Elevation values automatically obtained from elevation data 

2.3. Elevations values extracted from stereoscopic images (with horizontal positions) 

3. Type of images from which features are extracted or edited, either: 

3.1. Stereoscopic images 

3.2. Unrectified monoscopic images 

3.3. Rectified monoscopic images 

3.4. Orthorectified monoscopic images 

3.5. Mosaicked monoscopic images, normally orthorectified first 

2.1.2.2. Extract Feature from Image 
In the Extract Feature from Image use case, the actor is a user of a photogrammetric system 
(sometimes called an operator, a photogrammetrist, or a cartographer). This use case is started 
when the user decides to extract a new feature from displayed image(s). The assumption made in 
this use case is that a feature with geometry is to be extracted. 

Table 2-5 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. Some of the use case steps listed in the table are optional. Several of these 
steps could be lower level use cases. This table also lists some of the metadata used and generated 
by each step. 

Use Case Step Image Exploitation 
Services Used 

Metadata Used Metadata Generated 

1) Delineate new feature 
geometry in image(s) 

Classify and segment 
images, 
Delineate feature positions 

- Quality for 
delineation 

2) Convert feature geometry to 
product SRS 

Convert image positions to 
product SRS 

SRS for image, 
SRS for new product, 
Quality for delineation 

Quality for new 
feature 

3) If needed, measure 
dimension of feature from 
images, in product SRS (for 
example, measure feature 
height or width) 

Delineate feature positions, 
Measure object dimensions 

See step 2, 
Feature attributes for 
new product 

Quality for new 
feature 

4) Assign type and all attributes 
to feature 

 Feature types and 
attributes for new 
product 

Quality for new 
feature 

5) Automatically check 
extracted feature 

 Feature types and 
attributes for new 
product 

Quality for new 
feature 

6) Display new feature overlaid 
on image(s) 

Display images with overlaid 
graphics, 
Convert ground positions to 
image SRS 

SRS for image, 
SRS for new product 

- 

7) Review extracted feature  ? Quality for new 
feature 

Table 2-5. Image Exploitation Services Used to Extract Feature from Image 

Some of the possible variations in this use case are: 

1. Type of images from which features extracted or edited, either: 

The Open GIS Abstract Specification  Page 14 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

1.1. Stereoscopic images 

1.2. Unrectified monoscopic images 

1.3. Rectified monoscopic images 

1.4. Orthorectified monoscopic images 

1.5. Mosaicked monoscopic images, usually orthorectified first 

2. Elevation values attached to feature vertices, either: 

2.1. No elevation values recorded 

2.2. Elevation values automatically obtained from elevation data 

2.3. Elevations values extracted from stereoscopic images (with horizontal positions) 

2.1.2.3. Edit Elevation Data 
In the Edit Elevation Data use case, the actor is a user of a photogrammetric system (sometimes 
called an operator, a photogrammetrist, or a cartographer). This use case is started when the user 
decides to edit or extract elevation data.  

Table 2-6 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. Some of the use case steps listed in the table are optional. Several of these 
steps could be lower level use cases. This table also lists some of the metadata used and generated 
by each step. 

 

Use Case Step Image Exploitation 
Services Used 

Metadata Used Metadata Generated 

1) Obtain stereoscopic images 
suitable for extracting 
elevations, with image 
support data (perhaps obtain 
images from an image 
library or archive) 

Display images with overlaid 
graphics? 
Enhance images? 

Found using 
metadata for images, 
Obtained with 
support metadata 

- 

2) Display elevation data 
graphically overlaid on 
stereoscopic images (display 
both existing and newly 
extracted elevations) 

Display stereoscopic images 
with overlaid graphics, 
Convert ground positions to 
image SRS 

SRS for elevation 
data, 
SRS for images 

Quality of parallaxes 

3) Where needed, edit existing 
elevation point (repeat for 
each existing elevation point 
to be edited) 

see step 2 See step 2, 
Accuracy for existing 
elevation point 

Modified accuracy for 
elevation point 

4) Where needed, extract new 
elevation point (repeat for 
each new elevation point 
needed) 

see step 2, 
Automatically measure point 
elevation, 
Manually measure point 
elevation 

See step 2, 
Image accuracy 

Accuracy of new 
elevation point 

5) Display (new or edited) 
elevation point graphically 
overlaid on images 

see step 2 See step 2 - 

6) Check modified elevations    
a) Review all elevations, 

separately and overlaid 
on images 

 See step 2, 
Quality for modified 
elevation data? 

Quality for modified 
elevation data? 

b) Evaluate quality of 
elevation data 

 ? Quality for modified 
elevation data 

7) Release modified elevation 
data 

 - Store all metadata for 
edited elevation data 

The Open GIS Abstract Specification  Page 15 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Table 2-6. Image Exploitation Services Used to Edit Elevation Data 

Some of the possible variations in this use case are: 

1. Nature of elevation data, either: 

1.1. Grid elevation data 

1.2. TIN elevation data 

1.3. Contour lines 

1.4. Geomorphic features (that is, ridge lines, valley lines, slope break lines, peak points, 
saddle points, etc.) 

1.5. Combination of above 

2. Nature of elevation extraction, either: 

2.1. Edit existing elevation data (e.g., improve accuracy, density, etc.) 

2.2. Extract new elevation data (in part or all of product area) 

2.3. Combination of above 

2.1.2.4. Prepare Feature Source Package 
In the Prepare Feature Source Package use case, the actor is a user of a suitable source package 
preparation system. This use case is started when the user begins to prepare to produce a specific 
feature product. The assumptions made in this use case include: 

1. Images plus existing vector feature data are used to produce the feature product, 

2. Elevation data is needed to obtain correct horizontal positions from feature positions in images, 

3. An external use case handles decisions to produce feature products, plus any needed assignment 
and scheduling of users and systems. 

Table 2-7 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. Some of the use case listed in the table are optional. Several of these steps 
could be lower level use cases. This table also lists some of the metadata used and generated by 
each step.  

 

Use Case Step Image Exploitation 
Services Used 

Metadata Used Metadata Generated 

1) Define feature product to be 
extracted, including: 

   

a) If new product is in a 
series or of a standard 
type, obtain definitions 
of product series or type 

 Various metadata for 
product series or type 

- 

b) Define product Spatial 
Reference System 
(SRS) 

 SRS for product series 
or type 

SRS for new product 

c) Define product area to 
be covered (in product 
SRS) 

 Covered area for 
product series or type 

Covered area for new 
product 

d) Define feature types 
and attributes for use in 
product 

 Feature types and 
attributes for product 
series or type 

Feature types and 
attributes for new 
product 

2) Obtain existing feature data 
suitable for use and 
connection to by product 
(obtaining feature data from 

 Found using metadata 
for feature data, 
Obtained with feature 
metadata 

Source for new 
product 

The Open GIS Abstract Specification  Page 16 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

a product library or archive) 
3) Obtain images suitable for 

producing product, with 
image support data (perhaps 
obtain images from an image 
library or archive) 

Display images with 
overlaid graphics? 

Found using metadata 
for images, 
Obtained with image 
metadata 

Source for new 
product 

4) Obtain existing elevation 
data covering product area 
(obtaining elevation data 
from a library or archive) 

Display images with 
overlaid graphics? 

Found using metadata 
for elevation data, 
Obtained with elevation 
metadata 

Source for new 
product 

5) If needed, register images to 
each other and to existing 
feature and elevation data 
(see separate use case) 

(see separate use case) (see separate use case) (see separate use case) 

Table 2-7. Image Exploitation Services Used to Prepare Feature Source Package 

Some of the possible variations in this use case are: 

1. Nature of feature product, either: 

1.1. Updated existing product 

1.2. New product in a standard series of products 

1.3. New product of a predefined type of products 

1.4. Completely custom product 

2. Type of images from which features to be extracted or edited, either: 

2.1. Stereoscopic images 

2.2. Unrectified monoscopic images 

2.3. Rectified monoscopic images 

2.4. Orthorectified monoscopic images 

2.5. Mosaicked monoscopic images, usually orthorectified first 

2.1.2.5. Register Images 
In the Register Images use case, the actor is a user of a suitable photogrammetric system. This use 
case is started when the user decides that one or more images need to be registered to each other 
and/or to existing digital feature and elevation data. The assumptions made in this use case include: 

1. One or more images plus existing data are to be used to produce feature and/or elevation 
products, and the existing mathematical models of (some of) these image geometries are not as 
accurate as needed. 

2. For registration, the existing image geometry models will be adjusted by a mathematical process 
that uses the positions of multiple points as measured in the images being adjusted. 

3. The points used in adjustment include “control” points and/or “tie” Points. Control points are 
points whose ground coordinates are known (with some accuracy), in three, two, or just one 
dimension. Tie points are points whose ground coordinates are not known (with useful accuracy), 
but which can be measured in two or more overlapping images. 

4. Control points are selected from existing feature and/or elevation data. Some of this existing data 
will be used in the new product, or is in existing adjacent products with which the new product 
should be consistent. Other existing data may also be used, that is not to be used in the product. 
Specifically, “ground control” point features may exist for this purpose which have higher 
accuracies and/or include supplementary information to help find the proper point in the image(s). 

Table 2-8 summarizes the steps in this use case and lists some of the image exploitation services 
needed by each step. Some of the use case listed in the table are optional. Several of these steps 

The Open GIS Abstract Specification  Page 17 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

could be lower level use cases, especially the step “Compute corrected image geometry models”. 
Indeed, a variety of different use cases for that step could be defined, using different methods for 
computing the corrected geometry models using the point data. This table also lists some of the 
metadata used and generated by each step.  

 

Use Case Step Image Exploitation 
Services Used 

Metadata Used Metadata Generated 

1) Obtain the existing 
parameter values of the 
image geometry models for 
all images to be registered. 
These parameter values 
include information for each 
individual image, such as 
camera position data 
collected at the time of 
image exposure using the 
Global Positioning System 
(GPS) or an Inertial 
Navigation System (INS). 
These parameter values also 
include data common to 
multiple images, such as 
camera calibration 
information. 

 Current image geometry - 

2) Obtain additional existing 
feature data suitable for use 
as control points in the 
registration process 
(obtaining feature data from 
a library or archive) 

Display images with 
overlaid graphics? 

Found using metadata 
for feature data, 
Obtained with feature 
metadata, 
SRS for images 

Source for image 
registration 

3) Obtain additional existing 
elevation data suitable for 
use in the registration 
process (obtaining elevation 
data from a library or 
archive) 

Display images with 
overlaid graphics? 

Found using metadata 
for elevation data, 
Obtained with elevation 
metadata, 
SRS for images 

Source for image 
registration 

4) Select suitable control points 
in the existing feature and/or 
elevation data 

Display images with 
overlaid graphics 

Feature position 
accuracy, 
SRS for features, 
SRS for images 

Control point accuracy 

5) Select suitable tie points Display images with 
overlaid graphics, 
Measure point positions, 
Automatically select tie 
points 

Current image geometry Image position 
accuracy 

6) Measure the position of each 
selected control point in one 
or more of the images in 
which that point is visible 

Display images with 
overlaid graphics, 
Automatically measure 
corresponding image 
positions, 
Manually measure 
corresponding image 
positions 

Current image 
geometry, 
SRS for features, 
SRS for images 

Image position 
accuracy 

7) Measure the position of each 
selected tie point in each 
other image in which that 
point is visible 

see step 6 Current image geometry Image position 
accuracy 

8) Check all point position data 
for consistency, to detect any 

Display images with 
overlaid graphics 

See step 6  

The Open GIS Abstract Specification  Page 18 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

major errors (or blunders) 
9) Correct or eliminate the 

point position data detected 
as erroneous 

Display images with 
overlaid graphics 

See step 6  

10) Compute corrected values 
for selected parameters of 
the image geometry models 
for all images, so as to obtain 
the best practical fit to the 
known ground and image 
positions of all selected 
control and tie points 

Register images/geodata, 
Convert ground position to 
image SRS, 
Convert image position to 
ground SRS 

See step 6 Modified image 
geometry, 
Image accuracy data 

11) Check corrected image 
geometry models, to detect 
any major errors (or 
blunders) 

Display images with 
overlaid graphics 

Modified image 
geometry 

Image accuracy data 

12) Record corrected image 
geometry model data, in a 
form suitable for setting up 
images for data extraction 

 Modified image 
geometry, 
Image accuracy data 

Store modified image 
metadata 

Table 2-8. Image Exploitation Services Used to Register Images 

Technical Note: Position accuracy data is often required for ground and image coordinates that are 
generated or used. Methods need to be developed for determining the accuracy and other quality 
metadata listed above under Metadata Generated. The draft of ISO 15046-14 specifies some quality 
determination methods. Some other quality determination methods also exist, but they are not 
complete and are of questionable reliability.) 

Some of the possible variations in this use case are: 

1. Lines can be used for image registration in addition to points, or instead of points, perhaps called 
“control lines” and “tie lines”. The corresponding positions of lines can be matched in one less 
dimension than for points: one dimension instead of two dimensions for image positions. 

2.1.3. Description of Some Services 
This section describes in more detail some of the image exploitation services listed for steps the 
above use cases. 

2.1.3.1. Display Image With Overlaid Graphics 
As listed above, many use case steps display an image, usually with overlaid graphics. The overlaid 
graphics are used to display features or elevations plus measurement cursors and perhaps other 
information. Such image display uses a number of image exploitation services, including: 

1. Retrieve selected image window from larger image, centered on a specified image position 
(roaming) and with a specified window size (zooming). 

2. Resample pixels of retrieved image window to change pixel spacing (zooming). 

3. Enhance images, to make desired features more easily visible 

4. Rectify or orthorectify original image, either whole image or retrieved window of image. 

5. Mosaic multiple rectified or orthorectified images (mosaicking is not always needed). 

6. Convert data positions stored in another coordinate system into the ground coordinate system of 
the display window. 

7. Convert data positions stored in all other coordinate systems into the image coordinate system of 
the display window. 

8. Allow user to pick a graphically displayed item, and then present a full description of the 
selected item. 

The Open GIS Abstract Specification  Page 19 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Items 4 through 6 listed above are appropriate when the display is in a ground-position-based 
coordinate system, as assumed for “The Farmer” and “The Prospective Home Buyer” use cases. 
When the display is in an image-position-based coordinated system, as assumed for “The Soldier” 
use case, items 4 through 6 above are replaced by item 7. 

Many items listed above could be done in real-time for just the portion of the images being 
displayed, as implied in the above list. Alternately, these operations could be done in a pre-
processing step for the entire images. In that case, these operations could be done as a step 6 at the 
end of the Prepare Feature Source Package use case 

2.1.3.2. Generate Perspective Scene 
Generation of a perspective scene (or image perspective transformation) is the generation of a 
synthetic image by processing one or more actual images. Each synthetic image is generated to 
simulate a different image geometry, such as an image taken from a different point in space and/or 
looking in a different direction. In addition to using one or more actual images, perspective scene 
generation uses data defining the (approximate) shape of the visible surface that was imaged. This 
shape data is usually derived from grid elevation data, and can include vector feature 3-D shape 
data. 

2.1.3.3. Classify Pixels and Segment Image 
As listed, many use case steps classify image pixels and segment the resulting image (or raster data 
set). Such image manipulation can use a number of image exploitation services, including: 

1. Register multiple images, coverages, and feature collections to one another. 

2. Reproject and resample vector feature coverages and raster image coverages to one another, or to 
a third common coverage scheme (e.g. grid).  

3. Change pixel values, to make the properties of interest more easily visible (including reduction 
of effective "noise"). These imagery enhancement operations can use (input) data from only one 
pixel at a time, or from a small neighborhood of adjacent pixels. 

4. Apply previously defined classification or other analysis algorithms to multispectral pixel data. 
These classification or analysis algorithms can: 

• Produce results that are discrete (assigning each pixel to one of several possible 
categories) or continuous (assigning a numeric value to each pixel, as derived from a 
continuous function). 

• Use data from only one pixel at a time, or from a small neighborhood of adjacent pixels. 

• Use multiple bands from the same image or from different images that have been 
registered to each other (see item 1). One or more bands can also be non-image 
coverages, that are registered to all other data. 

5. Segment classified or analyzed image into discrete regions with similar properties, by finding 
groups of adjoining pixels with the same or similar values. The segmentation results can be 
produced in either raster or vector form. Such segmentation usually ignores single pixels or 
very small regions that may differ from all surrounding pixels. 

2.1.3.4. Automated Feature Detection 
Automated feature detection can also use a number of image exploitation services, including all 
those listed above for Classify Pixels and Segment Image. The results of such Classify Pixels and 
Segment Image operations are then automatically and/or manually analyzed to detect the feature 
types of interest and their attributes. Alternately or in addition, the image being analyzed can be 
compared with sample images showing the feature types of interest. 

Automated feature detection is largely outside the defined scope of the Image Exploitation Services 
SIG, so these services are not further detailed here. 

2.2. Image Exploitation Services Categorization and Taxonomy 
The following outline summarizes the current categorization and taxonomy of needed image 
exploitation services. 

The Open GIS Abstract Specification  Page 20 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

1. Ground Coordinate Transformation Services: 

1.1. Ground coordinate conversion (exact) services: 

1.1.1. Geodetic coordinate conversion services 

1.1.2. Map projection conversion services 

1.2. Ground coordinate transformation (approximate) services: 

1.2.1. Datum transformation services 

1.2.2. Affine 2-D transformation service 

1.2.3. General 2-D Polynomial transformation service 

1.2.4. Polynomial 3-D transformation service 

1.2.5. Vertical ground position transformation services 

1.2.6. Other 3-D coordinate transformation services 

1.2.7. Other 2-D horizontal ground position transformation services 

1.3. Concatenated ground coordinate transformation services (including two or more of the 
above transformations and/or conversions ): 

1.3.1. 3-D to 3-D concatenated transformation 

1.3.2. 2-D to 2-D concatenated transformation 

1.3.3. 1-D to 1-D concatenated transformation 

2. Image Coordinate Transformation Services: 

2.1. Image-ground position transformation services: 

2.1.1. Ground to image position transformation service (3-D to 2-D) 

2.1.2. Stereoscopic images to ground position transformation service (multiple 2-D to 
one 3-D) 

2.1.3. Monoscopic image plus elevation to ground position transformation service (2-
D plus elevation to 3-D) 

2.1.4. Monoscopic image plus other data to ground position transformation service 
(2-D plus other data to 3-D) 

2.2. Image position transformation services: (2-D to 2-D) 

2.2.1. Polynomial transformation service 

2.2.2. Image to rectified image position transformation service 

2.2.3. Rectified image to image position transformation service 

2.3. Concatenated image coordinate transformation services (including two or more of the 
above image transformations plus ground coordinate transformations and conversions): 

2.3.1. 3-D to 2-D concatenated transformation 

2.3.2. 2-D to 3-D concatenated transformation 

2.3.3. 2-D to 2-D concatenated transformation 

2.4. Imaging time determination service 

3. Image Modification Services: 

The Open GIS Abstract Specification  Page 21 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.1. Change pixel values services:  
(Note: Includes previously defined simple pixel manipulation services) 

3.1.1. Tone modification services 

3.1.2. Spatial filtering (or convolution) services 

3.1.3. Pixel (multi-band or multi-image) classification services 

3.1.4. Image segmentation services 

3.1.5. Band and image combination services 

3.1.6. Other image enhancement services 

3.1.7. Simulate non-idealities services 

3.1.8. Histogram generation service 

3.1.9. Fourier analysis service 

3.1.10. Other frequency domain services 

3.1.11. Graphical overlay application service 

3.1.12. Grid overlay generation service 

3.2. Change pixel positions services: 

3.2.1. Pixel resampling service (services used by following subtypes) 

3.2.2. Polynomial transformation warping service 

3.2.3. Computer graphics warping services (including splines, piece-wise 
transformations) 

3.2.4. Image rectification service 

3.2.5. Orthorectification service 

3.2.6. Image mosaicking service 

3.2.7. Perspective scene generation service 

3.3. Change image data format services: 
(Note: Includes or uses image coverage access services) 

3.3.1. Image section retrieval services 

3.3.2. Image section replacement services 

3.3.3. Tiling change services 

3.3.4. Reduced resolution generation service 

3.3.5. Increased resolution estimation (or creation) services 

3.3.6. Image compression and decompression services 

3.4. Composite image modification services, including two or more of above image 
modifications 

4. Dimension Measurement Services: 

4.1. Line segment dimensions service: 

4.1.1. Compute horizontal length and azimuth angle of a line segment, from one point 
to a second point 

The Open GIS Abstract Specification  Page 22 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

4.1.2. Compute 3-D length and direction angles of a line segment, from one point to a 
second point 

4.2. Multi-segment line length service: 

4.2.1. Compute length of multi-segment line feature or real world object, from 
sequence of vertices representing spatial position of that line 

4.3. Area dimensions services: 

4.3.1. Compute area and perimeter of area feature or real world object, from sequence 
of vertices representing boundary of that area 

4.3.2. Compute size, orientation, and center position of a standard geometrical shape, 
from a sequence of points on the perimeter of that shape 

4.4. Height dimension service: 

4.4.1. Compute height of a vertical real-world object (such as a pole or building), 
from one point on the image of the top and a second point on the image of the base 

4.4.2. Compute height of a vertical real-world object (such as a pole or tower), from 
one point on the image of the top and a second point on the image of the shadow of 
the first point 

4.5. Volume dimension service: 

4.5.1. Compute volume of a solid features using its shell, from a sequence of vertexes 
for each facet of the shell. 

4.5.2. Compute cut and fill volumes between two different elevation surfaces, 
specified by a digital terrain matrix, regular triangulated network, or triangulated 
irregular network. 

4.6. Temporal dimension service: 

4.6.1. Support time-stamping of features, or of each vertex of a feature, as a single 
value or as a time range. (The image exposure time of the feature, or its vertexes, 
could be associated with each feature or its vertexes. A feature time-stamp can be 
stored in feature attribute (or property) fields, using separate attributes for the 
beginning and ending times. A vertex time-stamp can be stored as a fourth 
dimension.) 

5. Geodata Registration Services: 

5.1. Adjust one SRS (Spatial Reference System) to another SRS. 

5.2. Adjust multiple SRSs to each other (but not adjust to a fixed SRS) 

5.3. Adjust multiple SRSs to a fixed SRS and to each other 

6. Automated Image Matching Services: 

6.1. Basic image matching services (services used by following subtypes) 

6.2. Tie point extraction service 

6.3. Control point transfer service 

6.4. Elevation extraction service 

6.5. Image pattern following services 

6.6. Fiducial mark measurement service 

6.7. Sample image matching services: 

6.7.1. Object detection and location services 

The Open GIS Abstract Specification  Page 23 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

6.7.2. Object identification services 

6.7.3. Object dimension determination services 

6.7.4. Object classification services 

7. Automated Image Understanding Services: 

7.1. Pattern recognition services: 

7.1.1. Object detection and location services 

7.1.2. Object identification services 

7.1.3. Object dimension determination services 

7.1.4. Object classification services 

7.2. Image comparison services 

7.2.1. Pixel values difference determination services 

7.2.2. Change detection services 

7.2.3. Trend analysis services 

7.2.4. Model-based differencing services 

7.2.5. Negation (determination of origin) of changes services 

8. Accuracy Conversion Services 

8.1. Convert covariances to other forms: 

8.1.1. Convert 3-D covariances to CE plus LE 

8.1.2. Convert 2-D covariances to CE 

8.1.3. Convert 1-D variance to LE 

8.1.4. Convert 1-D variance to Standard Deviation 

8.1.5. Convert 3-D covariances to Spherical Error 

8.2. Convert other forms to covariances: 

8.2.1. Convert CE plus LE to 3-D covariances 

8.2.2. Convert CE to 2-D covariances 

8.2.3. Convert LE to 1-D variance 

8.2.4. Convert Standard Deviation to 1-D variance 

8.2.5. Convert Spherical Error to 3-D covariances 

9. Composite image exploitation services: 
(Note: These higher level services use multiple lower level services) 

9.1. Display window generation services: 
(Note: Including image pan, zoom, rotate, and change histogram) 

9.1.1. Monoscopic display window generation service 

9.1.2. Stereoscopic display generation service 

9.2. Object counting services 

9.3. Feature extraction (automated) services 

The Open GIS Abstract Specification  Page 24 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

9.4. Synthetic image generation service 

9.5. Intelligence data extraction services 

9.6. Image registration services 

10. Support metadata access services: 

10.1. Image geometry model metadata access service 

10.2. Spatial reference system (SRS) metadata access service 

10.3. Coordinate transformation metadata access service 

10.4. Image format metadata access service 

10.5. Values (of pixels) metadata access service 

10.6. Service capabilities metadata access service 

10.7. Service properties (or strategies) metadata access service 

10.8. Image geometry model transformation services 

10.8.1. Fit approximate image geometry model to existing image geometry model 

10.8.2. Convert image geometry model to different, mathematically equivalent model 

Editor’s Note:  In the service categorization above, the top level items (numbered 1 through 10) are 
the current categorization of image exploitation services to be used for further detailing. That is, 
OGC abstract specifications will be prepared for each listed service category. The first three listed 
categories are the highest priority for further detailing, in the listed order. 

The Coordinate Transformation WG is already developing abstract specifications for the first listed 
category “Ground Coordinate Transformation Services”. The Image Exploitation Services SIG 
plans to develop abstract specifications for the second listed category “Image Coordinate 
Transformation Services”. The “Image Modification Services” category partially overlaps the 
scope of the Simple Coverages RFP, and further development of abstract specifications for that 
category may be delayed until definitive responses to that RFP are received. 

2.2.1. Notes on the image exploitation service taxonomy 
Some notes on the above taxonomy and categorization: 

1. This taxonomy favors similarity of the fundamental interfaces needed by different services 
(instead of similarities of services functions or use). Similarity of interfaces is more appropriate for 
development of multiple standard APIs to image exploitation services. 

2. This taxonomy includes Automated Image Understanding Services (item 7) and Synthetic Image 
Generation Service (item 9.4), although these services are considered largely beyond the scope of 
this SIG. Many other services listed above under Composite Image Exploitation Services (item 9) 
are also largely beyond the scope of this SIG. These services are listed in this taxonomy in order to 
show how these higher level services are related to the image exploitation services within the scope 
of this SIG. 

3. This taxonomy includes image coverage access services, although Coverages are a major 
concern of the Coverage Working Group. These coverage services are listed toward showing how 
this lower level service is related to and used by the image exploitation services within the scope of 
IES-SIG. 

4. This taxonomy intends to include certain low level services that are used by higher level image 
exploitation services, although these lower level services may be partially the same for features 
and/or collections of features with geometry. For example, Ground Coordinate Transformation 
Services (item 1) are included. 

The Open GIS Abstract Specification  Page 25 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

5. This taxonomy intends to exclude high level services that are largely the same for features and/or 
collections of features with geometry. For example, geodata discovery and access services (Catalog 
services) are not included. 

6. Most listed image exploitation services are also applicable to other grid coverage types, and 
some listed services are also applicable to non-grid coverage types. However, other grid and non-
grid coverage types will need additional services, not included here. 

7. Some of the listed services will have distinct sub-items (not all listed) using, for example, a) only 
one image or coverage and b) multiple images or coverages. 

2.3. Uses of Other Services 
Many of the image exploitation services listed above will use other listed services. For example, the 
Change Pixel Positions Services may use the Image-Ground Position Transformation Services. The 
service usage relationships are expected to produce a network of connected services, with some 
services being higher level and some being lower level in the service use network. 

Figure 2-2 shows some of the expected usage relationships between the listed services, in the form 
of a UML class diagram. This diagram also shows possible usage of these services by mission-
specific client applications, plus usage of the OpenGIS® Catalog and Coverage Services by these 
image exploitation services. To simplify this diagram, it does not show the multiplicities of the 
relationships shown; most relationship multiplicities could be many to many. This diagram also 
shows one box titled “Coordinate Transformation Services” that combines the “Ground Coordinate 
Transformation Services” plus the “Image Coordinate Transformation Services”. 

The Open GIS Abstract Specification  Page 26 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

«uses»

Mission
Specific

Applications

Composite
Exploitation

Services

Auto. Image
Understanding

Services

Geodata
Registration

Services

Dimension
Measurement

Services

Coordinate
Transformation

Services

Auto. Image
Matching
Services

OpenGIS®
Catalog
Services

OpenGIS®
Coverage
Services

Support
Metadata Acc.

Services

Image
Modification

Services

Accuracy
Conversions

Service

«uses»

«uses»
«uses»

«uses»«uses»
«uses»

«uses»

«uses»

«uses»

«uses»

«uses»

«uses»

«uses»

«uses»

«uses»«uses»

«uses»

«uses»

«uses»

 
Figure 2-2. Possible Usage Relationships Among Image Exploitation Services 

2.4. References for Section 2 
[1] OpenGIS Abstract Specification, OpenGIS Project Documents 98-100 through 98-114, available 

through www as http://www.opengis.org/techno/specs.htm 
[2] Cook, Steve, and John Daniels, Designing Objects Systems: Object-Oriented Modeling with Syntropy, 

Prentice Hall, New York, 1994, xx + 389 pp. 

The Open GIS Abstract Specification  Page 27 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3. Abstract Specification for Image Exploitation Services 
The following subsections provide more detailed descriptions of most of the image exploitation 
service categories listed in the preceding taxonomy. These descriptions do not describe the contents 
and formats of the “needed data” and “result data” of each service. The “needed data” could 
alternately be called inputs, and the “result data” could alternately be called outputs. The “needed 
data” and “result data” of multiple services are often identical or similar, so the possible contents 
and formats of this data are discussed later in Section 4. 

The image exploitation services will often use and produce metadata about the geospatial data that 
is manipulated. Metadata is the subject of the Metadata SIG and of Topic 11 of the Abstract 
Specification. To start to define service interactions with metadata, the “needed data” and “result 
data” items listed are often annotated with “(is metadata for ...)”. 

3.1. Ground Coordinate Transformation Services 
3.1.1. Function 

The Ground Coordinate Transformation services convert ground position coordinates between 
different Spatial Reference Systems (SRSs). Some service types may have operations that convert 
the positions of multiple points (not just one point at a time). 

3.1.2. Service subtypes 
Service subtypes include but are not necessarily limited to the following: 

3.1.2.1. Ground coordinate conversion (exact) services 

3.1.2.1.1. Geodetic coordinate conversion services 

3.1.2.1.2. Map projection conversion services 

3.1.2.2. Ground coordinate transformation (approximate) services 

3.1.2.2.1. Datum transformation services 

3.1.2.2.2. Affine 2-D transformation service 

3.1.2.2.3. General 2-D Polynomial transformation service 

3.1.2.2.4. Polynomial 3-D transformation service 

3.1.2.2.5. Vertical ground position transformation services 

3.1.2.2.6. Other 3-D coordinate transformation services 

3.1.2.2.7. Other 2-D horizontal ground position transformation services 

3.1.2.3. Concatenated ground coordinate transformation services  
These services may include two or more of the ground transformation and/or conversion services. 

Note: Although different interfaces could be used for different numbers of input and output 
coordinates for the services listed below, we consider such separation undesirable. 

3.1.2.3.1. 3-D to 3-D concatenated transformation 

3.1.2.3.2. 2-D to 2-D concatenated transformation 

3.1.2.3.3. 1-D to 1-D concatenated transformation 

3.1.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Output ground position coordinates, in desired SRS 

2. Partial derivatives of output position coordinates with respect to input position coordinates 
(optional, see note below) 

3. Metadata for output position coordinates, including: (optional, see note below) 

The Open GIS Abstract Specification  Page 28 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

4. Output SRS definition (is metadata for output positions) 

5. Absolute accuracy estimates for output position coordinates (is metadata for output positions) 

6. Relative accuracy estimates for output position coordinates (is metadata for output positions) 

Note: Result metadata is optionally returned to client software, depending on how the service is 
called. Similarly, partial derivatives are optionally returned to client software. The ability to 
produce result metadata and partial derivatives when requested are required capabilities of this 
service category. 

3.1.4. Needed data 
The data needed by these services (input data) includes, but are not limited to, the following: 

1. Input ground position coordinates, in another SRS 

2. Output SRS definition (is metadata for output positions) 

3. Coordinate transformation parameters (optional) (is metadata for SRS or transformation) 

4. Transformation accuracy estimates, for each SRS transformation (when output accuracy is 
needed) (is metadata for transformation) 

5. Metadata for input position coordinates, including: 

5.1. Input SRS definition (is metadata for input positions) 

5.2. Absolute accuracy estimates for input position coordinates (when output absolute 
accuracy is needed) (is metadata for input positions) 

5.3. Relative accuracy estimates for input position coordinates (when output relative accuracy 
is needed) (is metadata for input positions) 

3.1.5. Discussion 
Ground Coordinate Transformation Services are considered a service category separate from the 
Image Coordinate Transformation Services (see Section 3.2) in order to limit the size of service 
categories. However, these two service categories require very similar interfaces, and they must be 
able to inter-operate easily. Specifically, the Concatenated Image Coordinate Transformation 
Services  must be able to include individual or concatenated Ground Coordinate Transformation 
Services. 

When a Ground Coordinate Transformation Service is needed, the corresponding service for the 
opposite direction will often also be needed. Instead of requiring a client to handle separate Ground 
Coordinate Transformation Services for each direction, it appears desirable to automatically link 
the corresponding Services for the two directions. This linking might be done in several ways, 
including: 

• Have each Ground Coordinate Transformation Service provide transformations in both 
directions. Different service operations or an additional input to certain operations would be 
used to select which transformation direction is requested. 

• Provide a Ground Coordinate Transformation Service with an additional operation to obtain 
the reverse direction Service (or to obtain all the metadata needed by such a service) 

Editors note: These Ground Coordinate Transformation Services roughly correspond to the 
Geospatial Coordinate Transformation Services now in Topic Volume 12 (Services Architecture), 
and to the transformations being specified in Topic Volume 2 (Coordinate Systems and 
Transformations). 

The Open GIS Abstract Specification  Page 29 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.2. Image Coordinate Transformation Services 
3.2.1. Function 

The Image Coordinate Transformation services, alternatively called Image Geometry Model 
services, describes a group of services that convert image position coordinates between different 
Spatial References Systems (SRSs). Some service types may have operations that convert the 
positions of multiple points (not just one point at a time). 

3.2.2. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Output point position coordinates, in desired SRS 

2. Partial derivatives of output position coordinates with respect to input position coordinates 
(optional, see note below) 

3. Metadata for output position coordinates, including: (optional, see note below): 

3.1. Output SRS definition (is metadata for output positions) 

3.2. Absolute accuracy estimates for output position coordinates (is metadata for output 
positions) 

3.3. Relative accuracy estimates for output position coordinates (is metadata for output 
positions) 

Note: Result metadata is optionally returned to client software, depending on how the service is 
called. Similarly, partial derivatives are optionally returned to client software. The ability to 
produce result metadata and partial derivatives when requested are required capabilities of this 
service category. 

3.2.3. Needed data 
The data needed by these services (input data) includes, but are not limited to, the following: 

1. Input point position coordinates, in another SRS 

2. Output SRS definition (is metadata for output positions) 

3. Coordinate transformation parameters (optional) (is metadata for SRS or transformation) 

4. Transformation accuracy estimates, for each SRS transformation (when output accuracy is 
needed) (is metadata for transformation) 

5. Elevation data (for monoscopic image to ground) (could be considered metadata for an image?) 

6. Elevation accuracy estimates (when output accuracy is needed) (is metadata for elevation data) 

7. Metadata for input position coordinates, including: 

7.1. Input SRS definition (is metadata for input positions) 

7.2. Absolute accuracy estimates for input position coordinates (when output absolute 
accuracy is needed) (is metadata for input positions) 

7.3. Relative accuracy estimates for input position coordinates (when output relative accuracy 
is needed) (is metadata for input positions) 

3.2.4. Service subtypes 
3.2.4.1. Image-ground position transformation services 

3.2.4.1.1. Ground to image position transformation service (3-D to 2-D) 

3.2.4.1.2. Stereoscopic images to ground position transformation service (multiple 2-D to one 3-D) 

The Open GIS Abstract Specification  Page 30 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.2.4.1.3. Monoscopic image plus elevation to ground position transformation service (2-D plus 
elevation to 3-D) 

3.2.4.1.4. Monoscopic image plus other data to ground position transformation service (2-D plus 
other data to 3-D). (This other data might include laser profiling or radar range data.) 

3.2.4.2. Image position transformation services (2-D to 2-D) 

3.2.4.2.1. Polynomial transformation service 

3.2.4.2.2. Image to rectified image position conversion service 

3.2.4.2.3. Rectified image to image position conversion service 

3.2.4.3. Concatenated image coordinate transformation services 
These services include two or more of the above image transformations plus ground coordinate 
transformations and conversions. 

Note: Although different interfaces could be used for different numbers of input and output 
coordinates, as listed in services below, we consider such separation undesirable. 

3.2.4.3.1. 3-D to 2-D concatenated transformation (ground to image) 

3.2.4.3.2. 2-D to 3-D concatenated transformation (image to ground) 

3.2.4.3.3. 2-D to 2-D concatenated transformation (image to image) 

3.2.5. Discussion 
Image Coordinate Transformation Services are considered a service category separate from the 
Ground Coordinate Transformation Services (as discussed in the preceding subsection) in order to 
limit the size of service categories. However, these two service categories require very similar 
interfaces, and they must be able to inter-operate easily. Specifically, the concatenated image 
coordinate transformation services (see service subtype 3 above) must be able to include individual 
or concatenated Ground Coordinate Transformation Services. 

When an Image Coordinate Transformation Service is needed, the corresponding Service for the 
opposite direction will often also be needed. Instead of requiring a client to handle separate Image 
Coordinate Transformation Services for each direction, it appears desirable to automatically link 
the corresponding Services for the two directions. This linking might be done in several ways, 
including: 

• Have each Image Coordinate Transformation Services provide transformations in both 
directions. Different service operations or an additional input to certain operations would be 
used to select which transformation direction is requested. 

• Provide an Image Coordinate Transformation Service with an additional operation to obtain 
the reverse direction Service (or to obtain all the metadata needed by such a service) 

Editors note: These Image Coordinate Transformation Services roughly correspond to parts of the 
Image Geometry Model Services and the Geospatial Coordinate Transformation Services now in 
Topic Volume 12 (Services Architecture). 

3.3. Imaging Time Determination Service 

Technical Note: For certain purposes these services could be considered subsidiary to (i.e., a 
specialization of) the Image Coordinate Transformation Services (Section 3.2). They are described 
separately here because they need somewhat different interfaces, and the service interfaces may be 
separately specified by the OGC. 

3.3.1. Function 
These services are used to determine the imaging time of points in an image. For a “frame” type of 
image, all points are imaged at the same time. For pushbroom, whiskbroom, panoramic, SAR, and 
other types of images, different points in one image are imaged at somewhat different times. The 
imaging time differences within one image can be important for some image exploitation purposes, 
such as estimating the velocity of imaged objects. 

The Open GIS Abstract Specification  Page 31 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.3.2. Service subtypes 
Services in this category include, but are not limited to, the following: 

3.3.2.1. Determine imaging time for one or more image positions 

3.3.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to, the following: 

1. Imaging times 

2. Metadata for imaging times, including: (optional, see note below) 

2.1. Temporal SRS definition (is metadata for output times) 

2.2. Absolute accuracy estimates for imaging times (is metadata for output times) 

2.3. Relative accuracy estimates for imaging times (is metadata for output times) 

Note: Result metadata is optionally returned to client software, depending on how the service is 
called. The ability to produce result metadata when requested is a required capability of the service. 

3.3.4. Needed data 
The data needed by these services (input data) includes, but are not limited to, the following: 

1. Image position coordinates 

2. Output temporal SRS definition (is metadata for output times) 

3. Temporal SRS transformation parameters (optional)  (is metadata for temporal SRS or 
transformation) 

4. Temporal transformation accuracy estimates (when output accuracy is needed) (is metadata for 
temporal transformation) 

5. Metadata for input position coordinates, including 

5.1. Input SRS definition (is metadata for input positions) 

5.2. Absolute accuracy estimates for input position coordinates (when output absolute 
accuracy is needed) (is metadata for input positions) 

5.3. Relative accuracy estimates for input position coordinates (when output relative accuracy 
is needed) (is metadata for input positions) 

3.3.5. Discussion 
Specification and implementation of this imaging time determination service probably depends on 
specification of temporal reference systems. Imaging time determination also depends on the 
temporal part of image geometry models. Complete specification of temporal reference systems has 
been put off for future work by the OGC. Therefore, complete specification and implementation of 
this imaging time determination service may have to be delayed. 

Editor’s Note: This Imaging Time Determination Services may be notionally categorized as a 
subtype of Image Coordinate Transformation Services because time can be considered as another 
dimension of a point coordinate. Furthermore, the data needed to determine imaging time is closely 
related to the data needed to transform image positions. 

3.4. Image Modification Services 
3.4.1. Function 

The Image Modification Services produce modified version of images, providing access to all or 
selected sections of the modified image. Most of these services modify one image. However, some 
services must or can combine two or more images. Some of these service types also allow a client 

The Open GIS Abstract Specification  Page 32 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

to change a selected section of the modified image, with the corresponding changes being made to 
the original image(s). 

3.4.2. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.4.2.1. Change pixel values services 

Editor’s Note: Includes previously defined simple pixel manipulation services. 

3.4.2.1.1. Tone modification services 
1. Tonal Transfer Curve (TTC) service 

2. Dynamic Range Adjustment (DRA) service 

3. Histogram Equalization service 

3.4.2.1.2. Spatial filtering (or convolution) services 
1. Linear filtering service 

2. Edge extraction services 

3. Other non-linear filtering services 

4. Artifact correction services 

3.4.2.1.3. Pixel (multi-band or multi-image) classification services 

3.4.2.1.4. Image segmentation services 

3.4.2.1.5. Band and image combination services 

3.4.2.1.6. Other image enhancement services 

3.4.2.1.7. Simulate non-idealities services 
1. Simulate imaging conditions non-idealities services (e.g., haze) 

2. Simulate image sensor non-idealities services (e.g., detector calibration errors) 

3. Simulate illumination direction change services 

3.4.2.1.8. Histogram generation service 

3.4.2.1.9. Fourier analysis service 

3.4.2.1.10. Other frequency domain services 

3.4.2.1.11. Graphical overlay application service 

3.4.2.1.12. Grid overlay generation service 

3.4.2.2. Change pixel positions services 

3.4.2.2.1. Pixel resampling service (service used by following subtypes) 

3.4.2.2.2. Polynomial transformation warping service 

3.4.2.2.3. Computer graphics warping services (including splines, piece-wise transformations) 

3.4.2.2.4. Image rectification service 

3.4.2.2.5. Orthorectification service (including orthophoto stereomate generation) 

3.4.2.2.6. Image mosaicking service 

3.4.2.2.7. Perspective scene generation service 

3.4.2.3. Change image data format services 

Technical Note: Includes or uses Image Coverage Access Services. 

The Open GIS Abstract Specification  Page 33 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.4.2.3.1. Image section retrieval services 
1. Single pixel retrieval service 

2. Patch (or rectangular window) retrieval service 

3. Polygon area (area-of-interest, AOI) retrieval service 

3.4.2.3.2. Image section replacement services 
1. Single pixel replacement service 

2. Patch (or rectangular window) replacement service 

3. Polygon area (area-of-interest, AOI) replacement service 

3.4.2.3.3. Tiling change services 

3.4.2.3.4. Reduced resolution generation service 

3.4.2.3.5. Increased resolution estimation (or creation) services 

3.4.2.3.6. Image compression and decompression services: 
1. Lossy compression services 

2. Lossless compression services 

3.4.2.3.7. Composite image modification services 
Includes two or more of the above image modifications. (Note: A composite modification is a 
single service that combines or concatenates what would otherwise be multiple separate services.) 

Editor’s Note: This service category may be too large, and it may have to be split into two or more 
categories. For example, the “Change Pixel Values Services” could be separated from the “Change 
Pixel Positions Services”.  These services are listed as one category here because of the 
commonality of required interfaces. 

3.4.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Modified image pixels, for entire image or selected section of image 

2. Metadata for modified image pixels, including: (optional, see note) 

3. Modified image SRS definition (is metadata for output image) 

4. Actual image modifications identification and parameters (is lineage metadata for output image) 

Note: Result metadata is optionally returned to client software, depending on how the service is 
called. The ability to produce result metadata when requested is a required capability of the service. 

3.4.4. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

1. Existing image pixels, for each image used 

2. Modified image SRS definition (if changing pixel positions)  (is metadata for output image) 

3. Selection of desired image modifications (is metadata for modified image) 

4. Values of parameters required and useful to control modification processes (sometimes called 
strategy parameters) (is metadata for adjustment process) 

5. Selection of desired image section (is metadata for image section) 

6. Metadata for existing image pixels, including: 

7. Input image SRS definition (is metadata for input image) 

The Open GIS Abstract Specification  Page 34 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

8. Input image pixel formats (is metadata for input image) 

3.4.5. Discussion 
The image SRS definition input and output are required only when pixel positions are modified. 
However for interface generality, this input and output might be included in all cases, with the 
output being the same as the input when pixel positions are not modified. 

When an Image Modification Service (indirectly or directly) includes one or more Change Image 
Pixel Position Services, it will often be necessary to perform the corresponding Image Coordinate 
Transformation, as discussed in Section 2.2 above. That is, it may be necessary to take point 
positions in the modified image and determine the corresponding point positions in the original 
image. Alternately, it may be necessary to take point positions in the original image and determine 
the corresponding point positions in the modified image. Furthermore, it may be necessary to take 
point positions in the modified or original image and determine the corresponding point positions in 
any desired ground coordinate SRS. 

Instead of requiring the software  to handle one or more separate Image Coordinate Transformation 
Services for an Image Modification Service, it appears desirable to (perhaps optionally) 
automatically link a single Image Modification Service to the corresponding Image Coordinate 
Transformation Services. This linking might be done in several ways, including: 

• Provide a service that has the (standard) interfaces for both Image Modification and 
Concatenated Image Coordinate Transformation services 

• Provide an Image Modification Service with an additional operation to obtain the 
corresponding Image Coordinate Transformation Service (or to obtain all the metadata needed 
by such a service) 

When an Image Modification Service (indirectly or directly) uses more that one source image, there 
can be a different Coordinate Transformation for each source image. When this occurs, it appears 
necessary to include an input to some operations that specifies which source image is being used. 

3.5. Dimension Measurement Services 
3.5.1. Function 

The Dimension Measurement Services compute dimensions of objects visible in an image or other 
geodata. An alternative name for this service category is “Image Mensuration Services.” 

It is assumed that dimensions are required in a selected SRS, often a project world SRS. It is 
further assumed that dimensions are computed from positions measured in an (unrectified) image 
or other SRS. In most cases, dimension computation requires access to the (approximate) elevation 
of at least one point. (Possible forms of elevation data are discussed in Section 3.6.) 

3.5.2. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.5.2.1. Line segment dimensions services: 

3.5.2.1.1. Compute horizontal length and angle clockwise from North of a line segment, from one 
point to a second point 

3.5.2.1.2. Compute 3-D length and direction angles of a line segment, from one point to a second 
point 

3.5.2.2. Multi-segment line length service: 

3.5.2.2.1. Compute length of multi-segment line feature or real world object, from sequence of 
vertices representing spatial position of that line 

3.5.2.3. Area dimensions services: 

3.5.2.3.1. Compute area and perimeter of area feature or real world object, from sequence of 
vertices representing the polygon boundary of that area 

3.5.2.3.2. Compute size, orientation, and center position of a standard geometrical shape, from a 
sequence of points on the perimeter of that shape. (The standard geometrical shapes are 

The Open GIS Abstract Specification  Page 35 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

usually horizontal or vertical in the project world SRS. A variety of different shapes 
could be supported, including rectangle, square, ellipse, circle, parallelogram, and 
more complex shapes.) 

3.5.2.1. Height dimension service: 

3.5.2.1.1. Compute height of a vertical real-world object (such as a pole or building), from one 
point on the image of the top and a second point on the image of the base. (The real-
world object is assumed to be vertical in the project world SRS.) 

3.5.2.1.2. Compute height of a vertical real-world object (such as a pole or tower), from one point 
on the image of the top and a second point on the image of the shadow of the first point. 
(The real-world object is assumed to be vertical in the project world SRS. This 
computation requires access to the illumination direction, and assumes that the top of 
the shadow falls on a surface at the same elevation as the base of the real-world object.) 

3.5.2.2. Volume dimension service: 

3.5.2.2.1. Compute volume of a solid features using its shell, from a sequence of vertexes for each 
facet of the shell. (This capability requires the ability to record features with volume 
geometries. Handling of volume features has been put off for future work by the OGC. 
Therefore, complete specification and implementation of this Volume dimension service 
may have to be delayed.) 

3.5.2.2.2. Compute cut and fill volumes between two different elevation surfaces, specified by a 
digital terrain matrix, regular triangulated network, or triangulated irregular network. 

3.5.2.3. Temporal dimension service: 

3.5.2.3.1. Compute time difference between two points with known time coordinates. 

3.5.2.3.2. Compute velocity of same object imaged at two different points and times, in the same or 
different images. The object could be assumed to travel in a straight line between these 
two points, or to travel along a defined path. 

Technical Note: Specification and implementation of the Temporal dimension service depends on 
the ability to represent time in point coordinates. Specification and implementation of time 
representation probably depends on specification of temporal reference systems. Complete 
specification of time representation and of temporal reference systems has been put off for future 
work by the OGC. Therefore, complete specification and implementation of this Temporal 
dimension service may have to be delayed. 

3.5.3. Results 
The data resulting from these services (output data) includes, but are not limited to: 

1. Values of one or more computed dimensions, in desired SRS 

2. Dimension accuracy estimates, in output dimension SRS (optional) (is metadata for dimensions) 

3. The possible output dimension data types and units include: 

3.1. Distance (in ground coordinate units) 

3.2. Area (in ground coordinate units squared) 

3.3. Angle (in degrees, probably measured clockwise from North) 

3.4. Position Coordinates (in ground coordinate units) 

3.5. Volume (in ground coordinate units cubed, or in the product of the ground coordinate 
units in the three axes) 

3.6. Time Difference (in time units) 

3.7. Velocity (in distance units divided by time units) 

3.5.4. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

The Open GIS Abstract Specification  Page 36 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

1. Point position coordinates, in any SRS 

2. Selection of desired dimensions 

3. Illumination direction, azimuth and elevation angles (when computing height from shadow or 
layover) (is metadata for image) 

4. Position accuracy estimates for input position coordinates, relative or absolute (when dimension 
accuracy is needed) (is metadata for input positions) 

5. Output SRS definition (is metadata for output dimensions) 

6. Input SRS definition (is metadata for input positions) 

7. Coordinate transformation parameters (optional)  (is metadata for SRS or transformation) 

8. Elevation data (for monoscopic image to ground) (could be considered metadata for an image?) 

9. Elevation accuracy estimates (when elevation is input and output accuracy is needed) (is 
metadata for elevation data) 

Technical Note: This service must use an Image Coordinate Transformation Service when the input 
position coordinates SRS is not the desired ground position SRS, and coordinate transformation is 
thus required. 

3.6. Geodata Registration Services 
3.6.1. Function 

The Geodata Registration Services change the estimated SRS of one or more images, or other 
geospatial datasets, to better match other geospatial datasets. 

Change SRS by adjusting the parameters of an existing SRS or of a transformation between two 
SRSs. (Some SRSs are defined by the transformation from another specified SRS.) When a 
transformation is adjusted, usually only one transformation in a chain of existing transformations is 
adjusted. The adjusted transformation may initially be a null transformation inserted in the chain 
for the purpose of being adjusted. 

3.6.2. Service Subtypes 
3.6.2.1. Adjust one SRS (Spatial Reference System) to another SRS. 

 The adjusted SRS is usually for one image or other dataset, but could be the SRS for multiple 
datasets. 

3.6.2.2. Adjust multiple SRSs to each other (but not adjust to a fixed SRS) 

3.6.2.3. Adjust multiple SRSs to a fixed SRS and to each other 

3.6.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Adjusted parameters of transformation between SRSs, for each adjusted transformation (is 
metadata for image or other dataset) 

2. Transformation accuracy estimates, for each adjusted transformation (optional) (is metadata for 
transformation) 

3.6.4. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

1. Positions of same point in two or more SRSs, for multiple points 

2. Selection of transformations and parameters to be adjusted 

3. Parameters of existing transformations between SRSs, for each SRS in which a position is 
provided (is metadata of point position SRSs), including: 

The Open GIS Abstract Specification  Page 37 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.1. Adjustable transformations 

3.2. Non-adjustable transformations 

4. Position accuracy estimates for input position coordinates (is metadata for input positions): 

4.1. Absolute accuracy estimates, of each point (required) 

4.2. Relative accuracy estimates, between points (optional) 

5. Transformation accuracy estimates, for parameters of each adjustable transformation (optional) 
(is metadata for transformation) 

6. Transformation accuracy estimates, for each non-adjustable transformation, or for complete SRS 
definition of each SRS (optional) (is metadata for SRS) 

7. Values of parameters required and useful to control adjustment process (sometimes called 
strategy parameters) (is metadata for adjustment process?) 

Technical Note: This service must use an image coordinate transformation service, and/or a ground 
coordinate transformation service, to compute corresponding positions in different SRSs. That 
service must also be used to compute partial derivatives of output coordinates with respect to input 
coordinates. For adjustable parameters, extensions to those services are needed to compute partial 
derivatives of position coordinates with respect to the adjustable parameters. 

3.6.5. Discussion 
Adjustments are often done by minimizing the mean square of the weighted residual errors in 
fitting an input set of point position data. The weighted residual errors in fitting measured 
transformation parameters can also be included. The weights are usually inversely proportional to 
the error estimates for each point position or transformation parameter. For such least-square 
adjustment, there must be more known values than adjusted values, sometimes up to twice as many 
known values. 

The position of each point must be previously determined in two or more different SRSs. For 
flexibility, this service does not include measuring the positions of points in images or other 
datasets with different SRSs, for example, “Tie Point Extraction” and “Control Point Transfer” 
services (see Section 3.6.5). A higher level composite service could combine registration with 
measuring the positions of points in images or other datasets, see item 9.6 in Section 1. 

3.6.6. Related Services 
Automated Image Matching Services

3.7. Automated Image Matching Services 
3.7.1. Function 

The Automated Image Matching Services determine matching positions in two or more images, 
using (partially) automated image comparison methods. Some manual assistance could also be 
allowed. 

The multiple images may be of the same ground area, or of different ground areas with similar 
appearances. 

These services match small or larger areas in the different images (not matching single pixels, 
which is impractical). 

3.7.2. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.7.2.1. Basic image matching services (services used by following subtypes): 

3.7.2.1.1. Correlation matching service 

3.7.2.1.2. Least-squares matching service 

3.7.2.2. Tie point extraction service 

The Open GIS Abstract Specification  Page 38 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.7.2.3. Control point transfer service 

3.7.2.4. Elevation extraction service 

3.7.2.5. Image pattern following services 

3.7.2.6. Fiducial mark measurement service 

3.7.2.7. Sample image matching services 

3.7.2.7.1. Object detection and location services 

3.7.2.7.2. Object identification services 

3.7.2.7.3. Object dimension determination services 

3.7.2.7.4. Object classification services 

3.7.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Feature(s) with geometry.  Possible feature geometries include: 

1.1. Single point 

1.2. Set of points 

1.3. Grid of points 

1.4. Linear feature geometry 

1.5. Area feature geometry 

1.6. Volume feature geometry 

2. Metadata for output feature geometry, including: (optional, see note) 

2.1. Measures of quality of image match 

2.2. Absolute accuracy estimates for output feature geometry 

2.3. Relative accuracy estimates for output feature geometry 

3.7.4. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

1. Image pixels, for each image to be used, often a specified section of a larger image 

2. Output SRS definition (is metadata for output feature) 

3. Input image SRS definition (is metadata for input image) 

4. Selection of desired image matching service 

5. Values of parameters required and useful to control matching process (sometimes called strategy 
parameters) (is metadata for matching process?) 

6. Approximate feature with geometry (optional) 

7. Input feature SRS definition (optional) (is metadata for input feature) 

8. Position accuracy estimates for input feature geometry (optional) (is metadata for input feature) 

8.1. Absolute accuracy estimates (when absolute accuracy is needed) 

8.2. Relative accuracy estimates (when relative accuracy is needed) 

9. Elevation data (for monoscopic image to ground) (could be considered metadata for an image?) 

10. Elevation accuracy estimates (when elevation is input and output accuracy is needed) (is 
metadata for elevation data) 

The Open GIS Abstract Specification  Page 39 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

3.8. Accuracy Conversion Services 
3.8.1. Function 

The Accuracy Conversion Services convert position accuracy estimates between error covariance 
matrix form and Circular Error (CE) plus Linear Error (LE) or other forms. 

These accuracy conversions are also applicable to linear dimensions and perhaps other accuracy 
estimates. 

3.8.2. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.8.2.1. Convert covariance matrices to other forms 

3.8.2.1.1. Convert 3-D covariances to CE plus LE 

3.8.2.1.2. Convert 2-D covariances to CE 

3.8.2.1.3. Convert 1-D variance to LE 

3.8.2.1.4. Convert 1-D variance to Standard Deviation 

3.8.2.1.5. Convert 3-D covariances to Spherical Error 

3.8.2.2. Convert other forms to covariance matrices 

3.8.2.2.1. Convert CE plus LE to 3-D covariances 

3.8.2.2.2. Convert CE to 2-D covariances 

3.8.2.2.3. Convert LE to 1-D variance 

3.8.2.2.4. Convert Standard Deviation to 1-D variance 

3.8.2.2.5. Convert Spherical Error to 3-D covariances 

3.8.3. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. Accuracy estimates in desired form (is metadata for some point positions) 

2. Confidence level(s) for output CE and LE values (is metadata for CE and LE values?) 

3.8.4. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

1. Accuracy estimates in another form (is metadata for same point positions) 

2. Selection of accuracy estimate form desired 

3. Confidence level(s) for input CE and LE values (is metadata for CE and LE values?) 

4. Accuracy conversion parameters (is metadata for accuracy conversions?) 

3.8.5. Discussion 
Both absolute and relative accuracy estimates can be separately converted by these services. 

Some cells of a covariance matrix may be unknown, and unknown cells must be handled in an 
appropriate manner. 

When converting most other forms of accuracy data to covariance matrices, correct values will not 
be known for some covariance matrix cells. Specifically, the off-diagonal cells for covariances 
between coordinates will not be known. As specified in Abstract Specification Topic 9: Quality, the 
values of these covariance matrix cells should be null or missing. (Alternately, these covariances 
values would be assumed to be zero.) 

3.9. Metadata Access Services 
3.9.1. Function 

The Open GIS Abstract Specification  Page 40 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

The Metadata Access Services retrieve or modify desired metadata, converting its format when 
needed. 

3.9.2. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.9.2.1. Image geometry model metadata access service 

3.9.2.2. Spatial reference system (SRS) metadata access service 

3.9.2.3. Coordinate transformation metadata access service 

3.9.2.4. Image format metadata access service 

3.9.2.5. Values (of pixels) metadata access service 

3.9.2.6. Service capabilities metadata access service 

3.9.2.7. Service properties (or strategies) metadata access service 

3.9.2.8. Support Metadata Retrieval Services 

3.9.2.8.1. Result Data: 
1. Metadata (or service using metadata) (is metadata) 

3.9.2.8.2. Needed Data: 
1. Image or dataset identification (is metadata for dataset) 

2. Selection of desired metadata (or of service using metadata) 

3. Selection of desired metadata format 

3.9.2.9. Support Metadata Modification Services 

3.9.2.9.1. Result Data: 
1. Success or failure of metadata modifications 

3.9.2.9.2. Needed Data: 
1. Modified metadata (or service having modified metadata) 

2. Image or dataset identification (is metadata for dataset) 

3. Specification of input metadata format (is part of metadata?) 

4. Selection of metadata to be modified 

3.9.3. Discussion 

Technical Note: Services 3.9.2.8 and 3.9.2.9 are alternatives to the preceding services that combine 
Metadata Access Services with the services that use each type of metadata. 

Metadata retrieval and modification services have different interfaces, as outlined above, although 
they might be implemented as different operations of a single service. 

3.10. Image Geometry Model Transformation Services 
3.10.1. Function 

The Image Geometry Model Transformation Services produce a different geometry model for an 
image, or metadata for a different image geometry model. 

3.10.2. Consequences 
There are many different possible geometry models for an image, with different properties. For 
example, a rigorous geometry model can be accurately adjusted (see Section 2.5), but has high 
computation requirements. On the other hand, a “real-time” geometry model has lesser computation 
requirements, but cannot be accurately adjusted. Transformation from a rigorous geometry model 

The Open GIS Abstract Specification  Page 41 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

to a corresponding “real-time” geometry model is then sometimes required. (Transformation from a 
“real-time” geometry model to a rigorous geometry model is usually not possible or practical.) 

These Image Geometry Model Transformation Services are described here because they are similar 
to Metadata Access Services. These Image Geometry Model Transformation Services support the 
Image Coordinate Transformation Services. However, these Image Geometry Model 
Transformation Services have significantly different interfaces. 

3.10.3. Service Subtypes 
Services in this category include, but are not limited to, the following: 

3.10.3.1. Fit approximate image geometry model to point positions computed using existing image 
geometry model 

3.10.3.2. Convert image geometry model to different, mathematically equivalent model, by converting 
geometry parameters of existing image geometry model 

3.10.4. Results Data 
The data resulting from these services (output data) includes, but are not limited to: 

1. New image geometry model, for entire image or selected section of image (is modified metadata 
for image) 

2. Metadata for new image geometry model, including: 

2.1. Absolute accuracy estimates for new model (is metadata for new model) 

2.2. Relative accuracy estimates for new model (is metadata for new model) 

2.3. Modified image SRS definition (is metadata for new model) 

2.4. Identification of applicable image section (is metadata for new model) 

2.5. Model fitting error estimates (is metadata for new model) 

Technical Note: These services should always return result metadata to client software (result 
metadata is not optional). 

3.10.5. Needed data 
Inputs (needed data) to these services include, but are not limited to, the following: 

1. Existing image geometry model (is metadata for image) 

2. Desired accuracy of geometry model transformation 

3. Values of parameters required and useful to control transformation processes (sometimes called 
strategy parameters) (is metadata for transformation process) 

4. Selection of desired image section (is metadata for new model) 

5. Metadata for existing image geometry model, including 

5.1. Absolute accuracy estimates for model (is metadata for model) 

5.2. Relative accuracy estimates for model (is metadata for model) 

5.3. Existing image SRS definition (is metadata for model) 

The Open GIS Abstract Specification  Page 42 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

4. Well Known Types and Structures 
This section describes in broad “notional” terms the contents and use of the “needed data” and 
“result data” elements for the services described in the previous section. The “needed data” can 
alternately be called inputs, and the “result data” can alternately be called outputs. This section 
discusses various data categories, recognizing that the “needed data” and “result data” of multiple 
services are often identical or similar. Some of these data descriptions use the ISO (and CORBA) 
standard Interface Definition Language (IDL) to more concisely convey their scope and use. A 
brief summary of the IDL data types and structures is also included.  

More detailed specification of “well known types” and “well known structures” for image 
exploitation is left to the respective service descriptions planned in other topic volumes of the 
OpenGIS® Abstract Specification. 

4.1. Metadata 
The image exploitation services will often use and produce metadata about the geospatial data that 
is manipulated. Metadata is the subject of the Metadata SIG and of Topic 11 of the Abstract 
Specification. To start to define service interactions with metadata, inputs and outputs listed in 
Section 3 are often annotated with “(is metadata for ...)”. 

Several aspects of metadata have already been standardized, as discussed below, and thus do not 
need to be standardized as part of defining standard interfaces to various image exploitation 
services. Indeed, these aspects of metadata organization should be the same for all OpenGIS® 
services. 

The draft ISO Metadata Standard, 15046-15, specifies the logical organization to be used for 
metadata, including both standard and custom metadata. Related metadata “elements” are grouped 
into metadata “entities” (including metadata “sections”). Each metadata entity (or section) contains 
a defined set of metadata elements and/or a set of lower level metadata entities. Each metadata 
element, entity, and section has a name and a definition. 

The current version of Abstract Specification Topic 11: Metadata requires use of the ISO metadata 
concepts and terminology. In addition, Topic 11 provides object-oriented notation for ISO-
structured metadata. All metadata entities (and sections) comprise one abstract class, and each type 
of metadata entity (and section) is a concrete subclass. Each metadata entity (or section) subclass 
contains a set of metadata elements and/or lower level entities. The included metadata element 
names and corresponding values are captured as attributes of the object subclass. 

In Topic 11, a metadata set is a concrete class where each metadata set object contains a collection 
of metadata entity objects, serving as metadata sections. Each OpenGIS® feature collection and/or 
individual feature is directly related to one metadata set object. 

The draft ISO Metadata Standard, 15046-15, also specifies the names, definitions, data types, units, 
etc. for many metadata elements in many metadata entities. Some of these metadata elements and 
entities are mandatory and some are optional. In many cases, an image exploitation service input or 
output in Section 3 that is marked “(is metadata for ...)” is all or most of one ISO metadata entity. 
Table 4-1 lists various service inputs and outputs with the exactly or approximately corresponding 
ISO metadata entities. 

Image Exploitation Service ISO Metadata Name 
Input or Output Section Entity 

Ground position SRS definition, 
Coordinate transformation parameters, 
Adjusted parameters of transformation between 
SRSs 

Reference system 
information 

Spatial reference by coordinates (and 
lower level entities) 

Illumination direction, azimuth and elevation 
angles 

Spatial data 
representation 
information 

Image spatial representation information 
(part of entity) 

Image or dataset identification Identification 
information 

Identification Citation, 
Image identification information 

Imaging times, 
Accuracy estimates for imaging times 

Identification 
information 

Temporal extent (in Extent information) 

Temporal SRS definition Reference system Temporal reference system information 

The Open GIS Abstract Specification  Page 43 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

information 
Specification of metadata format Metadata reference 

information 
Metadata standard information, 
Metadata extension information 

Table 4-1.  ISO Metadata Used as Service Inputs and Outputs 

4.2. Image Pixels 
As listed in Section 3, image pixels are inputs and outputs of several image exploitation service 
categories. In addition to transferring pixel values, the size of the pixel grid must be transferred, 
plus the sequencing scheme used when transferring pixel values. Responses to the Simple (or grid) 
Coverages RFP are expected to specify standard formats for transferring image pixels and other 
grid data, as inputs and outputs to Coverage access operations. This document assumes that these 
grid coverage formats can be used to transfer image pixels for image exploitation services inputs 
and outputs. 

4.3. Desired Image Section 
The desired image section is also an input or output of several image exploitation service 
categories. The location and size of the desired image section must be specified, within a larger 
image (or set of image pixels). Responses to the first (or grid) Coverages RFP are also expected to 
specify standard formats for specifying the desired image section, as inputs and outputs to 
Coverage access operations. This document assumes that this image section specification format 
can be used for image exploitation services. 

Alternately, the desired image section could be specified using an area feature geometry, such as 
specified in the three Simple Features implementation specifications that have been accepted by the 
OGC. We assume this area feature geometry would be in 2-D image coordinates, not 3-D or 2-D 
ground coordinates. 

If the desired image section is a rectangle in image space, such a rectangle could be specified by the 
pixel position of one corner, plus the pixel section width and height. Using this approach, an Image 
Section data type defined using ISO standard IDL data types and structures is: 

// Type: Image Section, rectangular section of an image 
      struct ImageSection { 
         long corner_column; // Smallest pixel column number 
         long corner_row;    // Smallest pixel row number 
         long width;         // Number of image pixel columns 
         long height;        // Number of image pixel rows 
         }; 

4.4. Point Position Coordinates 
Point position coordinates are also inputs and outputs of several image exploitation service 
categories. Such a point position requires specifying the values of three, two, or one coordinates. 
All three OpenGIS® accepted implementation specifications for Simple Features include data 
formats for point positions in two (or three, TBR) coordinates. (We are referring to the vertices of 
feature geometries, not to point geometries.) That format is a data structure containing two (or 
three, TBR) floating point numbers. The modification of this data format to three or one coordinate 
is obvious. 

(Note: The SRSs used for point position coordinates are listed as separate service inputs and 
outputs, and are discussed in Table 1 of Section 3.1.) 

4.5. Position Accuracy Estimates 
Absolute and relative position accuracy estimates are also inputs and outputs of several image 
exploitation service categories. The accuracy inputs and outputs are often optional, needed by 
operations only when accuracy output data is desired by a client program or user. Several 
alternative forms of accuracy data could be used. However, Abstract Specification Topic 9: Quality 
specifies that accuracy be recorded as covariance matrices. 

The Open GIS Abstract Specification  Page 44 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

As discussed in Section 2.8 of Topic 9, detailed accuracy information can be recorded using a 
covariance matrix, sometimes called a variance-covariance matrix. For the three ground 
coordinates of one point, a covariance matrix is a 3 by 3 matrix, with the matrix rows and columns 
each corresponding to the three coordinates. For just the two horizontal ground coordinates, a 
covariance matrix is a 2 by 2 matrix, with the matrix rows and columns each corresponding to the 
two horizontal coordinates. Similarly, for two image coordinates, a covariance matrix is a 2 by 2 
matrix, with the matrix rows and columns each corresponding to the two image coordinates. 

The covariance matrix cells contain the expected average values of the product of the error in the 
matrix row coordinate times the simultaneous error in the matrix column coordinate. For absolute 
accuracy, the diagonal matrix cells contain the error variances of the corresponding ground 
coordinates, or the squares of the standard deviations. The off-diagonal cells contain the 
covariances between the errors in the corresponding ground coordinates; these covariances will be 
zero when the errors in different coordinates are not statistically correlated. All covariance matrices 
are symmetrical, meaning that the same cell values appear on both sides of the diagonal cells. 

Covariance matrices can be used to record absolute and/or relative accuracies. A covariance matrix 
for the relative accuracy between two points uses the three (or two) coordinates of one point for 
matrix rows and the three (or two) coordinates of the second point for matrix columns. A complete 
covariance matrix for N specific points would contain 3N rows and 3N columns. 

When other forms of accuracy data are desired by a user, such as Circular Error (CE) and Linear 
Error (LE), they can be converted from (or to) covariance matrices. (Please see Sections 2.4 
through 2.7 of Topic 9 for definitions of CE, LE, and other forms of accuracy data.) Such accuracy 
conversion is the purpose of the Accuracy Conversion Services, as discussed in Section 2.7 of this 
document. CE and LE can each be transferred as a single precision floating point number, as can 
the confidence probability associated with each CE and LE. 

This document assumes that accuracy will always be specified in OpenGIS® interfaces in units of 
meters or meters-squared, as specified in Abstract Specification Topic 9: Quality. Alternately, the 
units used for accuracy values must be specified. 

4.5.1. Covariance Matrix Data Structures 
A covariance matrix may not have known values for all matrix cells, so the data structure used 
should allow some cells to have null or missing values. One possible way to transfer a potentially 
incomplete covariance matrix is to use a list, or one-dimensional array, of simple data structures. 
This list will contain a simple data structure for each known and unique valued covariance matrix 
cell. Each simple data structure will contain a covariance matrix cell identifier and the 
corresponding cell value. Each matrix cell identifier could consist of two characters, each character 
designating one of the matrix cell indices. The cell value could be a single precision floating point 
value. 

Using this approach, a set of accuracy data types can be defined. Such a set defined using ISO 
standard IDL data types and structures is: 

// Type: Matrix Cell, of a covariance matrix 
      struct MatrixCell { 
         string <2>   axes;   // Axes of covariance matrix 
         float        value;  // Units: Meters squared 
         }; 
 
// Type: Ground Covariances, of 3-D ground coordinates 
      typedef sequence <MatrixCell, 6>  GroundCovariances; 
   // Covariance matrix cells included only when correct 
   //    value is known 
   // Required values of “axes” string: XX, YY, ZZ 
   // Optional values of “axes”  string: XY, XZ, YZ 
   // Where X, Y, and Z stand for three ground coordinates 
 
// Type: Horizontal Covariances, of 2-D ground coordinates 
      typedef sequence <MatrixCell, 3> HorizontalCovariances; 
   // Covariance matrix cells included only when correct 

The Open GIS Abstract Specification  Page 45 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

   //    value is known 
   // Required values of “axes”  string for variances: XX, YY 
   // Optional values of “axes”  string for covariances: XY 
   // Where X and Y stand for two horizontal coordinates 
 
// Type: Image Covariances, of image position coordinates 
      typedef sequence <MatrixCell, 3>  ImageCovariances; 
   // Covariance matrix cells included only when correct 
   //    value is known 
   // Required values of “axes”  string for variances: RR, CC 
   // Optional values of “axes”  string for covariances: RC 
   // Where R and C stand for Image Row and Image Column 

4.6. Elevation Data 
When a position in a monoscopic image is used to find the corresponding ground position, 
elevation (or height) data is usually needed. Elevation data is thus an input to several image 
exploitation service categories. Such elevation data could take one of several forms, including: 

1. Single elevation value, to be used for one or more image positions 

2. List of elevation values, to be used with a corresponding list of image positions 

3. Elevation coverage, that defines the elevation as a function of ground position, to be used for one 
or more image positions 

Each elevation could be transferred as one double precision floating point value. (Note: The SRSs 
used for elevations are listed as separate service inputs and outputs.) Elevation data structures 
defined using ISO standard IDL data types and structures are: 

// Type: Double List, list of elevation or other numbers 
      typedef sequence <double>   DoubleList; 
 
// Type: Elevation Data Type 
      enum ElevationType { 
         SINGLE,  // One elevation for all image positions 
         LIST,    // One elevation for each image position 
         MODEL    // Elevation is modeled function of 

            // horizontal position 
         }; 
 
// Type: Elevation Data, used with monoscopic image positions 
      union ElevationData   switch (ElevationType) { 
         case SINGLE:  double             elevation; 
         case LIST:    DoubleList         elevations_list; 
         case MODEL:   ElevationCoverage  elevation_model; 
            // Reference to an Elevation Coverage object 
         }; 

4.7. Elevation Accuracy Estimates 
When elevation is used and output accuracy is needed, elevation accuracy data is a needed input to 
several image exploitation service categories. The accuracy of a single elevation value, or of all 
elevations in a list, can be specified by a one single precision floating point number. This value 
could have one of several meanings, including variance, standard deviation, or LE (Linear Error). A 
LE value could use one of several confidence probabilities. For consistency with using a covariance 
matrix to specify the accuracy of two or three dimensional coordinates, a variance value should be 
used for elevation value accuracy. 

When elevation is specified by an elevation coverage, the effect of horizontal position errors on the 
elevation value error should be represented. This can be done using a partial 3-D covariance matrix, 
with a special interpretation of the values in off-diagonal cells. These off-diagonal cells can contain 

The Open GIS Abstract Specification  Page 46 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

the ratio of the covariance value of that cell to the unknown variance of the corresponding 
horizontal axis. The variance cell for the elevation would have the normal meaning. The other 
diagonal cells in the covariance matrix, for the two horizontal coordinates, would be missing or 
have null values. The off-diagonal cells for the covariances between the horizontal coordinates 
would also be missing or have null values. 

Using this approach, elevation accuracy data types can be defined. Such a set defined using ISO 
standard IDL data types and structures is: 

// Type: Matrix Cell, of a covariance matrix 
      struct MatrixCell { 
         string <2>   axes;   // Axes of covariance matrix 
         float        value;  // Units: Meters squared 
         }; 
 
// Type: Elevation Covariances 
      typedef sequence <MatrixCell, 3>  ElevationCovariances; 
   // Covariance matrix cells included only when correct 
   //    value is known 
   // Required values of ìaxesî string: ZZ 
   // Optional values of ìaxesî string: XZ, YZ 
   // Where X, Y, and Z stand for three ground coordinates 
   // Matrix cell XZ contains the ratio of XZ to XX 
   // Matrix cell YZ contains the ratio of YZ to YY 

4.8. Image SRS Definition 
The SRS of an image is often specified by a ground position SRS definition plus an image 
geometry model, that together relate image positions to ground positions (in that ground SRS). The 
ground position SRS can be specified as in the draft ISO standard for geospatial metadata, 
including the “Spatial reference by coordinates” and lower level metadata entities (as discussed in 
Table 1 of Section 3.1). The image geometry model can be specified by the values of the set of 
parameters used by a specified mathematical model of the image geometry. These parameters are 
considered metadata for the image. 

Image geometry model metadata is already partially discussed or implied in Abstract Specification 
Topic 7: The Earth Imagery Case, and in proposal document 98-033: Alternatives for Transferring 
Orientation Data of Digital Aerial Images. These documents describe a number of possible forms 
of image geometry model metadata: 

1. Values of image geometry model parameters: 

1.1. For rigorous geometry models (there are many existing rigorous geometry models) 

1.2. For real-time geometry models, including: 

1.2.1. Polynomial models (Section 3.2 of Topic 7) 

1.2.2. Ratios of Polynomials (Section 3.4 of Topic 7) 

1.2.3. Universal Real-Time Model (Section 3.5 of Topic 7) 

2. Positions of points in both ground and image coordinates: 

2.1. Grid of Points with Interpolation (Section 3.3 of Topic 7) 

2.2. Set of reference points, used by client for fitting parameters of image geometry model 
(Sections 2.3 and 3.2 of 98-033) 

The Open GIS Abstract Specification  Page 47 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

Technical Note: The OGC Technical Committee (TC) must answer several questions on the 
possible forms of image geometry model metadata, including: 

1. Are there other possible forms of image geometry model metadata? 

2. To what degree can or should the TC leave the selection of one or more forms of image 
geometry model metadata up to organizations that propose implementation specifications in 
response to an RFP? 

3. For which future RFP should the form(s) of image geometry model metadata be selected 
(whether selected by the TC or by the RFP responders)? 

4. Which one or more forms of image geometry model metadata should the TC select or prefer? 

4.9. Features With Geometry 
Features with geometry are also inputs and outputs of several image exploitation service categories. 
Some of these features include a full set of feature attributes, while other input/output features may 
include few feature attributes other than the geometry. All three OpenGIS® accepted 
implementation specifications for Simple Features include data formats for features with geometry, 
including collections of features. This document assumes that these feature formats can be used to 
transfer features with geometry for inputs and outputs to image exploitation services. 

The possible feature geometries used as service inputs and outputs include: 

1. Single point 

2. Set of points 

3. Grid of points 

4. Linear feature geometry 

5. Area feature geometry 

4.10. Strategy Parameters 
Some image exploitation services require inputs containing values of strategy parameters, that are 
used by the service algorithms to control service operations. The values of such strategy parameters 
are often heuristic, being experimentally found to produce the best results for some set of primary 
input data. However, the most effective set of values differs for different categories of other input 
data. 

In some cases, the categories of input data affecting strategy parameters are types of ground details 
that are visible in the input image(s). For example, the most effective set of strategy parameter 
values for Elevation extraction service (Section 3.7.2.4) depends heavily on the roughness of the 
(visible) ground surface over the ground area to be extracted. The most effective strategy parameter 
values for automatic elevation extraction also depends on the amount of high-frequency detail 
visible in the ground cover. Similarly, the most effective set of strategy parameter values for 
Geodata Registration Services (Section 3.6) depends on the spatial distributions of control and tie 
points. (A control point has a known correct ground location, and a tie point does not). 

The needed set of strategy parameters is different for different image exploitation services and is 
very likely to be different for different implementations of the same service. However, a name 
value list (as described in Section 4.14) could be used as a standard data structure for all possible 
sets of strategy parameters. Of course, each implementation of each service must specify the set of 
names and definitions that it uses for strategy parameters, together with the data type, units, and 
range (or domain) of the values for each parameter name. Each service probably should make all 
this information available to a client by providing an operation that retrieves this strategy parameter 
description information. 

4.11. Selection of Service Operation 
Selection of the specific image exploitation service desired is listed as an input for most service 
categories. Such selection would conventionally be done by calling a different service object or 
operation for each specific service. Alternately, selection can be done by using one or more 

The Open GIS Abstract Specification  Page 48 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

“Service Selection” inputs whose data type is an enumeration of all the alternative specific services 
available through one service operation. These “Service Selection” inputs could be handled like, or 
as an extension of, the Strategy Parameters discussed above. 

4.12. Other Inputs and Outputs 
Some image exploitation service inputs and outputs do not fall in the above categories. Table 4-2 
lists many of these other inputs and outputs, with some information on the possible data format, 
mostly using ISO standard IDL data types and structures. 

Service Input or Output Possible Data Format 
Computed dimensions, including: 

Distance, 
Area,  

 
Volume 

 
Angle 
Time Difference 

 
Velocity 

NameValueList // See Section 4.2, or use: 
typedef float  Distance;  // Units: meters 
typedef float  Area; 
   // Units: meters squared 
typedef float  Volume; 
   // Units: meters cubed 
typedef float  Angle;     // Units: degrees 
typedef float  TimeDifference; 
   // Units: seconds 
typedef float  Velocity; 
   // Units: meters per second 

Dimension accuracy estimates typedef float  Variance; 
   // Units: Dimension units squared 

Transformation accuracy estimates See Position Accuracy Estimates, Section 3.5 
Accuracy estimates See Position Accuracy Estimates, Section 3.5, and: 

typedef float  CE;          // Units: meters 
typedef float  LE;          // Units: meters 
typedef float  SphericalError; 
   // Units: meters 

Confidence level for CE and LE typedef float  Confidence; 
   // Units: probability 

Accuracy conversion parameters NameValueList  // See Section 3.12.1 
Measures of quality of image match typedef float  Confidence; 

   // Units: probability 
See Position Accuracy Estimates, Section 3.5 

Success or failure of metadata 
modifications 

typedef boolean  OperationSucceeded; 

Table 4-2. Possible Formats of Other Service Inputs and Outputs 

Note that all quantities listed as “float” type could alternately be “double” type, if more accuracy is 
needed. The quantities listed as “float” type are considered unlikely to need more accuracy than 
provided by “float”. 

4.12.1. Accuracy Conversion Parameters 
The “Accuracy conversion parameters” might be formatted as a Name Value List, as discussed 
below in Section 4.14. For conversion between covariance matrices and CE plus LE, the names and 
values shown in Table 4-3 might be used: 

Name Data Type Units Definition Comments 
Error Probability float (none) Confidence probability for CE and LE error 

estimates 
Note A 

Probability 
Distribution Name 

string (none) Name of probability distribution, such as 
“normal distribution” 

 

LE Multiplier float (none) Multiplier of standard deviation to obtain LE 
with specified probability 

Note B 

CE Multiplier 
Function 

sequence 
<float> 

(none) Multipliers of standard deviation to obtain CE 
with specified probability 

Note C 

Table 4-3. Possible Accuracy Conversion Parameters 

Table Notes: 

The Open GIS Abstract Specification  Page 49 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

A. The possible probability values include 0.50, 0.6827, 0.90, and 0.95. 
B. This multiplier is used to compute LE with the specified confidence probability from the 

standard deviation of the error (square root of the variance). 
C. These multipliers are used to compute CE with the specified confidence probability from the 

standard deviation (square root of the variance) along the major axis of the error ellipse. 
The CE is computed from the covariance matrix of the expected errors in two axes, either the two 
horizontal ground coordinates or the two image coordinates. When the error estimates in the two 
axes are correlated and/or are not equal, the variances are first computed for the major and minor 
axes of the error ellipse. The ratio of the variance in the minor axis to the variance in the major axis 
of the error ellipse is then computed. As this ratio varies from 0.0 to 1.0, the multiplier needed to 
compute CE varies from one number to a larger number. 

The multipliers are specified for a variable number of evenly spaced values of the minor/major axis 
variance ratio, from 0.0 to 1.0. (The number of ratio values may be 21, for ratio values differing by 
0.05.) For a minor/major ratio between the recorded values, linear interpolation is used. 

4.13. Other Possible Outputs 
For some applications, it appears desirable to make electronically available lists of the functions, 
operations, inputs, and outputs of a service. Such information could be provided to client software 
in at least two different ways: 

1. A separate service could be provided that makes available information about many other 
services. These other services would be registered with this service-information providing service. 
This service would provide information on any registered service, when requested for a specified 
service by a client program. 

2. Each service could provide one or more operations that could be called to obtain information 
about that service. These operations would provide information about that service. The result data 
listed in Section 3 for each image exploitation service category does not currently list such 
information, but it could be added to all service categories. 

A separate service that provides information about many other services (as in item 1 above) appears 
to be beyond the scope of the IES SIG. We think it is beyond the IES scope since it equally 
supports both feature and image based OGC services. Furthermore, the OGC catalog services 
described in OGC Abstract Specification Topic 13 support finding such information about other 
services. A service that provides information about many other services may also be beyond the 
scope of the OGC. This may be beyond the desirable scope of the OGC since it equally supports 
both geospatial and non-geospatial services. For example, we think CORBA defines such a service. 

Providing service operations that make information available about that service (as in item 2 listed 
above) might be considered within the scope of the IES SIG. However, this issue is broader than 
the IES SIG, since such operations should be provided by both feature and image based OGC 
services. Furthermore, these information-providing operations should be essentially the same for all 
services, and should use common software for efficiency. 

In either of the two cases listed above, the data returned by an operation to get information about a 
service should include a list of all the operations provided by that service. For each operation, lists 
of the inputs and outputs (or arguments) should be returned. A list of any exceptions that can be 
raised by each operation should also be available. The data available about a service probably 
should include information expected to be used by software plus human readable information for 
use in error messages and by a client programmer. 

The data made available for each operation’s input and output might include: 

1. Software Name - Software name of this quantity, perhaps fixed length and not containing spaces. 

2. Human Name - Human understandable name of this quantity, variable length and can contain 
multiple words separated by spaces. 

3. Definition - Human understandable text defining this quantity and its expected use. 

4. Comments - Human understandable text providing more information about this quantity and its 
use 

The Open GIS Abstract Specification  Page 50 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

5. Quantity Required - Specifies whether a value is required or optional for this quantity. 

6. Data Type - Specifies the data type of this quantity, perhaps selecting from a separately specified 
set of data types. 

7. Units Name - Specifies the physical units of values for this quantity, using human readable text.  
Omitted when not applicable. 

8. Minimum Value - Specifies the maximum value of a numerical quantity.  Omitted when not 
applicable. 

9. Maximum Value - Specifies the maximum value of a numerical quantity.  Omitted when not 
applicable. 

10. Default Value - Specifies the default or null value for this quantity.  Omitted when not 
applicable. 

11. Legal Value Expected - Specifies if the value is expected to be one of an enumerated set of 
standard or legal values. 

12. Legal Value and Meaning - Specifies a legal value of this quantity, and the human readable 
meaning of that value. This data is repeated for each legal value, and is omitted when not 
applicable. 

The data available for each exception that can be raised by operations might include: 

1. Software Name - Software name of this exception, perhaps fixed length and not containing 
spaces. 

2. Human Name - Human understandable name of this exception, variable length and can contain 
multiple words separated by spaces. 

3. Definition - Human understandable text defining this exception and the conditions when it is 
raised. 

4. Comments - Human understandable text providing more information about this exception and its 
use, including recovery suggestions. 

Additional data available for each operation might include: 

1. Software Name - Software name of this operation, perhaps fixed length and not containing 
spaces. 

2. Human Name - Human understandable name of this operation, variable length and can contain 
multiple words separated by spaces. 

3. Function - Human understandable text defining the function(s) performed by this operation and 
its expected use. 

4. Comments - Human understandable text providing more information about this operation and its 
use. 

4.14. Hierarchical Name Value Lists 
A Name Value List is a well-known data structure for flexibly transferring data. A Name Value 
List stores a variable length list of name and value pairs. Each Name is recorded as a character 
string. Different names can have associated values of different data types, including integer 
number, floating point number, and character string. The data type used for each value is selected 
appropriate to the definition of the associated name. 

A hierarchy of Name Value Lists can be used. That is, the value of a Name Value pair can be 
allowed to be a lower level Name Value List. Such a Name Value pair can also be allowed to be 
repeated, using the same Name but containing different Values in different lower level Name Value 
Lists. When hierarchical Name Value Lists are used, the top level Name Value List will often 
contain one or more values that are lower level Name Value Lists. 

Using ISO standard IDL, the structure of hierarchical Name Value Lists is: 

The Open GIS Abstract Specification  Page 51 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

// Type: Name 
      typedef string     Name; 
 
// Type: Name Value 
      struct NameValue { 
         Name   name;    // Computer name of item 
         any    value;   // Value of item 
         }; 
   // Note: The ìanyî type includes a Name Value List and 
   //    probably other data structures 
 
// Type: Name Value List 
      typedef sequence <NameValue>   NameValueList; 

 

The value in a Name Value pair can also be allowed to be a data structure other than a Name Value 
List. Some other useful data structures include: 

1. Position coordinates, a structure containing the values of two or three coordinates 

2. List (or sequence) of simple values, such as a list of character string values used for a list of 
names 

3. List (or sequence) of simple data structures, such as position coordinates data structures used for 
the vertices of a polygon 

A metadata entity, section, or set could be implemented or transferred using a hierarchical Name 
Value List data structure. Similarly, a Name Value List structure could be used for a metadata set, a 
feature, a feature collection, a set of strategy parameters, or many other service inputs and outputs. 

If and when a Name Value List is used to transfer service inputs and outputs, the specific set of 
Names and Values used must still be carefully specified. If service inputs and outputs are specified 
in ISO standard IDL using Name Value Lists as defined above, then the specific set of Names and 
Values used must be separately specified (not in the interface IDL). A set of Names and Values 
could be specified in a variety of ways, including using tables such as Table 4-3 in Section 4.12.1 
or the tables used in the draft ISO Metadata Standard, 15046-15. 

4.15. Input and Output Specifications 
Whether or not Name Value Lists are used, all service inputs and outputs must be completely 
specified, to permit client software to be written to correctly use that service. Furthermore, the 
service input and output specifications should be readily available and clearly understandable to the 
applications programmer. In the past, data inputs and outputs have rarely been completely and 
clearly specified in a readily available and easily found location. 

One possible way to make input and output specifications available is for a service to provide an 
operation by which a client can get requested data specifications. For client software, the requested 
data specifications might be returned in the form of a hierarchical Name Value List. 

For an item in a Name Value List, the information needed to completely specify an input or output 
quantity generally includes: 

1. Software Name - Software name of this quantity, perhaps fixed length and not containing spaces. 
Used as the "Name" in name value lists. 

2. Human Name - Human understandable name of this quantity, variable length and can contain 
multiple words separated by spaces. 

3. Parent Name - Name of parent Name Value List that includes this Name Value, if any. Can be 
omitted when not applicable. 

4. Definition - Human understandable text defining this quantity and its expected use. 

5. Comments - Human understandable text providing more information about this quantity and its 
use 

The Open GIS Abstract Specification  Page 52 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

6. Quantity Required - Specifies whether a value is required or optional for this quantity. 

7. Maximum Repetitions - Specifies the maximum number of times this name value pair can be 
repeated. 

8. Data Type - Specifies the data type of this quantity, usually selecting from a separately specified 
set of data types. 

9. Units Name - Specifies the physical units of values for this quantity, using human readable text.  
Omitted when not applicable. 

10. Minimum Value - Specifies the maximum value of a numerical quantity.  Omitted when not 
applicable. 

11. Maximum Value - Specifies the maximum value of a numerical quantity.  Omitted when not 
applicable. 

12. Default Value - Specifies the default or null value for this quantity.  Omitted when not 
applicable. 

13. Legal Value Expected - Specifies if the value is expected to be one of an enumerated set of 
standard or legal values. 

14. Legal Value and Meaning - Specifies a legal value of this quantity, and the meaning of that 
value. This data is repeated for each legal value, and is omitted when not applicable. 

4.15.1. Name Value List Use Objects 
A Name Value List could be implemented by an object of a general “Name Value List Use” 
(concrete) class. That is, a Name Value List Use object might be passed as a service input or 
output, instead of passing a data structure. (An object can be an operation input or output in 
CORBA, but perhaps not in other Distributed Computing Platforms.) 

In addition to storing a Name Value List as its internal state, the Name Value List Use class of 
objects can provide operations to conveniently access the data stored. For example, the Name 
Value List Use class might provide the operations listed in Table 4-4. 

Operation Name Function Inputs Outputs 
Create Object 
 

Create new object, initially empty – new name value list 
use object 

Copy Object 
 

Create new object by copying existing 
name value list use object 

old name value list use 
object 

new name value list 
use object 

Append Name 
Value  

Add new name and value record to end of 
state name value list 

name, 
value 

– 

Get First Name 
Value  

Retrieve first name and value record from 
state name value list 

– name, 
value 

Get Next Name 
Value  
 

Retrieve next name and value record in 
state name value list, after last record 
retrieved by Get Next Name Value or by 
Get First Name Value 

– name, 
value 

Get Selected 
Name Value  

Retrieve value for specified record in state 
name value list 

name, 
partial value name value list 

use object 

current value 

Set Selected 
Name Value 

Change value of specified record in state 
name value list 

name, 
partial value name value list 

use object 

– 

Remove Name 
Value 

Remove selected record from state name 
value list 

name, 
partial value name value list 

use object 

– 

Delete Object 
 

Delete this object – – 

Table 4-4. Possible Operations of Name Value List Use Class 

The Open GIS Abstract Specification  Page 53 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

4.16. ISO Standard IDL 
Many of the ISO (and CORBA) standard Interface Definition Language (IDL) data types and 
structures are summarized in Table 4-5. Most of these data types are common to the C++ 
programming language. 

IDL Name Meaning 
short 16 bit signed integer 
long 32 bit signed integer 
unsigned short 16 bit unsigned integer 
unsigned long 32 bit unsigned integer 
float 32 bit floating point number 
double 64 bit floating point number 
char one 8 bit text character 
string sequence of 8 bit text characters, usually of unlimited length 
boolean one bit data type 
enum enumeration of all possible values 
union discriminated union, containing different data types 

depending on a specified enum data type 
sequence ordered list of data items or data structures, usually of 

unlimited length 
struct structure or record, containing specified list of data items, 

sequences, or lower level structures 
any any data type, including any object identifier or any user 

defined data type (e.g., a name value list) 

Table 4-5. ISO IDL Data Types and Structures 

 
Table 4-6 lists some other IDL terms with the terms used elsewhere for the same concepts. 

IDL Term Other Terms for Same Thing 
interface class, object type 
operation method, function, subroutine 
attribute member, visible data 
parameter argument, input, output 
readonly attribute value can be read but not changed 
in input argument or parameter 
out output argument or parameter 
raises defines which special exceptions can be raised by operation 

when normal execution is not possible 
const constant data value 
typedef custom type definition 
// comment delimiter, start of comment at end of line 

Table 4-6. Other ISO IDL Terms 

The Open GIS Abstract Specification  Page 54 
Volume 15: Image Exploitation Services (00-115 corrigendum) 



   

The Open GIS Abstract Specification  Page 55 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

5. Future Work 

5.1. Software Frameworks 
The interfaces to each image exploitation service or category could be defined independently. If 
defined independently, the interfaces to each service or category would tend to use different 
formats and contents for the same or similar data, used as inputs and/or outputs of different 
services. However, it would be better if multiple service categories use interfaces that are defined to 
use the same data formats and contents for the same or similar data, used as inputs and/or outputs 
of different services. 

Such use of the same interface formats and contents by multiple service categories means 
developing what is often called a software framework. A software framework defines standardized 
interface aspects across multiple software components, where these components often provide 
different user services. Use of a software framework facilitates using multiple complementary 
services together, including using different services in mix-and-match fashion. 

A key issue is: How can the Open GIS Consortium (OGC) obtain multiple implementation 
specifications that fit into one or more software frameworks, to the maximum useful extent? More 
detailed questions include: 

1. Should the OGC request that vendors propose a software framework, or just trust that vendors 
will propose a framework when appropriate? 

2. If the OGC requests that vendors propose a software framework, should this request be in a 
separate RFP, or in an RFP that also requests implementation specifications for interfaces to 
specific services? 

3. If the OGC requests a software framework in an RFP for specific service interfaces, in which 
specific RFPs should a software framework be requested? 

4. How should selected image exploitation services be combined into one RFP (or separated into 
different RFPs) to improve the probability and quality of proposed software frameworks? 

Note that the taxonomy of image exploitation services groups these services into categories with 
similar interfaces. We hope that such a grouping of services will improve the probability and 
quality of proposed software frameworks. For example, item 3 in Section 1 (Image Modification 
Services) includes many lower level services (because they need somewhat similar interfaces). 
Specifically, these Image Modification Services include many Change pixel values services (item 
3.1), many Change pixel positions services (item 3.2), and many other services (items 3.3 and 3.4). 

Similarly, item 1 in Section 1 (Ground Coordinate Transformation Services) includes many 
services that should have largely identical interfaces. Also, Section 2 (Image Coordinate 
Transformation Services) includes many services that should have largely identical interfaces. 
Furthermore, both ground and image coordinate transformation services should have largely 
identical interfaces. 



   

The Open GIS Abstract Specification  Page 56 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

6. Appendix A. Acronyms and Glossary 

6.1. Acronyms 
AOI Area Of Interest 
CE Circular Error 
DRA Dynamic Range Adjustment 
IDL Interface Definition Language 
ISO International Standards Organization 
LE Linear Error 
OGC Open GIS Consortium 
RFP Request for Proposals 
RRDS Reduced Resolution Data Set 
SRS Spatial Reference System 
TTC Tonal Transfer Curve 
USIGS United States Imagery and Geospatial System 

6.2. Definitions 

Editor’s Note: Most of these definitions are copied from the USIGS Glossary. That glossary 
includes definitions extracted from many other documents, including ISO and OGC documents.  
The definitions not copied are annotated “(Note: This definition is not in the USIGS Glossary.)”. 

Absolute accuracy   
Absolute accuracy is defined as the statistic which gives the uncertainty of a point with respect to 
the datum required by a product specification. This definition implies that the effects of all error 
sources, both random and systematic, must be considered. 

Accuracy  
The degree to which information on a map or in a digital database matches true or accepted values. 
Accuracy pertains to the quality of data and the number of errors contained in a dataset or map. In 
discussing a GIS database, it is possible to consider horizontal and vertical accuracy with respect to 
geographic position, as well as attribute, conceptual, and logical accuracy. The effect of inaccuracy 
and error on a GIS solution is the subject of sensitivity analysis. Accuracy, or error, is distinguished 
from precision , which concerns the level of measurement or detail of data in a database. 

Attribute  
1. A named property of an object.  An attribute belongs to a certain attribute type and has a value 
taken from the domain belonging to the attribute type. 

2. A characteristic of a site or phenomenon. May be physical, social, economic or titular in nature.  
For example, road types and road names are road attributes. 

3. Recorded property of a digital feature. An attribute belongs to a certain attribute type and has a 
value taken from the domain belonging to the attribute type. For example, road types and road 
names are road attributes.  
(Note: This definition is not in the USIGS Glossary.) 

Attribute Data   
Descriptive information about features or elements of a database. For a database feature like census 
tract, attributes might include many demographic facts including total population, average income, 
and age. In statistical parlance, an attribute is a "variable," whereas the database feature represents 
an "observation" of the variable. 

Catalog  
A collection of entries, each of which describes and points to a feature collection. Catalogs include 
indexed listings of feature collections, their contents, their coverages, and other metadata. Registers 
the existence, location, and description of feature collections held by an Information Community. 
Catalogs provide the capability to add and delete entries. At a minimum Catalog will include the 
name for the feature collection and the locational handle that specifies where this data may be 
found. The means by which an Information Community advertises its holdings to members of the 
Information Community and to the rest of the world. Each catalog is unique to its Information 



   

The Open GIS Abstract Specification  Page 57 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

Community.  
(Note: This definition is not in the USIGS Glossary.) 

Circular Error  
An accuracy figure representing the stated percentage of probability that any point expressed as a 
function of two linear components (e.g., horizontal position) will be within the given figure. 
Commonly used are Circular Error Probable (CEP [50 percent]), and CE (90 percent). A horizontal 
measurement on the ground, in feet or meters, defining a radius of a circle, within which an object 
of known coordinates should be found on an image. The CE value should have some measure of 
probability (P) associated with it. For example, a CE of 100 meters and .9 P, means that 90 percent 
of the time the object will fall within a circle having a radius of 100 meters. 

Classification  
The assignment of a discrete value to each position in an image or other data. Image classification 
usually uses multiple bands of a multispectral image, or uses multiple images which have been 
accurately registered to one another. Classification can use the values at a single pixel, or can use 
multiple pixel values in a small region centered on the pixel being classified. Classification can 
assign an independent value to each pixel, but often assigns the same value to multiple adjacent 
pixels. For example, isolated pixels with a different initial classifications may be reassigned the 
classification of the adjacent pixel(s) with similar pixel values. A wide variety of methods can be 
used for classification, including Tomlin’s “Map Algebra”, fuzzy logic, and neural nets. 
(Note: This definition is not in the USIGS Glossary.) 

Compilation  
1.  (JCS) Selection, assembly, and graphic presentation of all relevant information required for the 
preparation of a map or chart. Such information may be derived from other maps or charts or from 
other sources. 

2.  (photogrammetry) The production of a new or recompiled map, chart, or related product from 
aerial photographs and geodetic control data by use of photogrammetric instruments. Also called 
photogrammetric compilation; stereocompilation. See also recompilation. 

Concatenated transformation   
Sequential application of multiple transformations.  
(Note: This definition is not in the USIGS Glossary.) 

Coordinate Conversion  
An exact transformation of position coordinates from one Spatial Reference System (SRS) to 
another. This term is used only when the SRS transformation is known exactly.  
(Note: This definition is not in the USIGS Glossary.) 

Coordinate Transformation  
An approximate transformation of position coordinates from one Spatial Reference System (SRS) 
to another. For example, this term is used when the transformation coefficients are determined by 
least squares adjustment. This term is strictly used only when the SRS transformation is known 
only approximately. This term is loosely used when the SRS transformation is known either 
approximately or exactly. 
(Note: This definition is not in the USIGS Glossary.) 

Covariance matrix  
A detailed form of position accuracy data, sometimes called a variance-covariance matrix. For 
three ground coordinates, a covariance matrix is a 3 by 3 matrix, with the matrix rows and columns 
each corresponding to the three coordinates. For just two horizontal ground coordinates, a 
covariance matrix is a 2 by 2 matrix, with the matrix rows and columns each corresponding to the 
two horizontal coordinates. Similarly, for two image coordinates, a covariance matrix is a 2 by 2 
matrix, with the matrix rows and columns each corresponding to the two image coordinates. 
 
The covariance matrix cells contain the expected average values of the product of the error in the 
matrix row coordinate times the simultaneous error in the matrix column coordinate. For absolute 
accuracy, the diagonal matrix cells contain the error variances of the corresponding ground 
coordinates, or the squares of the standard deviations. The off-diagonal cells contain the 
covariances between the errors in the corresponding ground coordinates; these covariances will be 
zero when the errors in different coordinates are not statistically correlated. All covariance matrices 
are symmetrical, meaning that the same cell values appear on both sides of the diagonal cells. 
 



   

The Open GIS Abstract Specification  Page 58 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

Covariance matrices can be used to record absolute and/or relative accuracies. A covariance matrix 
for relative accuracy uses the three (or two) coordinates of one point for matrix rows and the three 
(or two) coordinates of the second point for matrix columns. A complete covariance matrix for N 
specific points would contain 3N rows by 3N columns. 
(Note: This definition is not in the USIGS Glossary.) 

Coverage  
1. GIS coverages (including the special case of Earth images) are two- (and sometimes higher-) 
dimensional metaphors for phenomena found on or near a portion of the Earth’s surface. 
Fundamentally, coverages (and images) provide humans with an n-dimensional (where n is usually 
2, and occasionally 3 or higher) “view” of some (usually more complex) space of geographic 
features. The power of coverages is their ability to model and make visible spatial relationships 
between, and the spatial distribution of, Earth phenomena. 

2. A coverage is a special case of (or a subtype of) feature. 

Delineate  
Two dimensional collection of feature position in an image.  
(Note: This definition is not in the USIGS Glossary.) 

Dimension 
Exploitation  
The evaluation of an image or multiple images to extract the information contained within the 
image(s) as it pertains to a specific list of questions or general categories of questions. Exploitation 
may result in the creation of a report or product to disseminate the information, whether it be to a 
requester or to a data base. 

Extraction  
Two or three dimensional collection of information from one or more images. In monoscopic 
extraction, extraction of each point is normally from one image. In stereoscopic extraction, 
extraction of each point is normally from one stereoscopic pair of images (or stereomates), 
sometimes called “conjugate feature extraction”. In the case of range images, such as SAR or laser 
images, a one dimensional extraction of distance might be done, to determine the distance from the 
camera to a feature.  
(Note: This definition is not in the USIGS Glossary.) 

Feature  
A digital representation of a real world entity or an abstraction of the real world. It has a spatial 
domain, a temporal domain, or a spatial/temporal domain as one of its attributes. Examples of 
features include almost anything that can be placed in time and space, including desks, buildings, 
cities, trees, forest stands, ecosystems, delivery vehicles, snow removal routes, oil wells, oil 
pipelines, oil spills, and so on. Features are usually managed in groups as feature collection. 

Feature attribute  
An essential trait, quality, or characteristic of a geographic feature. 

Feature collection  
A set of related features managed as a group. 

Feature type  
Class of features with common characteristics 

Framework  
In terms of software design, a reusable software template, or skeleton, from which key enabling and 
supporting services can be selected, configured and integrated with application code.  
(Note: This definition is not in the USIGS Glossary.) 

Image  
The permanent record of the likeness of any natural or man-made features, objects, and activities 
reproduced on photographic materials. This image can be acquired through the sensing of visual or 
any other segment of the electromagnetic spectrum by sensors, such as thermal infrared, and high 
resolution radar. 

Image column  



   

The Open GIS Abstract Specification  Page 59 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

Position of an image pixel in the horizontal direction, as that image is normally viewed. Sometimes 
referred to as (image ) sample. 

Image compression  
An operation that, through various techniques, reduces the quantity of stored data needed to 
represent a digital image. 

Image correlation  
The matching of position and physical characteristics between images of the same geographic area 
from different types of sensors, between sensor images and a data base, or between two images 
from the same sensor. 

Image data  
All data collected by a sensor, which after processing, comprises an image. 

Image enhancement  
Any one of a group of operations that improve the detectability of features in an image. These 
operations include contrast improvement, edge enhancement, spatial filtering, noise suppression, 
image smoothing, and image sharpening. 

Image row  
Position of an image pixel in the vertical direction, as that image is normally viewed. Sometimes 
referred to as (image) line. 

Image perspective transformation 
This product type includes video and hardcopy format showing several views of a scene with other 
than the original image geometry. This product type is used to simulate movement around a scene 
at ground or flight level. 

Interface  
A shared boundary between two functional entities.  A standard specifies the services in terms of 
the functional characteristics and behavior observed at the interface.  The standard is a contract in 
the sense that it documents a mutual obligation between the service user and provider and assures 
stable definition of that obligation. 

Linear Error  
1. A one-dimensional error (such as an error in elevation) defined by the normal distribution 
function. 

2. Vertical error at the target. The accuracy with which the elevation of the target can be 
determined. The LE at a point is a value such that the true elevation of the point can be expected to 
have the given value plus or minus LE with same degree of probability (usually 0.9 P). 

3.  In a Linear Error, we record that the value has a specified probability of having an error 
magnitude less than a specified distance.  
(Note: This definition is not in the USIGS Glossary.) 

Mensuration  
1. The act, process, or art of measuring. 

2. That branch of mathematics dealing with the determination of length, area, or volume. 

Metadata  
Data about the content, quality, condition, and other characteristics of data. 

Monoscopic image  
A single image taken of the target. 

Mosaic  
1. An assembly of overlapping aerial photographs which have been matched to form a continuous 
photographic representation of a portion of the Earth's surface. Also called aerial mosaic.  

2. An assembly of two or more overlapping or adjacent orthorectified (or rectified) images to form 
a continuous image of a larger ground area. The images mosaicked are normally first 
radiometrically matched to minimize visible discontinuities in the mosaic between the adjacent 



   

The Open GIS Abstract Specification  Page 60 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

images. Unrectified images are not normally mosaicked, because the effects of camera tilt and 
terrain relief will leave large position discontinuities along the mosaicking lines between different 
original images.  
(Note: This definition is not in the USIGS Glossary.) 

Orthorectification  
1. The process of removing image displacement caused by tilt and terrain relief. Tilt, however, is 
not relevant in radar images. 

2. The process of transforming one input image into an output image possessing a perpendicular 
parallel projection. Orthorectified images thus have a constant scale. The orthorectification process 
removes image tilt and displacement due to terrain elevation. Orthorectification requires using 
digital elevation data, usually in grid form. Orthorectification is sometimes termed “differential 
rectification” since the input image is separately rectified to cover each elevation grid cell.  
(Note: This definition is not in the USIGS Glossary.) 

Orthophotograph  
1. A photographic copy, prepared from a perspective photograph, in which the displacements of 
images due to tilt and relief have been removed. 

2. An image produced by orthorectification.  
(Note: This definition is not in the USIGS Glossary.) 

Orthophoto stereomate  
An image generated to support stereoscopic viewing with a specific orthophotograph. An 
orthophoto stereomate can be produced by methods similar to those used in producing the 
orthophotograph, except that image details are deliberately displaced by an amount simulating 
displacement due to the relief that was removed from the orthophoto. 
(Note: This definition is not in the USIGS Glossary.) 

Perspective scene generation  
See Image Perspective Transformation 

Pixel  
1. 2-dimensional picture element that is the smallest nondivisible element of a digital image. 

2. In image processing, the smallest element of a digital image that can be assigned a gray level. 
Note: This term originated as a contraction for “picture element”. 

Photogrammetry  
1. Use of aerial photographs to produce planimetric and topographic maps of the earth's surface and 
of features of the built environment. Effective photogrammetry makes use of ground control by 
which aerial photographs are carefully compared and registered to the locations and characteristics 
of features identified in ground-level surveys. 

2. The science of mensuration  and geometric adjustment of, an aerial photograph or satellite 
image.  Photogrammetry requires: a mathematical model of the image formation process, 
computation of  the internal geometry of an image, and subsequent correction of imagery based 
upon the ground relationship for every part of the image.  Correction of imagery based on 
computational algorithms and measurement of geometrical position in an image. 

Product 
A completely specified data set, comprised of a set of profiles; specifically including , the schema, 
metadata, quality information, reference system, structure primitives, and encoding. 

Rectification  
1. In photogrammetry, the process of projecting a tilted or oblique photograph onto a horizontal 
reference plane. [Although the process is applied principally to aerial photographs, it may also be 
applied to the correction of map deformation.] 

2. The geometric adjustment of image pixels to remove distortions caused by the imaging sensor 
and the geometry of the sensor to the ground. For the removal of terrain relief displacement see 
orthorectification.  



   

The Open GIS Abstract Specification  Page 61 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

3. The process of projecting a tilted or oblique image onto a selected plane or other surface. The 
plane is often horizontal, but can be tilted to achieve some desired condition, such as to better fit 
the local surface of the earth. Rectification of an ideal frame image is a plane-to-plane projection. 
Rectification of non-ideal images and of images with non-planar geometries (such as pushbroom 
images) includes corrections for the known image deviations from a plane, using an accurate 
mathematical model of the image geometry. 
(Note: This definition is not in the USIGS Glossary.) 

Reduced Resolution Data Set (RRDS)  
Original, high-resolution imagery is useful for many applications (especially close-up displays), but 
for overall displays there may be too much data to process. For example, if the raw image consists 
of 16K X 16K pixels, it is impossible to fit this much data into the cathode ray tube refresh memory 
at once to build an overview display. Therefore, RRDSs are created (as a preprocessing step) and 
are used as input by overview displays whenever the original high-resolution data are impossible to 
use. An original 16K X 16K (=256 megabytes) may be reduced to 1K X 1K (=1 megabyte) for 
overview purposes. 

Relative accuracy An accuracy evaluation based on random errors in determining the positional 
accuracy of one point feature with respect to another feature. 

Request for Information (RFI) 
A general request to the industry to submit information to one of the Task Force Working Groups 
in anticipation of an RFP or to fill a gap in the Abstract Specification.   
(Note: This definition is not in the USIGS Glossary.) 

Request for Proposals (RFP)   
An explicit OGC request to the industry to submit proposals to one of the Task Force Working 
Groups for technology satisfying a portion of the Abstract Specification. RFPs result in 
Implementation Specifications. 

Spatial Reference System (SRS)  
Description of how geographic objects are positioned in space. 

Spherical Error 
A spherical error records that a 3-D position has a specified probability of having a vector error 
magnitude less than a specified distance. 

Stereoscopic images  
1. Two images taken of a single target on one imaging pass to allow three-dimensional viewing of a 
target. 

2. Two photographs [or images] with sufficient overlap of detail to make possible stereoscopic 
examination of an object or an area common to both. 

3. Two or more images of the same object taken from different imaging positions, and thus 
different object viewing directions, that can be used to determine object position in three-
dimensions. Two stereoscopic images are often taken from different points along one flight path, 
but there are also stereoscopic images from different flight paths.  
(Note: This definition is not in the USIGS Glossary.) 

Tile  
1. Partition of a dataset based on the definition of a geographic area. 

2. Part of an image based on rectangular or square image areas.  
(Note: This definition is not in the USIGS Glossary.) 

Tiling scheme  
The scheme used to define tile shape and size, and unique tile identification number. 

Transformation  
1. (photogrammetry) The process of projecting a photograph (mathematically, graphically, or 
photographically) from its plane onto another plane by translation, rotation, and/or scale change. 
The projection is made onto a plane determined by the angular relations of the camera axes and not 
necessarily onto a horizontal plane. See also rectification.  



   

The Open GIS Abstract Specification  Page 62 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

2. (surveying) The computational process of converting a position from UTM or other grid 
coordinates to geodetic, and vice versa; from one datum and ellipsoid to another using datum shift 
constants and ellipsoid parameters. The survey position of a point is frequently given in several 
different grids or ellipsoids; local datum and Doppler-derived WGS 84 are common requirements. 

Triangulated Irregular Network (TIN) 
Triangulated Irregular Network (TIN) A terrain model created from continuously connected 
triangles derived from the Delauney algorithm.  The vertices of the triangles form irregularly 
spaced elevation posts.  Unlike a grid, the TIN allows extra information to be displayed in areas of 
complex relief without displaying dense or redundant data gathered in areas of simple relief. 

Alternately, the TIN triangles can be derived using other constraints, such as Thiessen 
triangulation.  

(Note: This discussion is not in the USIGS Glossary.) 



   

The Open GIS Abstract Specification  Page 63 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

7. Appendix B. The Geospatial Data Extraction Process 
The functional block diagram in Figure 7-1 shows how geospatial data can be extracted from 
images. In this diagram, each box represents a function or activity that can be performed when 
needed, and each arrow represents a flow of data between functions. (Note: This diagram was 
adapted from one used in the previous Earth Imaging Working Group, which was adapted from a 
diagram in the response to RFI #2 submitted to the OGC by the TRIFID Corporation.) 

Radiometric
Correction

Source
Package
Assembly

Geo-
positioning

Feature
Extraction/
Compilation

Thematic
Classification

Elevation
Extraction

Image
Ortho-

rectification

Product
Finishing

Quality
Assurance

Data
Formatting

Product
Database

Image and 
Source

Database

 
Figure 7-1. Image Exploitation Block Diagram 

Table 7-1 summarizes the function of each box shown in the above diagram, plus some of its inputs 
and outputs. (Note: Some of this information was adapted from the response to RFI #2 submitted to 
the OGC by the TRIFID Corporation.)  The inputs to many boxes are listed as “Reformatted 
Images”, and this is thus an output of the “Source Package Assembly” box. The term “Reformatted 
Images” is used since image reformatting is often required, from the formats stored in the ”Image 
and Source Database” to the formats required by the software used by other functional boxes. This 
reformatting can include image data decompression and also reformatting of the Image Metadata. 
This Image Metadata either directly or indirectly defines pairs of images suitable for stereoscopic 
elevation and feature extraction. 



   

The Open GIS Abstract Specification  Page 64 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

Name Function Inputs Outputs 
Source Package 
Assembly 

Select, obtain, and quality check 
source materials needed for 
project, and format data for 
exploitation processes to be used 

Images, 
Image Metadata, 
Control Points, 
Ancillary Data 

(see inputs to other 
functions) 

Radiometric 
Correction 

Correct and/or enhance image 
radiometry (colors and gray 
levels) 

Reformatted Images, 
Image Radiometric 

Calibration Metadata 

Radiometrically Corrected 
Images, 

Image Radiometric 
Correction Metadata 

Geopositioning Adjust image geometry metadata 
to register images to each other 
and/or to control points 

Reformatted Images, 
Image Geometry Metadata, 
Control Points 

Adjusted Image Geometry 
Metadata, 

Image Accuracy Metadata 
Thematic 
Classification 

Classify land use or land cover, 
using single or multiple 
multispectral images plus other 
data (such as existing digital 
feature data) 

(Radiometrically Corrected) 
Images, 

Orthorectified Images, 
Ancillary Data (ground truth 

data) 

Classified Images, 
Classified Image Metadata 

Feature Extraction/ 
Compilation 

Extract digital feature data from 
stereoscopic or monoscopic 
images, or from orthorectified 
images and image mosaics 

Reformatted Images, 
Orthorectified Images, 
Classified Images, 
Image Mosaics, 
Adjusted Image Geometry 

Metadata, 
Elevation Data, 
Ancillary Data (existing 

feature data) 

Feature Data, 
Feature Metadata, 
Geomorphic Features 

Elevation 
Extraction 

Extract and edit digital elevation 
data (grid, TIN, and/or contours) 
from stereoscopic images 

Reformatted Images, 
Adjusted Image Geometry 

Metadata, 
Geomorphic Features, 
Ancillary Data (existing 

elevation data) 

Elevation Data, 
Elevation Metadata 

 

Image Ortho-
rectification 

Orthorectify or rectify to selected 
horizontal coordinate datum and 
projection. Optionally mosaic 
multiple images after radiometric 
and geometric matching. 

Radiometrically Corrected 
Images, 

Adjusted Image Geometry 
Metadata, 

Elevation Data 

Orthorectified Images, 
Rectified Images, 
Image Mosaics 

Product Finishing Prepare complete product, 
combining multiple data types as 
needed, and assemble product 
metadata 

Feature Data, 
Elevation Data, 
Orthorectified Images, 
Image Mosaics, 
Classified Images, 
Radiometrically Corrected 

Images 

Complete Products, 
Product Metadata 

Quality Assurance Review complete product and 
metadata for completeness, 
accuracy, and quality, and update 
product metadata 

Complete Products, 
Product Metadata 

Complete Products, 
Checked Product Metadata 

Data Formatting Convert complete product and 
metadata into correct format for 
output and storage 

Complete Products, 
Checked Product Metadata 

Formatted Products, 
Formatted Product 

Metadata 

Table 7-1. Process Box Functions, Input and Outputs 

A wide variety of use cases are implied by the diagram in Figure 7-1, including all the use cases 
defined in Section Error! Reference source not found.. Each step listed in Section Error! 
Reference source not found. is part (or all) of a process box shown in Figure 7-1. For example, 
the steps listed for the “Produce Feature Product” use case in Section 2.1.2.1 correspond to the 
process box functions shown in Figure 7-1 as listed in Table 7-2. 

Use Case Step Image Exploitation Process 
1) Prepare feature source package Source Package Assembly, 



   

The Open GIS Abstract Specification  Page 65 
Volume 15: Image Exploitation Services (00-115 corrigendum) 

Geopositioning 
2) Edit elevation data Elevation Extraction 
3) Display features overlaid on images Feature Extraction/Compilation 
4) Edit existing feature Feature Extraction/Compilation 
5) Extract feature from image Feature Extraction/Compilation 
6) Check new product Quality Assurance 
7) Release new feature product Data Formatting 

Table 7-2 . Image Exploitation Processes Used to Produce Featrure Product 

Although many more use cases could be derived from Figure 7-1 and Table 7-1, such use cases 
have not yet been explicitly defined. Although not presented in use case format, Figure 7-1 and 
Table 7-1 imply a number of image exploitation services, and so are documented here. 

8. Appendix C. OGC Image Levels 
The OGC has defined a set of image levels to be used in labeling processed images. These image 
levels imply some additional use cases that would use image exploitation services, but are not 
documented here. The OGC list of image levels is: 

• A Level 0 image includes systems corrections only.  Its metadata is the raw information 
extracted from telemetry. 

• A Level 1 image admits refinement and additions to metadata.  It also allows radiometric and 
geometric calibrations using external information. 

• A Level 1A image supports geographic formatting using the sensor system’s geographic 
knowledge.  The image pixel values are not adjusted, but based on internal system 
information, metadata values may change, or new metadata is added. 

• A Level 1R image provides radiometric adjustment using the sensor system’s radiometric 
calibration data measurements. 

• A Level 1G image has photogrammetric geopositioning of the sensor data using external 
geo-referenced information. 

• A Level 1N image is a non-mapping product. 

• A Level 2 image involves image pixel modification, and possibly the compilation of products 
from Level 1 data. 

• A Level 2R image possesses radiometric modification of level 1 data using external 
information.  An example is atmospheric correction. 

• A Level 2G image has been geometrically transformed (resampled) using 
photogrammetric geopositioning.  Examples include rectification and orthorectification. 

• A Level 2T product consists of terrain information compiled from level 1G images. 

• A Level 2F product consists of feature or thematic classification from level 1G images. 

• A Level 3 product involves the extraction or classification of information from level 2 
products. 

• A Level 3F product consists of features or thematic information extracted from level 
2 products 

• A Level 3T product consists of terrain information extracted from level 2 products 

• A Level 4 products consists of symbolized information extracted from level 2 or 3 products. 
• Level 4F and 4T products support feature symbolization and terrain symbolization 

respectively. 

 

 


	1. Introduction
	1.1. The Abstract Specification
	1.2. Introduction to Image Exploitation Services
	1.3. References for Section 1

	2. Background for Image Exploitation Services
	2.1. Use Cases
	2.1.1. The Information Consumer Perspective
	2.1.1.1. The Farmer
	2.1.1.2. The Prospective Home Buyer
	2.1.1.3. The Soldier

	2.1.2. The Information Producer Perspective
	2.1.2.1. Produce Feature Product
	2.1.2.2. Extract Feature from Image
	2.1.2.3. Edit Elevation Data
	2.1.2.4. Prepare Feature Source Package
	2.1.2.5. Register Images

	2.1.3. Description of Some Services
	2.1.3.1. Display Image With Overlaid Graphics
	2.1.3.2. Generate Perspective Scene
	2.1.3.3. Classify Pixels and Segment Image
	2.1.3.4. Automated Feature Detection


	2.2. Image Exploitation Services Categorization and Taxonomy
	2.2.1. Notes on the image exploitation service taxonomy

	2.3. Uses of Other Services
	2.4. References for Section 2

	3. Abstract Specification for Image Exploitation Services
	3.1. Ground Coordinate Transformation Services
	3.1.1. Function
	3.1.2. Service subtypes
	3.1.2.1. Ground coordinate conversion (exact) services
	3.1.2.1.1. Geodetic coordinate conversion services
	3.1.2.1.2. Map projection conversion services

	3.1.2.2. Ground coordinate transformation (approximate) services
	3.1.2.2.1. Datum transformation services
	3.1.2.2.2. Affine 2-D transformation service
	3.1.2.2.3. General 2-D Polynomial transformation service
	3.1.2.2.4. Polynomial 3-D transformation service
	3.1.2.2.5. Vertical ground position transformation services
	3.1.2.2.6. Other 3-D coordinate transformation services
	3.1.2.2.7. Other 2-D horizontal ground position transformation services

	3.1.2.3. Concatenated ground coordinate transformation services 
	3.1.2.3.1. 3-D to 3-D concatenated transformation
	3.1.2.3.2. 2-D to 2-D concatenated transformation
	3.1.2.3.3. 1-D to 1-D concatenated transformation


	3.1.3. Results Data
	3.1.4. Needed data
	3.1.5. Discussion

	3.2. Image Coordinate Transformation Services
	3.2.1. Function
	3.2.2. Results Data
	3.2.3. Needed data
	3.2.4. Service subtypes
	3.2.4.1. Image-ground position transformation services
	3.2.4.1.1. Ground to image position transformation service (3-D to 2-D)
	3.2.4.1.2. Stereoscopic images to ground position transformation service (multiple 2-D to one 3-D)
	3.2.4.1.3. Monoscopic image plus elevation to ground position transformation service (2-D plus elevation to 3-D)
	3.2.4.1.4. Monoscopic image plus other data to ground position transformation service (2-D plus other data to 3-D). (This other data might include laser profiling or radar range data.)

	3.2.4.2. Image position transformation services (2-D to 2-D)
	3.2.4.2.1. Polynomial transformation service
	3.2.4.2.2. Image to rectified image position conversion service
	3.2.4.2.3. Rectified image to image position conversion service

	3.2.4.3. Concatenated image coordinate transformation services
	3.2.4.3.1. 3-D to 2-D concatenated transformation (ground to image)
	3.2.4.3.2. 2-D to 3-D concatenated transformation (image to ground)
	3.2.4.3.3. 2-D to 2-D concatenated transformation (image to image)


	3.2.5. Discussion

	3.3. Imaging Time Determination Service
	3.3.1. Function
	3.3.2. Service subtypes
	3.3.2.1. Determine imaging time for one or more image positions

	3.3.3. Results Data
	3.3.4. Needed data
	3.3.5. Discussion

	3.4. Image Modification Services
	3.4.1. Function
	3.4.2. Service Subtypes
	3.4.2.1. Change pixel values services
	3.4.2.1.1. Tone modification services
	3.4.2.1.2. Spatial filtering (or convolution) services
	3.4.2.1.3. Pixel (multi-band or multi-image) classification services
	3.4.2.1.4. Image segmentation services
	3.4.2.1.5. Band and image combination services
	3.4.2.1.6. Other image enhancement services
	3.4.2.1.7. Simulate non-idealities services
	3.4.2.1.8. Histogram generation service
	3.4.2.1.9. Fourier analysis service
	3.4.2.1.10. Other frequency domain services
	3.4.2.1.11. Graphical overlay application service
	3.4.2.1.12. Grid overlay generation service

	3.4.2.2. Change pixel positions services
	3.4.2.2.1. Pixel resampling service (service used by following subtypes)
	3.4.2.2.2. Polynomial transformation warping service
	3.4.2.2.3. Computer graphics warping services (including splines, piece-wise transformations)
	3.4.2.2.4. Image rectification service
	3.4.2.2.5. Orthorectification service (including orthophoto stereomate generation)
	3.4.2.2.6. Image mosaicking service
	3.4.2.2.7. Perspective scene generation service

	3.4.2.3. Change image data format services
	3.4.2.3.1. Image section retrieval services
	3.4.2.3.2. Image section replacement services
	3.4.2.3.3. Tiling change services
	3.4.2.3.4. Reduced resolution generation service
	3.4.2.3.5. Increased resolution estimation (or creation) services
	3.4.2.3.6. Image compression and decompression services:
	3.4.2.3.7. Composite image modification services


	3.4.3. Results Data
	3.4.4. Needed data
	3.4.5. Discussion

	3.5. Dimension Measurement Services
	3.5.1. Function
	3.5.2. Service Subtypes
	3.5.2.1. Line segment dimensions services:
	3.5.2.1.1. Compute horizontal length and angle clockwise from North of a line segment, from one point to a second point
	3.5.2.1.2. Compute 3-D length and direction angles of a line segment, from one point to a second point

	3.5.2.2. Multi-segment line length service:
	3.5.2.2.1. Compute length of multi-segment line feature or real world object, from sequence of vertices representing spatial position of that line

	3.5.2.3. Area dimensions services:
	3.5.2.3.1. Compute area and perimeter of area feature or real world object, from sequence of vertices representing the polygon boundary of that area
	3.5.2.3.2. Compute size, orientation, and center position of a standard geometrical shape, from a sequence of points on the perimeter of that shape. (The standard geometrical shapes are usually horizontal or vertical in the project world SRS. A variety of different shapes could be supported, including rectangle, square, ellipse, circle, parallelogram, and more complex shapes.)

	3.5.2.1. Height dimension service:
	3.5.2.1.1. Compute height of a vertical real-world object (such as a pole or building), from one point on the image of the top and a second point on the image of the base. (The real-world object is assumed to be vertical in the project world SRS.)
	3.5.2.1.2. Compute height of a vertical real-world object (such as a pole or tower), from one point on the image of the top and a second point on the image of the shadow of the first point. (The real-world object is assumed to be vertical in the project world SRS. This computation requires access to the illumination direction, and assumes that the top of the shadow falls on a surface at the same elevation as the base of the real-world object.)

	3.5.2.2. Volume dimension service:
	3.5.2.2.1. Compute volume of a solid features using its shell, from a sequence of vertexes for each facet of the shell. (This capability requires the ability to record features with volume geometries. Handling of volume features has been put off for future work by the OGC. Therefore, complete specification and implementation of this Volume dimension service may have to be delayed.)
	3.5.2.2.2. Compute cut and fill volumes between two different elevation surfaces, specified by a digital terrain matrix, regular triangulated network, or triangulated irregular network.

	3.5.2.3. Temporal dimension service:
	3.5.2.3.1. Compute time difference between two points with known time coordinates.
	3.5.2.3.2. Compute velocity of same object imaged at two different points and times, in the same or different images. The object could be assumed to travel in a straight line between these two points, or to travel along a defined path.


	3.5.3. Results
	3.5.4. Needed data

	3.6. Geodata Registration Services
	3.6.1. Function
	3.6.2. Service Subtypes
	3.6.2.1. Adjust one SRS (Spatial Reference System) to another SRS.
	3.6.2.2. Adjust multiple SRSs to each other (but not adjust to a fixed SRS)
	3.6.2.3. Adjust multiple SRSs to a fixed SRS and to each other

	3.6.3. Results Data
	3.6.4. Needed data
	3.6.5. Discussion
	3.6.6. Related Services

	3.7. Automated Image Matching Services
	3.7.1. Function
	3.7.2. Service Subtypes
	3.7.2.1. Basic image matching services (services used by following subtypes):
	3.7.2.1.1. Correlation matching service
	3.7.2.1.2. Least-squares matching service

	3.7.2.2. Tie point extraction service
	3.7.2.3. Control point transfer service
	3.7.2.4. Elevation extraction service
	3.7.2.5. Image pattern following services
	3.7.2.6. Fiducial mark measurement service
	3.7.2.7. Sample image matching services
	3.7.2.7.1. Object detection and location services
	3.7.2.7.2. Object identification services
	3.7.2.7.3. Object dimension determination services
	3.7.2.7.4. Object classification services


	3.7.3. Results Data
	3.7.4. Needed data

	3.8. Accuracy Conversion Services
	3.8.1. Function
	3.8.2. Service Subtypes
	3.8.2.1. Convert covariance matrices to other forms
	3.8.2.1.1. Convert 3-D covariances to CE plus LE
	3.8.2.1.2. Convert 2-D covariances to CE
	3.8.2.1.3. Convert 1-D variance to LE
	3.8.2.1.4. Convert 1-D variance to Standard Deviation
	3.8.2.1.5. Convert 3-D covariances to Spherical Error

	3.8.2.2. Convert other forms to covariance matrices
	3.8.2.2.1. Convert CE plus LE to 3-D covariances
	3.8.2.2.2. Convert CE to 2-D covariances
	3.8.2.2.3. Convert LE to 1-D variance
	3.8.2.2.4. Convert Standard Deviation to 1-D variance
	3.8.2.2.5. Convert Spherical Error to 3-D covariances


	3.8.3. Results Data
	3.8.4. Needed data
	3.8.5. Discussion

	3.9. Metadata Access Services
	3.9.1. Function
	3.9.2. Service Subtypes
	3.9.2.1. Image geometry model metadata access service
	3.9.2.2. Spatial reference system (SRS) metadata access service
	3.9.2.3. Coordinate transformation metadata access service
	3.9.2.4. Image format metadata access service
	3.9.2.5. Values (of pixels) metadata access service
	3.9.2.6. Service capabilities metadata access service
	3.9.2.7. Service properties (or strategies) metadata access service
	3.9.2.8. Support Metadata Retrieval Services
	3.9.2.8.1. Result Data:
	3.9.2.8.2. Needed Data:

	3.9.2.9. Support Metadata Modification Services
	3.9.2.9.1. Result Data:
	3.9.2.9.2. Needed Data:


	3.9.3. Discussion

	3.10. Image Geometry Model Transformation Services
	3.10.1. Function
	3.10.2. Consequences
	3.10.3. Service Subtypes
	3.10.3.1. Fit approximate image geometry model to point positions computed using existing image geometry model
	3.10.3.2. Convert image geometry model to different, mathematically equivalent model, by converting geometry parameters of existing image geometry model

	3.10.4. Results Data
	3.10.5. Needed data


	1.  
	4. Well Known Types and Structures
	4.1. Metadata
	4.2. Image Pixels
	4.3. Desired Image Section
	4.4. Point Position Coordinates
	4.5. Position Accuracy Estimates
	4.5.1. Covariance Matrix Data Structures

	4.6. Elevation Data
	4.7. Elevation Accuracy Estimates
	4.8. Image SRS Definition
	4.9. Features With Geometry
	4.10. Strategy Parameters
	4.11. Selection of Service Operation
	4.12. Other Inputs and Outputs
	4.12.1. Accuracy Conversion Parameters

	4.13. Other Possible Outputs
	4.14. Hierarchical Name Value Lists
	4.15. Input and Output Specifications
	4.15.1. Name Value List Use Objects

	4.16. ISO Standard IDL

	5. Future Work
	5.1. Software Frameworks

	6. Appendix A. Acronyms and Glossary
	6.1. Acronyms
	6.2. Definitions

	7. Appendix B. The Geospatial Data Extraction Process
	8. Appendix C. OGC Image Levels

